1
00:00:12,544 --> 00:00:13,056
Technology

2
00:00:13,312 --> 00:00:13,824
The internet

3
00:00:15,104 --> 00:00:15,872
Palm of your hand

4
00:00:19,968 --> 00:00:22,016
Technology is a driver of our times

5
00:00:22,528 --> 00:00:26,112
Since its founding in 1958 in the midst of the Cold War

6
00:00:26,368 --> 00:00:26,880
DARPA

7
00:00:27,136 --> 00:00:29,952
The defense Advanced research projects agency

8
00:00:30,208 --> 00:00:30,976
Has been

9
00:00:32,768 --> 00:00:37,888
Welcome to voices from DARPA a window onto DARPA score of program managers

10
00:00:38,400 --> 00:00:39,168
Their job

11
00:00:39,680 --> 00:00:40,704
To redefine what is

12
00:00:40,960 --> 00:00:41,472
Is possible

13
00:00:42,240 --> 00:00:44,032
My name is Ivan Amato and I'm your doorbell

14
00:00:44,288 --> 00:00:44,800
Host

15
00:00:45,056 --> 00:00:47,616
Today I'm pleased to have with me in the studio Jonathan Foust

16
00:00:48,128 --> 00:00:52,224
A program manager since 2015 and his information innovation office

17
00:00:53,504 --> 00:00:56,832
Jonathan earned a PhD in computer engineering from the University

18
00:00:57,088 --> 00:00:58,112
Cambridge in England

19
00:00:58,624 --> 00:01:03,488
But along the way here in degrees in electrical engineering Computer Engineering in brain and cognitive Sciences

20
00:01:04,000 --> 00:01:06,560
All for the Massachusetts Institute of Technology

21
00:01:07,072 --> 00:01:09,888
Jonathan epitomizes darpa's deliberate blindness

22
00:01:10,144 --> 00:01:10,912
To traditional this

23
00:01:11,168 --> 00:01:11,936
Disciplinary boundaries

24
00:01:12,448 --> 00:01:17,568
In search of new research and development territories were perhaps some of the most consequential offer

25
00:01:17,824 --> 00:01:18,336
Opportunities

26
00:01:18,592 --> 00:01:19,616
For technology development

27
00:01:19,872 --> 00:01:20,384
Reside

28
00:01:20,640 --> 00:01:23,712
At DARPA his principal research interests lie at the intersection

29
00:01:23,968 --> 00:01:26,272
And of the computational and behavioral and social sciences

30
00:01:27,296 --> 00:01:29,600
So thanks Jonathan for joining me in the studio today

31
00:01:29,856 --> 00:01:30,880
It's awesome to be here

32
00:01:31,136 --> 00:01:36,768
Before we actually dive into some of the really good stuff about how you got to DARPA and how you think

33
00:01:37,024 --> 00:01:40,096
About technology a program that you recently got going

34
00:01:40,352 --> 00:01:41,120
Few other things

35
00:01:41,632 --> 00:01:43,424
I've got to ask you something that

36
00:01:43,680 --> 00:01:44,192
What I learned

37
00:01:44,448 --> 00:01:45,472
About you and your family

38
00:01:47,008 --> 00:01:47,520
DARPA

39
00:01:48,032 --> 00:01:50,592
And I'm referring here to the naming

40
00:01:50,848 --> 00:01:51,360
I love you words

41
00:01:52,896 --> 00:01:59,040
Tell us a little better so my wife is also a scientist so we had a rather long and lengthy discussion about name

42
00:01:59,296 --> 00:02:00,576
Algorithms and how you

43
00:02:00,832 --> 00:02:02,368
Depending on the gender of a child you make

44
00:02:02,624 --> 00:02:04,928
What are consonants you might want to talk valve

45
00:02:05,440 --> 00:02:06,976
And then we also being scientist

46
00:02:07,232 --> 00:02:08,512
Started to think about names

47
00:02:09,280 --> 00:02:10,048
The scientist

48
00:02:10,304 --> 00:02:12,608
Maybe match some of those criteria soap

49
00:02:13,376 --> 00:02:18,752
We named our children Tesla in Ferriday and we thought very hard about that because it's pretty nerdy

50
00:02:19,264 --> 00:02:22,592
And we want to be able to also call them Tess and Farah

51
00:02:22,848 --> 00:02:24,384
Should they want to tone it down a little

52
00:02:25,152 --> 00:02:31,296
And just how have your daughters responded to having such unusual names like they've loved it I mean we made a point

53
00:02:31,552 --> 00:02:37,696
End up going to the Royal Society in London with Faraday where they have much of Faraday's Regional Lab

54
00:02:37,952 --> 00:02:40,000
Put Menthol in a really nice small

55
00:02:40,512 --> 00:02:41,792
Not very busy Museum

56
00:02:42,304 --> 00:02:43,072
It's been a lot of fun

57
00:02:43,328 --> 00:02:46,400
So I don't get an opportunity there to tell the curator

58
00:02:46,656 --> 00:02:52,800
Is very positive LOL sometimes

59
00:02:53,056 --> 00:02:55,104
Tesla that we do get asked about the rock band

60
00:02:55,360 --> 00:02:58,944
And occasionally about there's I don't know you may have heard there's a car company

61
00:03:00,224 --> 00:03:03,296
Important part of that story of courses who was Nikola Tesla's

62
00:03:03,552 --> 00:03:04,064
Hero

63
00:03:05,088 --> 00:03:06,112
And Michael Faraday

64
00:03:07,648 --> 00:03:08,416
Beautiful connection

65
00:03:08,928 --> 00:03:11,744
So I have to say that's quirky but I say that with great affection

66
00:03:12,000 --> 00:03:15,328
It's a it's a sure sign of your motion to science

67
00:03:15,584 --> 00:03:17,632
So what's actually not talk about

68
00:03:17,888 --> 00:03:20,448
Your background I mentioned the degrees that you had gotten

69
00:03:20,960 --> 00:03:24,288
Would like to hear about that those interested in how you ended up at

70
00:03:24,544 --> 00:03:25,056
Actually

71
00:03:25,568 --> 00:03:26,080
Getting in

72
00:03:26,336 --> 00:03:26,848
Opportunity to work here

73
00:03:27,616 --> 00:03:31,200
Wow yeah so I'll go I'll go way back to

74
00:03:31,456 --> 00:03:32,224
The Apple II Plus

75
00:03:32,992 --> 00:03:37,600
And my father with some sort of give us a date point on 1979

76
00:03:38,112 --> 00:03:42,976
Father with with some great insights and no personal computers we need these in our house

77
00:03:43,488 --> 00:03:44,000
And

78
00:03:44,512 --> 00:03:49,888
I don't know if you work all these old magazines like bite magazine you would type in

79
00:03:50,144 --> 00:03:51,424
Programs in which type in

80
00:03:51,680 --> 00:03:52,192
Computer games

81
00:03:53,216 --> 00:03:55,776
And I said that I said Dad I want to make my own computer

82
00:03:56,288 --> 00:03:56,800
And he said

83
00:03:57,056 --> 00:03:58,080
Here's the manual sun

84
00:03:58,336 --> 00:03:59,616
Plugs it in front of me

85
00:04:00,128 --> 00:04:01,152
And next thing you know ice

86
00:04:01,664 --> 00:04:02,176
Programming

87
00:04:02,432 --> 00:04:04,224
I started to fall in love with computers

88
00:04:05,248 --> 00:04:06,784
Later once I got to

89
00:04:07,552 --> 00:04:12,672
Undergraduate I'm sitting there I was fortunate to overlap with my sister at the same University

90
00:04:13,184 --> 00:04:15,488
She was studying cognitive science this is amazing

91
00:04:15,744 --> 00:04:16,512
How people think

92
00:04:16,768 --> 00:04:18,815
How they behave what are the motivations for

93
00:04:19,071 --> 00:04:20,863
That's fascinating that's what I want to study

94
00:04:21,375 --> 00:04:24,959
And she looked at me and in a way that holding older sister can instead

95
00:04:25,215 --> 00:04:25,727
Jonathan

96
00:04:26,239 --> 00:04:27,519
You don't do computer science

97
00:04:28,031 --> 00:04:29,311
You're crazy so I did both

98
00:04:29,567 --> 00:04:30,847
And that's been my career

99
00:04:31,359 --> 00:04:32,639
DARPA

100
00:04:32,895 --> 00:04:34,687
Did you know about it and seek it out

101
00:04:34,943 --> 00:04:35,711
DARPA

102
00:04:35,967 --> 00:04:37,247
Such an amazing place

103
00:04:37,503 --> 00:04:40,063
That it's hard when you're in a

104
00:04:40,319 --> 00:04:44,159
Field doing research and development and leading other people and doing it

105
00:04:44,415 --> 00:04:48,511
Do not know about DARPA to not know about the amazing things that DARPA has done

106
00:04:48,767 --> 00:04:52,095
So for me it was it was very natural to say

107
00:04:52,607 --> 00:04:54,143
Well I can imagine at some point

108
00:04:55,167 --> 00:04:58,239
Appropriately in my career I would love to serve at DARPA

109
00:04:58,751 --> 00:04:59,519
Expendables

110
00:04:59,775 --> 00:05:01,567
For five years of my life you're helping

111
00:05:01,823 --> 00:05:04,383
Arriving at DARPA there's a sense of

112
00:05:04,639 --> 00:05:05,663
Incredible empowerment

113
00:05:06,175 --> 00:05:09,247
That with the wherewithal that you got

114
00:05:09,503 --> 00:05:12,319
To really make some extraordinary things happen not just

115
00:05:12,831 --> 00:05:18,975
Oh I'm going to run a program but no I'm going to write a seminal book with the best people in the world I am going to

116
00:05:19,487 --> 00:05:20,511
Changeable discipline

117
00:05:20,767 --> 00:05:22,047
It's an amazing feeling

118
00:05:22,559 --> 00:05:24,607
And when you do all of that and you tie it back

119
00:05:24,863 --> 00:05:25,375
2 National

120
00:05:25,631 --> 00:05:26,399
Security +

121
00:05:26,655 --> 00:05:28,191
Feeling like you're serving your country at

122
00:05:28,447 --> 00:05:28,959
It's a great feeling

123
00:05:29,727 --> 00:05:31,263
Yeah when one of the things I find

124
00:05:31,775 --> 00:05:32,543
A most fascinating

125
00:05:32,799 --> 00:05:33,567
About DARPA

126
00:05:33,823 --> 00:05:35,615
Is the sort of melting

127
00:05:35,871 --> 00:05:38,943
Of disciplinary boundaries which is not so easy to do with many other in

128
00:05:39,199 --> 00:05:40,735
Institutions you go to a university in

129
00:05:40,991 --> 00:05:43,807
Typical you're still in the biology Department of Chemistry Department

130
00:05:44,319 --> 00:05:47,903
Here goes kind of boundary is almost irrelevant because it's much more of a

131
00:05:48,159 --> 00:05:48,671
Project

132
00:05:49,183 --> 00:05:49,951
Directed

133
00:05:50,463 --> 00:05:53,023
Approach you could you sure

134
00:05:53,279 --> 00:05:58,911
Oh yeah I mean that part of the superpowers you got us a DARPA program manager is you can you can

135
00:05:59,423 --> 00:06:00,959
Remembering my sister grabbing my ear

136
00:06:01,215 --> 00:06:01,983
You should

137
00:06:02,239 --> 00:06:08,383
Think about this other if you can grab people by the ear and go I've watched this field for in my my case 25

138
00:06:08,639 --> 00:06:09,151
Sears

139
00:06:09,407 --> 00:06:14,783
And it's absolutely ridiculous that these people aren't working together or there's a huge opportunity

140
00:06:15,039 --> 00:06:15,807
If I can bring these p

141
00:06:17,087 --> 00:06:17,855
In the right way

142
00:06:18,367 --> 00:06:19,647
And that's what we try to do

143
00:06:19,903 --> 00:06:21,439
All right so let's talk about

144
00:06:21,695 --> 00:06:23,743
How your own mindset is changing now that you

145
00:06:23,999 --> 00:06:24,767
Shakira DARPA

146
00:06:25,023 --> 00:06:27,583
And we'll move from that come into the program

147
00:06:28,863 --> 00:06:29,887
To rub up the momentum

148
00:06:30,655 --> 00:06:31,935
So you made it your mission here

149
00:06:32,191 --> 00:06:32,703
Focus on

150
00:06:33,215 --> 00:06:33,727
Hard drive

151
00:06:33,983 --> 00:06:36,799
One of them being a modeling of large-scale human behavior

152
00:06:37,311 --> 00:06:38,079
Lightweight computer

153
00:06:39,359 --> 00:06:41,151
I would like you to first talk to me about your

154
00:06:41,407 --> 00:06:42,431
Views about Aaron

155
00:06:42,687 --> 00:06:43,455
Christian connect

156
00:06:44,735 --> 00:06:46,271
Global Information environment

157
00:06:47,039 --> 00:06:48,831
And how that's guiding what

158
00:06:49,087 --> 00:06:50,623
You hope to achieve here in your tie

159
00:06:53,439 --> 00:06:57,791
I get so excited when I think about the fact that people are interacting

160
00:06:58,559 --> 00:06:59,839
Ever increasingly

161
00:07:00,095 --> 00:07:01,375
Computer-mediated fashion

162
00:07:02,655 --> 00:07:04,959
Now I have this opportunity

163
00:07:05,471 --> 00:07:09,311
Through these kind of computer-mediated interactions to study human behavior

164
00:07:09,567 --> 00:07:10,591
At a scale

165
00:07:10,847 --> 00:07:11,615
It's never been

166
00:07:11,871 --> 00:07:12,383
Done before

167
00:07:12,639 --> 00:07:13,407
And what's exciting

168
00:07:13,663 --> 00:07:18,783
People are starting to think about that world so you'll see some behavioral scientist using Mechanical Turk

169
00:07:19,039 --> 00:07:19,551
For example

170
00:07:19,807 --> 00:07:23,647
Actually most people would not know what mechanical means

171
00:07:23,903 --> 00:07:26,207
So Amazon Mechanical Turk is a

172
00:07:26,975 --> 00:07:27,999
Crowdsourced

173
00:07:28,255 --> 00:07:32,095
Platform so I could say go to Amazon Mechanical Turk and I would like

174
00:07:32,607 --> 00:07:33,375
Toupee

175
00:07:33,887 --> 00:07:34,911
200 people

176
00:07:35,167 --> 00:07:36,703
To do some simple experiment which is

177
00:07:36,959 --> 00:07:37,727
Just to say you know

178
00:07:37,983 --> 00:07:40,287
Click on this card box when you see it

179
00:07:40,543 --> 00:07:41,823
Type of experiment or

180
00:07:42,079 --> 00:07:44,895
Collaborate on a project and let me watch how you doing

181
00:07:45,151 --> 00:07:45,663
So

182
00:07:45,919 --> 00:07:47,967
In the social sciences there's been a huge uptick

183
00:07:48,223 --> 00:07:50,271
In people using this particular platform

184
00:07:50,527 --> 00:07:51,551
It's just one

185
00:07:52,063 --> 00:07:53,343
Think about the fact that

186
00:07:53,599 --> 00:07:54,623
When you call Uber

187
00:07:55,391 --> 00:07:56,671
That it has date on the drivers

188
00:07:56,927 --> 00:07:58,719
Have data on the people that are getting picked up

189
00:07:59,231 --> 00:07:59,999
Think about Facebook

190
00:08:00,511 --> 00:08:04,095
Think about the fact that they have millions and millions and millions of users

191
00:08:04,351 --> 00:08:05,119
Around the world

192
00:08:05,375 --> 00:08:07,935
Taking two interesting studies of the differences between cultures

193
00:08:08,191 --> 00:08:09,983
That we could never conceive of

194
00:08:10,751 --> 00:08:11,519
At that scale.

195
00:08:12,543 --> 00:08:15,103
It's an incredibly exciting time for the behavioral social

196
00:08:16,383 --> 00:08:18,943
Right and just one more Moment On The Mechanical Turk

197
00:08:19,199 --> 00:08:20,735
What's fascinating about you for the name of that

198
00:08:21,247 --> 00:08:22,015
What is it associate

199
00:08:22,527 --> 00:08:23,039
A famous

200
00:08:23,295 --> 00:08:23,807
Example of an

201
00:08:24,063 --> 00:08:24,575
Otamatone

202
00:08:24,831 --> 00:08:25,343
On the mechanical

203
00:08:25,599 --> 00:08:26,367
Turk with the Kinect

204
00:08:27,391 --> 00:08:30,463
I think Amazon's original Vision was

205
00:08:31,487 --> 00:08:32,767
A Mechanical Turk where

206
00:08:33,279 --> 00:08:35,583
It's not with a human inside

207
00:08:36,095 --> 00:08:39,935
Tennis with a chess-playing automaton at that

208
00:08:40,191 --> 00:08:46,335
Center of all kinds of discussions when it first came out in the University was revealed to have a few minutes so what is the

209
00:08:46,591 --> 00:08:47,615
Is that there are

210
00:08:47,871 --> 00:08:49,919
New ever-increasing opportunities

211
00:08:50,431 --> 00:08:53,503
For interacting with humans in a way that would let us understand

212
00:08:53,759 --> 00:08:55,551
Not just how they're going to act

213
00:08:55,807 --> 00:08:59,135
A particular instance but what are the the kind of causal underpinning

214
00:08:59,391 --> 00:09:00,415
Of those behave

215
00:09:00,671 --> 00:09:02,975
Why do people act in a certain way insert

216
00:09:03,231 --> 00:09:03,743
Situations

217
00:09:04,255 --> 00:09:05,023
Interesting soap

218
00:09:05,279 --> 00:09:08,095
I think that's a good segue into a discussion

219
00:09:08,351 --> 00:09:08,863
About

220
00:09:09,119 --> 00:09:10,655
The program that you have begun

221
00:09:11,423 --> 00:09:12,959
It's called the computational

222
00:09:13,215 --> 00:09:16,543
Simulation of online social behavior program

223
00:09:16,799 --> 00:09:18,335
No in a short format

224
00:09:18,591 --> 00:09:20,127
As social Sim

225
00:09:20,383 --> 00:09:21,407
You've described

226
00:09:21,663 --> 00:09:24,223
This goal as developing Innovative Technologies

227
00:09:24,479 --> 00:09:25,503
4 High Fidelity

228
00:09:25,759 --> 00:09:27,295
Computational simulation

229
00:09:27,807 --> 00:09:29,087
Of online social

230
00:09:29,855 --> 00:09:30,879
I'd like you to flush that out

231
00:09:31,903 --> 00:09:33,183
What are the things to point out

232
00:09:33,439 --> 00:09:33,951
When I

233
00:09:34,207 --> 00:09:38,559
And rattling off these opportunities about understanding human behavior is understanding human behavior is

234
00:09:38,815 --> 00:09:39,583
Hard and I

235
00:09:39,839 --> 00:09:41,375
Far from solved problem

236
00:09:41,887 --> 00:09:42,911
So

237
00:09:43,679 --> 00:09:47,007
We often joke we wish we had the easy problems like the physicists do

238
00:09:47,775 --> 00:09:49,055
Humans are tough

239
00:09:49,567 --> 00:09:55,711
So this program is a fundamental research program it's not saying we're going to successfully model human behavior

240
00:09:55,967 --> 00:09:56,479
It says

241
00:09:56,991 --> 00:10:00,319
We're going to try to start to to chew the elephant

242
00:10:00,831 --> 00:10:05,695
We're going to get our very very tiny teaspoon and start to nibble at this giant problem of

243
00:10:06,207 --> 00:10:08,255
What can we understand about Behavior

244
00:10:08,767 --> 00:10:11,583
The goal of this program is to really start to tackle

245
00:10:12,351 --> 00:10:14,911
The issue of creating valid

246
00:10:15,679 --> 00:10:17,215
Simulations are valid models

247
00:10:17,727 --> 00:10:19,007
And there's a lot of folks

248
00:10:19,263 --> 00:10:22,079
In the modeling world who will build beautiful models

249
00:10:23,103 --> 00:10:23,871
And

250
00:10:24,383 --> 00:10:27,967
Not do such a great job of proving that they are correct

251
00:10:29,247 --> 00:10:35,391
Then there's people who will go out and do behavioral experiments but then don't bother to codified that and then some sort of Pop

252
00:10:35,647 --> 00:10:36,415
Habitational represent

253
00:10:37,439 --> 00:10:41,535
How do you think about bringing all of that together in a way where you can say yes

254
00:10:41,791 --> 00:10:43,071
We built this model we built this

255
00:10:43,327 --> 00:10:44,607
Habitational simulation

256
00:10:44,863 --> 00:10:45,887
And we know

257
00:10:46,655 --> 00:10:48,191
For some circumstances

258
00:10:48,447 --> 00:10:51,519
It's it works with some level of actors we know one

259
00:10:51,775 --> 00:10:54,079
We have things that are right and when we have things that are wrong

260
00:10:54,591 --> 00:10:56,383
Right and you're bringing it again

261
00:10:56,639 --> 00:10:57,919
This massive ability

262
00:10:58,431 --> 00:10:59,199
To scale up

263
00:10:59,455 --> 00:11:00,991
I should say the scale up in a massive

264
00:11:01,503 --> 00:11:05,087
Because you will be tapping in and it sort of Mama's crowdsourcing weigh in

265
00:11:06,111 --> 00:11:07,647
By reaching out to the social

266
00:11:08,159 --> 00:11:08,671
Media channel

267
00:11:08,927 --> 00:11:10,463
Absolutely so

268
00:11:10,719 --> 00:11:11,999
One of the things that's

269
00:11:12,255 --> 00:11:15,583
Different today is this notion of scale that we

270
00:11:15,839 --> 00:11:16,607
Have all of these

271
00:11:16,863 --> 00:11:17,375
Computer-mediated

272
00:11:17,631 --> 00:11:18,143
Medication

273
00:11:18,911 --> 00:11:19,423
And

274
00:11:19,679 --> 00:11:20,959
If we can do

275
00:11:21,215 --> 00:11:22,495
All of the appropriate

276
00:11:22,751 --> 00:11:24,543
Privacy and ethical consideration

277
00:11:25,311 --> 00:11:27,359
Which is things like informed consent

278
00:11:28,127 --> 00:11:29,151
You must ask someone

279
00:11:29,663 --> 00:11:31,199
You're going to use their data

280
00:11:31,711 --> 00:11:34,271
Can we then look at this data in aggregate

281
00:11:34,783 --> 00:11:36,063
We're not talking about individuals

282
00:11:36,319 --> 00:11:36,831
Here were talking about

283
00:11:37,855 --> 00:11:39,647
@scale millions of people

284
00:11:39,903 --> 00:11:40,927
Decide

285
00:11:41,695 --> 00:11:42,463
We're going to spread

286
00:11:43,231 --> 00:11:43,999
A piece of information on

287
00:11:45,023 --> 00:11:47,839
So we're going from online social behavior

288
00:11:48,607 --> 00:11:49,375
Potentially a very big

289
00:11:49,887 --> 00:11:52,191
Phase 2 of relatively simple Behavior which is

290
00:11:53,215 --> 00:11:53,727
The spread

291
00:11:54,239 --> 00:11:54,751
That information

292
00:11:55,007 --> 00:11:56,287
So why would you

293
00:11:57,055 --> 00:11:58,335
Tell me you just saw a great movie

294
00:11:59,359 --> 00:12:00,127
What motivates

295
00:12:00,895 --> 00:12:03,455
How does that happen and can we look at the

296
00:12:03,967 --> 00:12:04,735
Various factors

297
00:12:04,991 --> 00:12:06,015
Surrounding that as a function

298
00:12:06,527 --> 00:12:07,295
Which environment are we

299
00:12:08,063 --> 00:12:09,599
Is it something that you would tweet about it

300
00:12:10,111 --> 00:12:11,135
Something you might post on Facebook

301
00:12:12,159 --> 00:12:14,207
Can we do that as a function of

302
00:12:15,487 --> 00:12:16,255
Information itself

303
00:12:16,767 --> 00:12:18,815
What kinds of information are more likely to

304
00:12:19,839 --> 00:12:22,911
And can we do that as a function of the properties of the population

305
00:12:23,935 --> 00:12:30,079
This is a population that really is very connected and likes to spread information this is a population that's more disconnected and does

306
00:12:31,871 --> 00:12:33,407
How do all those factors interact

307
00:12:33,663 --> 00:12:34,431
And how can we

308
00:12:34,687 --> 00:12:35,199
Study though

309
00:12:35,455 --> 00:12:37,759
And say what we actually know and how well we know it

310
00:12:38,527 --> 00:12:41,599
If you were trying to make this a little bit more concrete for listeners

311
00:12:41,855 --> 00:12:43,391
What kinds of questions

312
00:12:43,647 --> 00:12:44,415
How do you think

313
00:12:45,439 --> 00:12:46,975
Do you know you will be asking

314
00:12:47,231 --> 00:12:48,255
King of the researcher

315
00:12:48,511 --> 00:12:49,023
She will be working

316
00:12:49,279 --> 00:12:50,303
I'm with you on this social Sim

317
00:12:50,559 --> 00:12:51,071
Program

318
00:12:51,327 --> 00:12:54,399
That's a are either relevant to National

319
00:12:54,655 --> 00:12:56,447
Security or other

320
00:12:56,703 --> 00:12:57,471
Societally important

321
00:12:57,727 --> 00:13:01,311
Yeah so I think one of the things in this program we're really focused

322
00:13:01,823 --> 00:13:02,335
On is

323
00:13:02,847 --> 00:13:04,895
Societal benefit as it relates to National

324
00:13:05,151 --> 00:13:06,943
Security so what's what's a great example of this

325
00:13:07,967 --> 00:13:09,503
US military has a mission

326
00:13:10,015 --> 00:13:11,551
Humanitarian assistance and disaster

327
00:13:12,831 --> 00:13:16,927
So when there's a tsunami or flood or a typhoon and

328
00:13:17,183 --> 00:13:19,487
Foreign country we may be asked to go help

329
00:13:19,999 --> 00:13:22,559
And one of the things we have to combat in those situations

330
00:13:22,815 --> 00:13:23,327
This is

331
00:13:23,583 --> 00:13:25,119
The spread of rumors for exam

332
00:13:25,631 --> 00:13:26,143
So

333
00:13:26,399 --> 00:13:31,519
There's a recent story about a rumor spreading that the bottled water that the US

334
00:13:31,775 --> 00:13:32,799
Military was bringing

335
00:13:33,055 --> 00:13:36,639
Was containing line controlled substances and they were going to

336
00:13:36,895 --> 00:13:38,431
Use it to control the population

337
00:13:39,199 --> 00:13:40,223
Patently false

338
00:13:40,735 --> 00:13:42,783
But it led to a lot of people getting very sick

339
00:13:43,039 --> 00:13:43,551
Because they weren't

340
00:13:43,807 --> 00:13:44,575
Drinking Safe Water

341
00:13:45,343 --> 00:13:51,487
So there's a very concrete example if we could understand why that particular message got traction why it spread the way it is

342
00:13:51,743 --> 00:13:54,559
We could maybe help a little bit better and such situations

343
00:13:55,071 --> 00:13:56,863
Now I guess moving in an in an ashen

344
00:13:57,119 --> 00:14:00,703
No security directions there's a phrase I've read maybe on your program page

345
00:14:00,959 --> 00:14:01,983
That really catches

346
00:14:02,239 --> 00:14:02,751
Mayan

347
00:14:03,519 --> 00:14:05,311
And it's resolving conflicts

348
00:14:05,567 --> 00:14:06,079
Out

349
00:14:06,335 --> 00:14:06,847
Force

350
00:14:07,359 --> 00:14:08,127
Which sounds like a

351
00:14:08,639 --> 00:14:09,663
Terrific ideal

352
00:14:10,175 --> 00:14:12,223
Talk to me a little bit about that and the relationship

353
00:14:12,479 --> 00:14:13,503
To the kind of working

354
00:14:14,271 --> 00:14:15,039
Yeah that the

355
00:14:15,295 --> 00:14:16,319
US military

356
00:14:16,575 --> 00:14:18,111
Is very very good

357
00:14:18,623 --> 00:14:19,135
At

358
00:14:20,415 --> 00:14:21,439
The kinetic

359
00:14:21,951 --> 00:14:23,487
Parts of operation

360
00:14:23,999 --> 00:14:26,303
In fact arguably without peer in many ways

361
00:14:26,815 --> 00:14:28,095
And I just want to point out for listener

362
00:14:28,607 --> 00:14:33,727
A bikenetic that means things that are moving and you can think of it as metal moving through air

363
00:14:33,983 --> 00:14:34,495
Among other things

364
00:14:35,519 --> 00:14:40,127
The military also tries to think about operations other than War

365
00:14:40,639 --> 00:14:41,151
So

366
00:14:41,407 --> 00:14:43,711
When we get into these humanitarian assistance

367
00:14:43,967 --> 00:14:46,271
Situations or we are trying to

368
00:14:46,783 --> 00:14:47,807
Advise

369
00:14:48,063 --> 00:14:48,575
Local Force

370
00:14:49,343 --> 00:14:50,623
About what's going on

371
00:14:50,879 --> 00:14:53,183
There's a lot of opportunity for us to make

372
00:14:53,439 --> 00:14:54,207
Huge difference

373
00:14:54,719 --> 00:14:55,231
Without

374
00:14:55,743 --> 00:14:58,047
Metal moving through air to use your phrase

375
00:14:58,303 --> 00:15:00,863
That seems like a very very Noble goal

376
00:15:01,119 --> 00:15:05,983
To me I want that I get very passionate about anytime you can save lives without

377
00:15:06,239 --> 00:15:07,007
Having two

378
00:15:07,263 --> 00:15:09,055
Be aggressive I think that's important

379
00:15:09,823 --> 00:15:10,335
This

380
00:15:10,847 --> 00:15:12,383
Makes me understand a little bit more

381
00:15:12,639 --> 00:15:13,919
About you and your passion for wanted

382
00:15:14,175 --> 00:15:14,687
Come here

383
00:15:15,199 --> 00:15:17,247
And having you have some sense that it

384
00:15:17,503 --> 00:15:18,783
Is possible for you too

385
00:15:19,039 --> 00:15:21,087
Move the the actual sort of

386
00:15:21,343 --> 00:15:26,975
Practice of warfare away from a kinetic and and bloody one into something that we're we're again,

387
00:15:27,231 --> 00:15:27,743
What's the result

388
00:15:28,767 --> 00:15:29,279
Forsen

389
00:15:29,791 --> 00:15:30,559
And what comes with it

390
00:15:31,071 --> 00:15:34,655
It's hard to not come into work in the morning and be passionate about

391
00:15:35,423 --> 00:15:35,935
That kind of

392
00:15:36,191 --> 00:15:42,335
That kind of statement okay course nothing is easy so the kinds of research that you were doing and which you were you're scaling

393
00:15:42,591 --> 00:15:44,127
Hang up your looking at a massive amount

394
00:15:44,895 --> 00:15:45,919
Social behavior

395
00:15:46,175 --> 00:15:48,479
By way of social media so this is where people

396
00:15:48,735 --> 00:15:50,271
Are revealing things about the moon

397
00:15:50,527 --> 00:15:52,831
Their ethics issues including privacy

398
00:15:53,087 --> 00:15:58,463
So how are you thinking about those issues as you move forward in your program

399
00:15:59,231 --> 00:15:59,743
There

400
00:15:59,999 --> 00:16:02,815
Front and center at a level that I don't know that it's been pushed

401
00:16:03,071 --> 00:16:05,119
So far in front and I'll tell you why

402
00:16:05,631 --> 00:16:06,143
When you

403
00:16:06,399 --> 00:16:07,679
Study the behavioral sciences

404
00:16:07,935 --> 00:16:10,751
And you go through here's how to do human behavior experiment

405
00:16:11,007 --> 00:16:14,079
I keep thinking about Bill Murray in Ghostbusters

406
00:16:14,847 --> 00:16:16,639
Where he's doing the the shock test

407
00:16:17,151 --> 00:16:19,199
With the to see if people have ESP or not

408
00:16:19,455 --> 00:16:22,015
He's breaking every ethical rule there is

409
00:16:22,271 --> 00:16:24,319
That was very humorous but

410
00:16:24,831 --> 00:16:27,391
When you do behavioral experiments you you have to get

411
00:16:27,647 --> 00:16:33,791
Informed consent and that means you have to have someone opt into doing this you have to show that there's minimal rescue

412
00:16:34,047 --> 00:16:35,071
You have to go through

413
00:16:35,327 --> 00:16:36,863
As a behavioral scientist I'm like

414
00:16:37,119 --> 00:16:37,631
Okay

415
00:16:37,887 --> 00:16:39,423
Now if you turn to the computer scientist

416
00:16:39,679 --> 00:16:40,191
Westworld

417
00:16:40,959 --> 00:16:42,495
They don't but there's just data

418
00:16:43,007 --> 00:16:47,359
Thursday. They're like a whip there's data that's about human beings or coming from

419
00:16:48,383 --> 00:16:50,943
And therefore privacy protections are

420
00:16:51,199 --> 00:16:51,711
Paramount

421
00:16:52,991 --> 00:16:55,807
A fun fact I don't know if you know this but if

422
00:16:56,319 --> 00:17:00,671
You look at what is in this end-user license agreements that you click through without reading

423
00:17:01,695 --> 00:17:03,743
There are things in there that give companies

424
00:17:03,999 --> 00:17:07,583
This notion of informed consent to mess with your date I never read

425
00:17:08,863 --> 00:17:12,191
That's where we need to provide some leadership we need to say yes if

426
00:17:12,447 --> 00:17:15,519
We're interested in people's data and we want to understand Behavior

427
00:17:15,775 --> 00:17:16,799
And we want to do the science

428
00:17:17,055 --> 00:17:18,335
Of of behavior

429
00:17:18,847 --> 00:17:20,127
We have to respect that from you

430
00:17:21,151 --> 00:17:23,455
So we've already run privacy and ethics Workshop

431
00:17:23,967 --> 00:17:25,247
We have

432
00:17:25,503 --> 00:17:27,295
External privacy Consultants that we work with

433
00:17:27,551 --> 00:17:29,855
Other programs that are for that are focused on

434
00:17:30,111 --> 00:17:31,391
Making sure we address privacy

435
00:17:32,671 --> 00:17:35,231
It's interesting to DARPA is known for

436
00:17:35,487 --> 00:17:41,119
Breakthroughs in technology but it almost sounds to me like you might be moving toward some new territory even when it comes to

437
00:17:41,375 --> 00:17:44,191
Consenting and these kinds of privacy and ethics issue

438
00:17:44,447 --> 00:17:47,263
Absolutely I do know art director has said

439
00:17:48,287 --> 00:17:52,383
It's not just our responsibility to prevent or anticipate strategic surprise

440
00:17:52,639 --> 00:17:53,919
From a technology standpoint

441
00:17:54,431 --> 00:17:58,015
But also from how we actually conduct the research and development that gets us.

442
00:18:00,063 --> 00:18:03,391
I want to just talk a little bit more about social semi but I'd like you to do

443
00:18:03,647 --> 00:18:05,695
Jonathan is is give us a service status

444
00:18:06,463 --> 00:18:09,023
Where is this program at in its life cycle

445
00:18:09,791 --> 00:18:10,303
And I'm going to

446
00:18:10,815 --> 00:18:11,327
Askew

447
00:18:11,583 --> 00:18:12,351
To get utopian

448
00:18:12,607 --> 00:18:13,375
Imagine

449
00:18:13,631 --> 00:18:14,399
The best success

450
00:18:14,911 --> 00:18:16,191
So you can imagine what the program but so

451
00:18:16,447 --> 00:18:17,471
First to satisfy

452
00:18:17,983 --> 00:18:19,775
We have completed

453
00:18:20,031 --> 00:18:22,591
Source selection which is to say we received a number of

454
00:18:22,847 --> 00:18:24,127
Pretty amazing proposals

455
00:18:24,383 --> 00:18:26,175
So now we go into the process of

456
00:18:26,431 --> 00:18:27,199
Forgetting those folks

457
00:18:27,455 --> 00:18:28,223
Under contract

458
00:18:28,735 --> 00:18:30,015
And getting the program

459
00:18:30,271 --> 00:18:31,039
Off the ground

460
00:18:31,295 --> 00:18:34,367
And then as it gets off the ground and over the next couple of years

461
00:18:34,623 --> 00:18:37,695
You're as we call our R&D Partners performers

462
00:18:37,951 --> 00:18:38,463
DARPA

463
00:18:38,975 --> 00:18:45,119
What is your what do you hope in several years when you bring the performers together and then you're you're having a

464
00:18:45,375 --> 00:18:47,167
In a moment of Celebration that the

465
00:18:47,423 --> 00:18:49,215
Program is completed what do you help with

466
00:18:49,471 --> 00:18:51,007
Be the payoff the deliverable

467
00:18:51,519 --> 00:18:57,663
A fuel changer is a changing the way this kind of research and development is done I don't think we are going to end up with

468
00:18:58,687 --> 00:19:03,039
Here is a correct model of how information spread I think what we're going to end up with

469
00:19:03,295 --> 00:19:04,831
Is a research community that

470
00:19:05,087 --> 00:19:08,927
Much More rigorously Much More scientifically

471
00:19:09,439 --> 00:19:09,951
Conduct

472
00:19:10,463 --> 00:19:12,511
The process of building these kinds of mod

473
00:19:13,279 --> 00:19:15,583
And everybody moves forward from that point out

474
00:19:15,839 --> 00:19:17,119
To the huge

475
00:19:17,631 --> 00:19:21,471
Massive possibly unbounded space of understanding human behavior

476
00:19:21,727 --> 00:19:25,567
Right and one of the things that's really fascinating about human behavior and I think how your

477
00:19:26,079 --> 00:19:27,359
Treatment program in thinking about it

478
00:19:27,615 --> 00:19:29,407
Is that social structures are

479
00:19:29,663 --> 00:19:33,503
Hierarchical wewe U&I Jonathan right now we are having a conversation this

480
00:19:33,759 --> 00:19:34,271
What's a social structure

481
00:19:34,783 --> 00:19:40,159
To Ben our audio engineer is with us so there's three people in our social structure in the studio

482
00:19:40,415 --> 00:19:46,559
But go up from there at Unity so because we didn't go to neighborhoods we go to cities we go

483
00:19:46,815 --> 00:19:51,935
All the way up to a global Community right so

484
00:19:52,959 --> 00:19:54,495
So there are

485
00:19:54,751 --> 00:20:00,895
You are in one neighborhood you're also in a town it's not necessarily all hierarchical cuz you also maybe in the group of

486
00:20:01,151 --> 00:20:06,783
Fathers you may be in the group of Americans you may be in the group of people that live on streets called

487
00:20:07,039 --> 00:20:07,807
Edison Street

488
00:20:08,319 --> 00:20:10,111
And when you think about those different

489
00:20:10,623 --> 00:20:11,391
Categorization

490
00:20:11,903 --> 00:20:13,951
What can you learn

491
00:20:14,207 --> 00:20:16,767
Apart from in the social behavior of each of those

492
00:20:17,023 --> 00:20:22,399
And that's one of the interesting challenges worth for trying to think about in the program is out of those different

493
00:20:22,911 --> 00:20:27,263
Let's call them resolutions are scales at which we can consider Behavior overlap and interact

494
00:20:28,287 --> 00:20:29,823
So how does your

495
00:20:30,079 --> 00:20:31,615
Identity as

496
00:20:32,127 --> 00:20:35,455
Bother overlap with your identity as an American

497
00:20:35,711 --> 00:20:36,735
Overlap with

498
00:20:37,247 --> 00:20:38,783
Your identity is in your age group

499
00:20:39,039 --> 00:20:39,551
For example

500
00:20:40,319 --> 00:20:44,415
So they overlap they interact they may dominate in different situations

501
00:20:44,671 --> 00:20:45,695
How to lose

502
00:20:45,951 --> 00:20:51,583
How does operate how do we understand a small organization differently than we understand whole region of people

503
00:20:51,839 --> 00:20:55,167
So are you in another interesting thing at DARPA is that so often

504
00:20:55,423 --> 00:20:56,447
The Technologies

505
00:20:56,703 --> 00:20:57,727
Is that program a turtle

506
00:20:57,983 --> 00:20:58,495
Are working on

507
00:20:59,007 --> 00:21:02,591
Are powerful enough that they have tremendous promise

508
00:21:03,615 --> 00:21:06,431
But also some potential peril

509
00:21:06,687 --> 00:21:10,015
You don't need some interested in your view of

510
00:21:10,271 --> 00:21:15,135
Again getting utopian if your program really succeeds we develop new ways of understanding

511
00:21:15,391 --> 00:21:16,672
Social behavior

512
00:21:17,184 --> 00:21:18,976
A scale that we've never

513
00:21:19,488 --> 00:21:20,000
I had to

514
00:21:20,256 --> 00:21:20,768
The kind of access

515
00:21:21,280 --> 00:21:21,792
Work

516
00:21:22,048 --> 00:21:25,120
What excites you most about that kind of NuWave understanding and

517
00:21:25,376 --> 00:21:27,168
When you think about it what kind of gives you

518
00:21:27,424 --> 00:21:28,960
Some parts I get

519
00:21:29,216 --> 00:21:31,008
Very excited about the societal benefits

520
00:21:31,776 --> 00:21:33,056
I got excited about

521
00:21:33,568 --> 00:21:38,432
Making sure people get vaccinated appropriately making sure people get appropriate Healthcare

522
00:21:38,688 --> 00:21:42,272
That during crises that were able to guide people in an appropriate way

523
00:21:42,784 --> 00:21:46,624
I feel very strongly that those are the really beneficial aspects

524
00:21:47,136 --> 00:21:47,904
But there's a darker

525
00:21:48,160 --> 00:21:49,184
Side to it as well

526
00:21:49,952 --> 00:21:54,560
Which is I want to be prepared if other nations governments

527
00:21:54,816 --> 00:21:55,328
Groups

528
00:21:55,840 --> 00:21:56,864
Decide to

529
00:21:57,376 --> 00:21:58,656
Spread information that isn't

530
00:21:58,912 --> 00:21:59,424
So correct

531
00:22:00,192 --> 00:22:01,216
And what do we do about that

532
00:22:02,752 --> 00:22:05,312
I like to think about an income of 3 boxes

533
00:22:05,824 --> 00:22:08,128
There's what is the US government going to do

534
00:22:08,384 --> 00:22:10,688
We have a lot of laws regulate

535
00:22:10,944 --> 00:22:13,504
Patients that are very specific about how we communicate

536
00:22:13,760 --> 00:22:17,600
Boats with our population in foreign populations the same as these kinds of privacy in ethics

537
00:22:19,904 --> 00:22:20,416
We also have

538
00:22:20,672 --> 00:22:21,440
American corporation

539
00:22:22,208 --> 00:22:23,232
That may have different rules

540
00:22:23,488 --> 00:22:26,048
They may have got you to click on that end user license agreement

541
00:22:26,304 --> 00:22:27,072
And then we have

542
00:22:27,328 --> 00:22:28,352
Other folks in the world

543
00:22:28,608 --> 00:22:34,240
That have very different perspectives on how you might use these kinds of models of social behavior so

544
00:22:34,496 --> 00:22:36,544
Perhaps there's an oppressive regime

545
00:22:37,056 --> 00:22:39,616
Perhaps there's a terrorist organization

546
00:22:39,872 --> 00:22:41,152
That I want understand

547
00:22:41,408 --> 00:22:45,504
How they're pushing out their messages and how they're creating influence in a way that

548
00:22:46,016 --> 00:22:47,296
I don't think any of us wants

549
00:22:47,552 --> 00:22:50,624
Right now another thing then came in another conversation that you and I

550
00:22:51,392 --> 00:22:55,232
The pad in which you kind of revealed to me that not only are you thinking about

551
00:22:55,488 --> 00:22:56,256
Really large

552
00:22:56,512 --> 00:22:57,792
Scales but you're also

553
00:22:58,048 --> 00:22:58,560
Thinking in

554
00:22:58,816 --> 00:23:00,096
In terms of the smaller

555
00:23:00,352 --> 00:23:01,120
Are scales let's say in

556
00:23:01,376 --> 00:23:02,144
In family units

557
00:23:02,400 --> 00:23:06,240
And the way our relationships information

558
00:23:06,496 --> 00:23:07,264
Technologies

559
00:23:07,520 --> 00:23:09,312
Changing the way we relate to

560
00:23:09,568 --> 00:23:12,640
Each other and to our machine so I'm referring to

561
00:23:12,896 --> 00:23:16,992
The issue of politeness that you're and you have a little bit of a sample

562
00:23:17,248 --> 00:23:20,064
Right in your household tell me a little bit of the story what's your

563
00:23:20,576 --> 00:23:22,624
Observing about how

564
00:23:22,880 --> 00:23:23,392
Children

565
00:23:23,904 --> 00:23:24,928
Relate to machines now

566
00:23:25,440 --> 00:23:26,720
This actually motivated some

567
00:23:26,976 --> 00:23:28,000
Some work that were funding

568
00:23:28,512 --> 00:23:30,816
With my children we have

569
00:23:31,072 --> 00:23:32,864
Alexa and Amazon Echo in our

570
00:23:33,632 --> 00:23:34,656
They liked it

571
00:23:35,680 --> 00:23:36,192
4 jokes

572
00:23:36,704 --> 00:23:38,752
I also like to ask fun questions like

573
00:23:39,264 --> 00:23:41,824
Alexa what's the smallest thing in it in the universe

574
00:23:42,592 --> 00:23:43,104
Alexa

575
00:23:44,896 --> 00:23:45,920
Which is pretty cool

576
00:23:46,432 --> 00:23:48,480
Don't say Alexa play music

577
00:23:48,736 --> 00:23:50,016
And then they'll say Dad

578
00:23:50,272 --> 00:23:51,040
Get me some juice

579
00:23:52,320 --> 00:23:52,832
MSA

580
00:23:53,088 --> 00:23:53,856
Wait a second

581
00:23:54,624 --> 00:23:57,440
That's not quite how you should speak to your father shouldn't you say

582
00:23:57,696 --> 00:23:58,208
Please

583
00:23:58,976 --> 00:24:04,096
And that led me to think quite a bit about etiquette and there's actually sociological models of etiquette

584
00:24:04,608 --> 00:24:07,680
That describe where and how we use

585
00:24:07,936 --> 00:24:09,216
Phrases like please and thank you

586
00:24:10,496 --> 00:24:14,080
And to me this is a very natural place to go when you think about

587
00:24:14,336 --> 00:24:16,128
Depression spreading why does affirmations

588
00:24:16,384 --> 00:24:17,664
How did those please

589
00:24:17,920 --> 00:24:18,432
Thank you

590
00:24:18,944 --> 00:24:20,224
Help or hinder

591
00:24:20,736 --> 00:24:22,528
The information may may spread

592
00:24:23,296 --> 00:24:23,808
Are you

593
00:24:24,064 --> 00:24:27,648
Asking your daughters to be polite with Alexa

594
00:24:28,160 --> 00:24:32,768
No I haven't but it raises a whole nother conversation about how we interact with

595
00:24:33,280 --> 00:24:33,792
Machines

596
00:24:34,304 --> 00:24:37,376
And do we see machines in the future as

597
00:24:37,888 --> 00:24:38,656
Partners

598
00:24:39,424 --> 00:24:39,936
Teammates

599
00:24:40,448 --> 00:24:41,472
Where do we see them at school

600
00:24:42,240 --> 00:24:44,032
And if we ever want to move beyond that

601
00:24:44,288 --> 00:24:45,568
New Submachine says tools

602
00:24:45,824 --> 00:24:48,128
We have to think about some of these sociological

603
00:24:48,384 --> 00:24:49,920
Principles of how we interact

604
00:24:50,688 --> 00:24:53,248
Okay so that actually gets to

605
00:24:53,504 --> 00:24:54,272
Another question

606
00:24:55,552 --> 00:24:56,320
A big one that I wanted

607
00:24:56,576 --> 00:24:57,088
To ask of you

608
00:24:57,344 --> 00:24:57,856
So you're talking about

609
00:24:58,624 --> 00:25:01,952
How machines kind of our evolving along with us and

610
00:25:02,208 --> 00:25:02,976
When I think about

611
00:25:03,488 --> 00:25:04,512
Robots

612
00:25:04,768 --> 00:25:06,304
And artificial intelligence annies

613
00:25:06,560 --> 00:25:07,328
Kinds of convergence

614
00:25:07,840 --> 00:25:11,168
Coming together yeah there are discussions out there about what happens

615
00:25:11,680 --> 00:25:12,704
If we

616
00:25:12,960 --> 00:25:14,240
Develop artificial intelligence

617
00:25:14,496 --> 00:25:16,544
Tools we develop robots where are we

618
00:25:16,800 --> 00:25:19,616
Almost want to say or we do want to say

619
00:25:20,384 --> 00:25:21,664
These are new types of

620
00:25:22,688 --> 00:25:23,200
Being

621
00:25:23,712 --> 00:25:25,760
Ethics comes in here in a huge way

622
00:25:26,272 --> 00:25:29,344
If this is the case and it was never going to be thinking about machines

623
00:25:29,856 --> 00:25:30,368
Do we have to

624
00:25:30,624 --> 00:25:32,672
Think about what their rights are

625
00:25:33,184 --> 00:25:36,512
I know you think about this a lot and I want you to

626
00:25:36,768 --> 00:25:38,816
Tell me and our listeners how you are thinking about

627
00:25:39,072 --> 00:25:43,168
Sure so let me just back up from the notion of Consciousness first

628
00:25:43,424 --> 00:25:44,704
And let's talk about emerging

629
00:25:45,472 --> 00:25:50,080
Emergence is a kind of fun word because if you start thinking about a society Society

630
00:25:50,848 --> 00:25:53,408
Is something that comes out of a bunch of individual

631
00:25:54,176 --> 00:25:56,224
Pretty interesting that something that

632
00:25:56,480 --> 00:25:58,528
Is it planned for can can appear almost

633
00:25:58,784 --> 00:26:00,576
What does a surprise that we have this

634
00:26:00,832 --> 00:26:05,184
Organized Society in the physics world or the chemistry world I should say the properties of water

635
00:26:05,440 --> 00:26:06,208
Emerge

636
00:26:06,720 --> 00:26:10,560
Out of hydrogen and oxygen both of them gases in

637
00:26:10,816 --> 00:26:11,840
Normal conditions

638
00:26:12,096 --> 00:26:15,936
Neither of those has properties of water but when then combined in a chemical reaction

639
00:26:16,192 --> 00:26:17,728
The Forum water then you have the emergency

640
00:26:18,752 --> 00:26:19,264
I just want to

641
00:26:19,776 --> 00:26:25,920
Connect what you're saying emergence in social structures actually has a kind of correlating absolutely and if you go to termite

642
00:26:26,176 --> 00:26:28,736
Mounds and you go to ant colonies you see this

643
00:26:28,992 --> 00:26:29,504
Yeast

644
00:26:30,016 --> 00:26:32,064
CDs amazing emergency

645
00:26:32,320 --> 00:26:32,832
Properties

646
00:26:33,344 --> 00:26:35,648
It leads us to ask questions about

647
00:26:35,904 --> 00:26:36,672
Artificial intelligence

648
00:26:37,440 --> 00:26:39,232
And it leads us down a path

649
00:26:39,488 --> 00:26:40,256
2

650
00:26:40,512 --> 00:26:42,816
Looking where there have been emergent

651
00:26:43,072 --> 00:26:46,656
Interaction so if you follow the notion of flash crashes

652
00:26:46,912 --> 00:26:47,424
On Wall Street

653
00:26:48,192 --> 00:26:49,984
You have automated trading system

654
00:26:50,752 --> 00:26:51,776
Operating an a

655
00:26:52,032 --> 00:26:53,056
Regulated environment

656
00:26:53,568 --> 00:26:54,592
Competitively

657
00:26:55,104 --> 00:26:55,616
End

658
00:26:56,128 --> 00:26:58,432
Occasionally they interact in a way that's

659
00:26:59,200 --> 00:27:00,480
So we have to ask yourself

660
00:27:00,736 --> 00:27:01,504
If we're being honest

661
00:27:01,760 --> 00:27:04,064
Way to say we can't always anticipate all of these

662
00:27:05,088 --> 00:27:08,928
So with all of the discussion today that you hear about safe AI

663
00:27:09,440 --> 00:27:11,232
DARPA I think needs to be thinking

664
00:27:12,256 --> 00:27:12,768
10 years old

665
00:27:13,280 --> 00:27:14,048
50 years out

666
00:27:14,560 --> 00:27:15,072
Sing

667
00:27:15,328 --> 00:27:18,144
What if there's something more than simply safety that we need to

668
00:27:19,680 --> 00:27:25,312
All right we'll Jonathan I'm glad that we have a program manager like yourself was thinking about these things as we all

669
00:27:25,568 --> 00:27:26,080
Go off

670
00:27:26,336 --> 00:27:29,408
But without knowing how the future can unfold in an hour

671
00:27:29,920 --> 00:27:33,248
New interactions with the massive amount of people in massive

672
00:27:33,504 --> 00:27:34,016
Machinist

673
00:27:34,784 --> 00:27:36,320
You're so so you're asking really fast

674
00:27:36,576 --> 00:27:40,160
Fascinating questions this conversation has just been fantastic and I want

675
00:27:40,416 --> 00:27:41,696
Thank you for Assurance and

676
00:27:42,464 --> 00:27:44,000
Of course I'm happy to share

677
00:27:44,512 --> 00:27:47,328
And thanks listeners for sharing your time with us

678
00:27:47,584 --> 00:27:49,632
I hope you join us again for the next

679
00:27:49,888 --> 00:27:50,912
Voices from DARPA

680
00:27:53,984 --> 00:27:56,032
For more information about Jonathan Fouts

681
00:27:56,288 --> 00:28:00,640
Is social Sim program and the other breakthrough Technologies DARPA is working on

682
00:28:00,896 --> 00:28:02,432
Visit DARPA. Mill

683
00:28:05,248 --> 00:28:08,064
And four links that enable you to download this podcast

684
00:28:08,320 --> 00:28:10,880
Go to the voices from DARPA page on dark web
