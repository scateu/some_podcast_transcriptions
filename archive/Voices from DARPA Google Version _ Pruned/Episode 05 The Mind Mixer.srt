1
00:00:07,168 --> 00:00:13,312
Dell Technologies the internet

2
00:00:13,568 --> 00:00:17,920
In the palm of your hand operation

3
00:00:18,176 --> 00:00:20,480
Technology is a driver of our time

4
00:00:21,248 --> 00:00:24,832
Since its founding in 1958 in the midst of the Cold War DARPA

5
00:00:25,088 --> 00:00:26,368
The defense Advanced research

6
00:00:26,624 --> 00:00:27,392
Projects agency

7
00:00:27,648 --> 00:00:28,416
Has been a driver of

8
00:00:29,952 --> 00:00:32,000
Welcome to voices from DARPA

9
00:00:32,256 --> 00:00:33,536
A window Into Darkness

10
00:00:33,792 --> 00:00:35,072
Program manager

11
00:00:35,584 --> 00:00:36,352
Their job

12
00:00:36,608 --> 00:00:38,400
To redefine what is possum

13
00:00:39,168 --> 00:00:41,728
My name is Ivan Amato and I'm your DARPA host

14
00:00:41,984 --> 00:00:44,544
And today I'm pleased to have with me in the studio

15
00:00:44,800 --> 00:00:45,568
Paul Cohen

16
00:00:45,824 --> 00:00:50,432
Program manager since 2013 in darkness information Innovation office

17
00:00:50,688 --> 00:00:52,480
Which is also known here as i-200

18
00:00:52,992 --> 00:00:55,552
There he oversees projects with names like

19
00:00:55,808 --> 00:00:58,368
Big mechanism and communicating with computers

20
00:00:58,624 --> 00:01:02,976
That are all about helping our all-too-human brand of intelligence

21
00:01:03,488 --> 00:01:04,000
Collaborate

22
00:01:04,256 --> 00:01:05,280
Woody merging

23
00:01:05,536 --> 00:01:06,816
Computer-based artificial

24
00:01:08,096 --> 00:01:10,912
It's a scene with deep roots at DARPA spanning back deck

25
00:01:11,936 --> 00:01:13,728
So thanks Paul for spending some time with me today

26
00:01:14,496 --> 00:01:15,264
Thanks very much I have

27
00:01:15,776 --> 00:01:21,920
To give him the project you're overseeing here and which we will talk about in just a little bit I'm intrigued by several ass

28
00:01:22,176 --> 00:01:23,200
Aspects of your background

29
00:01:23,456 --> 00:01:26,016
If you can talk a little bit about those and do they really come to mind

30
00:01:26,272 --> 00:01:30,112
And I'm all that you have a degree that combines psychology income

31
00:01:30,368 --> 00:01:33,184
Computer science is not a degree in computer science is not a degree in Psych

32
00:01:33,440 --> 00:01:33,952
Psychology but it's

33
00:01:34,464 --> 00:01:35,232
Find Lowe's

34
00:01:35,744 --> 00:01:40,608
And I'm also intrigued by your father who I'm sorry to acknowledge

35
00:01:41,120 --> 00:01:42,144
Passed away just a few months ago

36
00:01:43,424 --> 00:01:45,472
She also pushed in Blurred the boundaries

37
00:01:45,728 --> 00:01:46,240
Between

38
00:01:46,496 --> 00:01:50,080
Humans and machines in his case in the realm of Art

39
00:01:50,592 --> 00:01:54,688
I'm hoping that you can talk about those two things in other aspects of your background

40
00:01:54,944 --> 00:02:00,576
That would help us understand how it is that you ended up here at DARPA and why you are pursuing the sorts of projects

41
00:02:00,832 --> 00:02:01,344
Since you are here

42
00:02:02,112 --> 00:02:02,880
Yeah well

43
00:02:03,136 --> 00:02:06,464
Thanks for bringing up my dad he was in many ways

44
00:02:06,720 --> 00:02:08,000
Inspiration

45
00:02:08,256 --> 00:02:08,768
Tumi

46
00:02:09,024 --> 00:02:11,072
Think back to the

47
00:02:11,328 --> 00:02:12,608
1970s

48
00:02:13,376 --> 00:02:14,400
When

49
00:02:14,656 --> 00:02:19,776
Not everyone had a computer there weren't laptops there wasn't an internet some people had computers

50
00:02:20,288 --> 00:02:21,312
I'm computing

51
00:02:22,336 --> 00:02:22,848
Was

52
00:02:23,872 --> 00:02:26,432
I thought points of the metaphor of our times

53
00:02:27,200 --> 00:02:31,808
Just a steam engines and electricity and other technology it's would have captured

54
00:02:32,576 --> 00:02:34,112
The imaginations

55
00:02:34,880 --> 00:02:37,696
Scientists and Poets throughout history

56
00:02:37,952 --> 00:02:38,976
The computer

57
00:02:39,488 --> 00:02:40,512
Took on that room

58
00:02:41,536 --> 00:02:43,072
And many people

59
00:02:43,840 --> 00:02:44,864
Certainly my dad

60
00:02:45,376 --> 00:02:46,400
Later me

61
00:02:47,168 --> 00:02:48,960
Started to think of the computer

62
00:02:49,472 --> 00:02:51,776
Has a way of thinking about

63
00:02:52,288 --> 00:02:53,824
Other things how to make art

64
00:02:54,080 --> 00:02:54,848
How the mind works

65
00:02:55,616 --> 00:02:57,664
We started to think we'll maybe it's a computer

66
00:02:57,920 --> 00:03:01,504
Or maybe computational processes could do those things

67
00:03:02,528 --> 00:03:05,088
But there's always paying attention in AI

68
00:03:05,600 --> 00:03:08,160
Artificial intelligence artificial intelligence

69
00:03:08,416 --> 00:03:10,720
Between whether you're using the computer

70
00:03:10,976 --> 00:03:12,768
As a model of what humans do

71
00:03:13,280 --> 00:03:14,304
Weather

72
00:03:15,328 --> 00:03:18,144
You know you're just modeling a new kind of intelligence

73
00:03:18,400 --> 00:03:19,680
It's machine intelligence

74
00:03:20,192 --> 00:03:22,496
I think what's happened over the last 30 years

75
00:03:23,008 --> 00:03:27,872
Is that all of us who started out interested in using the machine as a model walk humans do

76
00:03:28,128 --> 00:03:32,480
I've now sort of come around to the fact the machine intelligences own kind of Intel

77
00:03:33,504 --> 00:03:37,088
Artificial intelligence these states actually has very little to do with humans

78
00:03:37,344 --> 00:03:38,624
You say that that

79
00:03:38,880 --> 00:03:40,672
Remind me again of that combined

80
00:03:40,928 --> 00:03:43,488
Not agree so talk to me a little bit about about that

81
00:03:43,744 --> 00:03:49,888
Will it I mean yes I have a combined degree inside cognitive psychology and computer science

82
00:03:50,400 --> 00:03:53,984
But remember that was in the late 1970s

83
00:03:54,240 --> 00:03:55,520
We didn't even know what

84
00:03:55,776 --> 00:03:57,312
Call that thing then it's

85
00:03:57,568 --> 00:04:00,128
More recently been called cognitive science

86
00:04:00,640 --> 00:04:03,456
I attended the first cognitive science conference

87
00:04:03,712 --> 00:04:05,760
UC San Diego undergraduate

88
00:04:08,064 --> 00:04:09,088
But but

89
00:04:09,344 --> 00:04:11,392
You know I was using the machine to study

90
00:04:11,648 --> 00:04:12,160
Human

91
00:04:12,416 --> 00:04:12,928
Thinking

92
00:04:14,208 --> 00:04:17,024
Nowadays when you talk about combining

93
00:04:17,280 --> 00:04:18,047
Human

94
00:04:18,303 --> 00:04:19,071
And machine

95
00:04:19,327 --> 00:04:21,119
Thinking you really telling about something else

96
00:04:21,631 --> 00:04:22,655
You're talking about

97
00:04:23,423 --> 00:04:24,959
Machine intelligence

98
00:04:26,495 --> 00:04:28,031
Its own kind of intelligence

99
00:04:28,799 --> 00:04:34,943
Meshing well with human intelligence its own kind of intelligence you're not talking about one trying to emulate the other

100
00:04:35,199 --> 00:04:36,479
A model the other orthodox

101
00:04:36,735 --> 00:04:38,527
Stand in for the other you talking about

102
00:04:38,783 --> 00:04:41,087
Too premature kinds of intelligence

103
00:04:41,855 --> 00:04:45,439
Call listening to the kinds of interest you have in the directions you taking this is this

104
00:04:45,695 --> 00:04:46,975
Does remind me

105
00:04:47,743 --> 00:04:49,279
That your work really connects with us

106
00:04:49,535 --> 00:04:50,815
Kind of long history here

107
00:04:51,071 --> 00:04:55,423
Add doorbell and trying to really find out how the human intelligence

108
00:04:55,679 --> 00:04:56,191
Jensen and artificial

109
00:04:56,959 --> 00:04:57,727
Just so you know

110
00:04:59,007 --> 00:05:00,799
Yes that's exactly right and

111
00:05:01,055 --> 00:05:03,103
I think for really long time

112
00:05:03,359 --> 00:05:07,199
People have viewed the machine role episode of a power tool

113
00:05:07,967 --> 00:05:10,015
So the machine is going to

114
00:05:11,039 --> 00:05:12,575
Do the very heavy

115
00:05:12,831 --> 00:05:13,343
Front work

116
00:05:13,599 --> 00:05:15,135
What's the we don't want to do it

117
00:05:15,391 --> 00:05:18,463
Proofreading it'll sort of surf the web riddle

118
00:05:18,719 --> 00:05:20,255
But it'll always do what we tell it

119
00:05:20,511 --> 00:05:26,655
To do right and where did the phrase data-crunching comes to my side crunch

120
00:05:26,911 --> 00:05:27,423
No doubt about

121
00:05:27,935 --> 00:05:30,495
Who's in charge and why the machine is doing things we

122
00:05:30,751 --> 00:05:34,079
So that's being their attitude towards machines machines are

123
00:05:34,591 --> 00:05:36,895
You know they're there like the tools in my toolbox

124
00:05:37,663 --> 00:05:42,271
They act on my Direction They simply amplify what I want to do

125
00:05:42,527 --> 00:05:43,039
Now

126
00:05:43,295 --> 00:05:44,063
I want to change that

127
00:05:44,575 --> 00:05:50,719
And my communicating with computers program has as one of its tenants that the machine must actually

128
00:05:50,975 --> 00:05:51,743
They have something to say

129
00:05:51,999 --> 00:05:53,023
And something to contribute

130
00:05:53,791 --> 00:05:57,119
The machine is going to be creative the machine is going to do some work

131
00:05:57,631 --> 00:05:58,655
On its own

132
00:05:58,911 --> 00:06:00,703
Forts for its own reasons

133
00:06:01,471 --> 00:06:02,751
What I didn't count on

134
00:06:03,007 --> 00:06:04,287
Is the enormous

135
00:06:04,799 --> 00:06:06,079
Cultural barriers

136
00:06:06,335 --> 00:06:07,359
To that view of machine

137
00:06:07,871 --> 00:06:09,663
Even within my own program

138
00:06:09,919 --> 00:06:14,527
Explain a little more you know within my own program

139
00:06:15,039 --> 00:06:18,111
I do want most program managers do I say let's pick

140
00:06:18,367 --> 00:06:18,879
Some

141
00:06:19,135 --> 00:06:20,415
Use cases or

142
00:06:20,671 --> 00:06:22,207
Applications that will

143
00:06:22,463 --> 00:06:27,071
You know really drive this technology and so you say to all of these superb scientists

144
00:06:27,583 --> 00:06:29,119
Tell me about some applications

145
00:06:29,375 --> 00:06:31,679
And all of your applications they come back with

146
00:06:31,935 --> 00:06:33,727
Have the machine in the role of a servant

147
00:06:34,495 --> 00:06:36,287
These are the best scientist in the world

148
00:06:36,799 --> 00:06:37,823
CC Macon

149
00:06:38,335 --> 00:06:43,711
Imagine the machine was actually doing something for itself and it really takes a lot of effort

150
00:06:44,479 --> 00:06:48,063
To think of machine says you know autonomous intelligences

151
00:06:48,319 --> 00:06:51,391
Well and I think you've gone so far as to

152
00:06:51,903 --> 00:06:53,183
Challenge some of your

153
00:06:53,951 --> 00:06:55,487
Performers those who work with you on the

154
00:06:55,743 --> 00:06:57,791
This program to even think about the machine

155
00:06:58,303 --> 00:06:59,583
ACO improvise

156
00:06:59,839 --> 00:07:03,935
It's a right almost like they're in a in a jazz group together we could talk a little bit about

157
00:07:04,191 --> 00:07:04,703
That's

158
00:07:04,959 --> 00:07:09,055
Yeah well actually jazz is a very interesting form of communication

159
00:07:09,567 --> 00:07:11,615
Very very similar

160
00:07:11,871 --> 00:07:13,407
Conversation insofar as

161
00:07:13,663 --> 00:07:15,967
They're they're pretty strict rules

162
00:07:16,479 --> 00:07:19,807
The governed The Interchange between two Jazz musicians

163
00:07:20,319 --> 00:07:22,367
But there's also an enormous amount of creativity

164
00:07:22,623 --> 00:07:24,159
Are there other similar

165
00:07:24,415 --> 00:07:26,719
Use cases within the program one is

166
00:07:26,975 --> 00:07:29,791
Taking turns contributing lines to a story

167
00:07:30,559 --> 00:07:32,095
Or to a poem

168
00:07:32,351 --> 00:07:33,375
Horchata recipe

169
00:07:33,631 --> 00:07:34,911
What was Finding

170
00:07:35,423 --> 00:07:39,007
Is that when you look at a short poem that is written both

171
00:07:39,263 --> 00:07:41,311
Buy human and machine

172
00:07:42,079 --> 00:07:44,639
And you show that poem to another human

173
00:07:45,151 --> 00:07:50,015
That person isn't so good at picking out which lines were written by the human and which were written by the machine

174
00:07:51,039 --> 00:07:52,063
I would consider that a metric

175
00:07:52,319 --> 00:07:53,855
I think it is symmetric

176
00:07:54,879 --> 00:07:57,695
Given that this is a program communicating

177
00:07:57,951 --> 00:07:59,231
Wizz computers

178
00:07:59,487 --> 00:08:01,023
The program within DARPA

179
00:08:01,791 --> 00:08:04,351
Defense Advanced research projects agency

180
00:08:04,607 --> 00:08:07,423
How do you imagine this new way of communicating with

181
00:08:07,679 --> 00:08:08,959
Computers assuming that your Altima lease

182
00:08:09,215 --> 00:08:09,727
Successful

183
00:08:10,239 --> 00:08:12,287
Will how will that change

184
00:08:12,799 --> 00:08:13,567
Apps away

185
00:08:14,079 --> 00:08:15,103
Those in the in the

186
00:08:15,359 --> 00:08:15,871
The world

187
00:08:16,127 --> 00:08:17,151
National Security

188
00:08:17,407 --> 00:08:18,175
Relate to computer

189
00:08:18,431 --> 00:08:18,943
Those are used on

190
00:08:19,199 --> 00:08:20,991
Yeah well I think what one

191
00:08:21,247 --> 00:08:22,783
One has to realize

192
00:08:23,039 --> 00:08:23,551
That

193
00:08:24,319 --> 00:08:27,647
The modes with which we communicate with computers today

194
00:08:28,415 --> 00:08:29,183
Omar

195
00:08:29,695 --> 00:08:31,487
Extremely unnatural

196
00:08:31,743 --> 00:08:33,791
Very very cumbersome

197
00:08:34,047 --> 00:08:40,191
Can you still give me things like keyboards keyboards but actually if you want a computer to do something

198
00:08:40,959 --> 00:08:41,983
And you said I have two choices

199
00:08:42,751 --> 00:08:43,519
You can either

200
00:08:44,031 --> 00:08:45,055
Be a programmer

201
00:08:46,079 --> 00:08:47,103
And most people aren't

202
00:08:47,871 --> 00:08:49,151
Or you can use

203
00:08:49,663 --> 00:08:51,967
An interface that's been designed by

204
00:08:52,223 --> 00:08:52,991
Programmer

205
00:08:53,503 --> 00:08:55,295
You can point and click and swipe

206
00:08:56,063 --> 00:08:56,831
Some things like that

207
00:08:57,855 --> 00:08:59,135
And neither of them is a

208
00:08:59,647 --> 00:09:00,927
Every natural way

209
00:09:01,183 --> 00:09:02,463
Of interacting

210
00:09:02,719 --> 00:09:03,487
With the machine

211
00:09:04,255 --> 00:09:05,791
One of the

212
00:09:06,047 --> 00:09:08,863
Just on that point so natural for example here we are

213
00:09:09,119 --> 00:09:12,191
Talking I'm looking at you I'm paying attention to your facial expressions

214
00:09:12,703 --> 00:09:15,519
I'm very gestural when I talk so you can see

215
00:09:15,775 --> 00:09:18,335
I might have to going all over the place is that what you mean by Nacho

216
00:09:18,847 --> 00:09:19,359
Communication

217
00:09:20,127 --> 00:09:20,895
Baidu

218
00:09:21,407 --> 00:09:26,015
But the sentence I just said I do is also offered during a wedding

219
00:09:26,271 --> 00:09:28,319
But it means something completely different

220
00:09:29,343 --> 00:09:29,855
Here

221
00:09:30,111 --> 00:09:31,391
Send it does a little wedding

222
00:09:31,647 --> 00:09:32,671
And that's because of

223
00:09:33,951 --> 00:09:36,767
And there has never been a good account

224
00:09:38,047 --> 00:09:40,095
Computational theory of contact

225
00:09:40,863 --> 00:09:41,631
The wood support

226
00:09:41,887 --> 00:09:44,191
Human machine communication and that's really

227
00:09:44,447 --> 00:09:46,239
The biggest technical problem

228
00:09:46,495 --> 00:09:48,287
In the communicating with computers

229
00:09:48,543 --> 00:09:49,055
Program

230
00:09:49,311 --> 00:09:51,103
It's a natural communication

231
00:09:51,359 --> 00:09:52,639
Depends on context

232
00:09:53,663 --> 00:09:57,503
And we've got to be able to represent contacts other When I Say I Do

233
00:09:58,015 --> 00:09:59,039
You don't think that

234
00:09:59,295 --> 00:10:00,319
I want to get married with you

235
00:10:01,855 --> 00:10:03,391
I'm upset

236
00:10:06,463 --> 00:10:11,583
So how far along are you or your performers which is sort of DARPA speak for those who end up

237
00:10:11,839 --> 00:10:12,351
Working on Pacheco

238
00:10:12,607 --> 00:10:13,119
Project

239
00:10:13,375 --> 00:10:13,887
In

240
00:10:14,143 --> 00:10:15,423
Getting machines

241
00:10:15,935 --> 00:10:17,215
To handle contacts

242
00:10:17,471 --> 00:10:18,495
Text to be able to discern Conte

243
00:10:18,751 --> 00:10:19,263
Text in the case of

244
00:10:19,519 --> 00:10:20,799
What wherever there's an I do

245
00:10:21,055 --> 00:10:21,823
Were you just saying

246
00:10:22,079 --> 00:10:22,847
I agree with you

247
00:10:23,103 --> 00:10:24,639
Versus I want to marry you

248
00:10:24,895 --> 00:10:25,919
How far

249
00:10:26,175 --> 00:10:26,687
How long are they

250
00:10:26,943 --> 00:10:27,455
Well

251
00:10:27,711 --> 00:10:31,295
Weaver pek 3 big problems to work on

252
00:10:31,551 --> 00:10:32,319
In the program

253
00:10:32,831 --> 00:10:33,343
And

254
00:10:33,855 --> 00:10:37,951
One of the things that distinguishes them is the amount of contacts that's available

255
00:10:38,463 --> 00:10:40,255
And the amount that has to be inferred

256
00:10:40,767 --> 00:10:42,303
So the simplest problem

257
00:10:42,815 --> 00:10:43,839
Is to build

258
00:10:44,863 --> 00:10:48,447
A sort of a castle out of wooden blocks on the table top

259
00:10:48,959 --> 00:10:51,263
And the contacts that's available there

260
00:10:51,775 --> 00:10:56,383
Is available to any computer vision system or to any human who can see

261
00:10:56,639 --> 00:10:57,919
You can actually see the blocks

262
00:10:58,431 --> 00:11:00,223
So when I say at another one

263
00:11:00,479 --> 00:11:03,295
You can see what we're talking about the context this right there it's

264
00:11:03,551 --> 00:11:04,063
Accessible

265
00:11:04,575 --> 00:11:10,207
Then the second big problem we're working on is having humans and machines collaborate

266
00:11:11,231 --> 00:11:11,999
To build

267
00:11:12,255 --> 00:11:16,351
Very complicated models of biological systems

268
00:11:17,631 --> 00:11:18,655
And there

269
00:11:19,167 --> 00:11:20,191
The context

270
00:11:20,447 --> 00:11:22,239
Is maintained by all kinds of

271
00:11:22,495 --> 00:11:24,543
Clever machine visualizations

272
00:11:25,567 --> 00:11:29,663
You know this molecule talks to that molecule and here's a great big network of molecules

273
00:11:30,175 --> 00:11:31,455
What's the third use

274
00:11:31,967 --> 00:11:35,039
Yes of a third use-cases this improvised ation kind of used

275
00:11:35,295 --> 00:11:36,063
Case and there

276
00:11:36,575 --> 00:11:40,927
The problem is for the context is established by the by the notes of the musician plays

277
00:11:41,183 --> 00:11:43,231
Oh by the words that a person says

278
00:11:43,743 --> 00:11:44,511
And nothing else

279
00:11:45,023 --> 00:11:46,815
Just as in this conversation

280
00:11:47,327 --> 00:11:50,143
Context is established by the words and nothing else

281
00:11:51,423 --> 00:11:53,215
Not a hundred percent true right

282
00:11:53,471 --> 00:11:55,007
We both have shared

283
00:11:55,519 --> 00:11:56,799
Common experience

284
00:11:58,335 --> 00:11:58,847
So

285
00:11:59,871 --> 00:12:01,919
Context is established by the words

286
00:12:02,175 --> 00:12:04,735
And this enormous background of human knowledge

287
00:12:05,247 --> 00:12:08,063
That turns out to be extremely hard for machines

288
00:12:08,575 --> 00:12:10,111
I have low expectations there

289
00:12:11,391 --> 00:12:14,207
Machine for example would not know why

290
00:12:14,719 --> 00:12:15,999
Baidu

291
00:12:16,255 --> 00:12:17,791
In a particular context

292
00:12:18,047 --> 00:12:21,119
It's funny because it just doesn't know anything about

293
00:12:22,143 --> 00:12:28,287
Get married and what you know it just doesn't feel right I said what I'm waiting for now is the greatest metric metric of success

294
00:12:28,543 --> 00:12:29,567
For me will be when when

295
00:12:29,823 --> 00:12:30,591
Paul you

296
00:12:31,103 --> 00:12:32,383
From your program we get

297
00:12:33,151 --> 00:12:33,663
First

298
00:12:33,919 --> 00:12:34,431
Comedic

299
00:12:36,223 --> 00:12:39,295
Let's Segway then into your other projects at the moment

300
00:12:39,551 --> 00:12:40,575
Big mechanism

301
00:12:41,855 --> 00:12:42,623
Well

302
00:12:43,903 --> 00:12:48,511
Why are we doing big Magnuson we are doing it because I am terrified

303
00:12:49,023 --> 00:12:51,327
That our reach exceeds our grasp

304
00:12:52,607 --> 00:12:53,887
We are

305
00:12:55,423 --> 00:12:59,263
In the state of human history where we can

306
00:13:00,031 --> 00:13:01,567
Interfere

307
00:13:02,079 --> 00:13:02,847
With

308
00:13:03,359 --> 00:13:04,639
Systems

309
00:13:05,407 --> 00:13:06,687
That we don't understand

310
00:13:07,455 --> 00:13:07,967
And

311
00:13:08,735 --> 00:13:09,759
That's okay if

312
00:13:11,039 --> 00:13:14,879
You're making some small experiment in your lab and you have to blow your lab up

313
00:13:15,647 --> 00:13:17,695
But it's not okay if it's the climate

314
00:13:17,951 --> 00:13:19,231
Or the economy

315
00:13:19,487 --> 00:13:22,559
Or any of the other huge the stones on which we depend

316
00:13:23,071 --> 00:13:24,607
So what's the problem is that

317
00:13:25,375 --> 00:13:30,751
We have really no good way of anticipating the effects of actions taken and very very complicated cyst

318
00:13:31,519 --> 00:13:33,823
So big mechanism is a program

319
00:13:34,079 --> 00:13:36,639
To develop technology to help humans

320
00:13:36,895 --> 00:13:37,919
Build models

321
00:13:38,175 --> 00:13:39,455
Of complicated systems

322
00:13:40,223 --> 00:13:40,991
Models of

323
00:13:41,247 --> 00:13:42,783
Unimaginable complexity

324
00:13:43,551 --> 00:13:44,575
Things That No human

325
00:13:44,831 --> 00:13:45,599
Possibly build

326
00:13:45,855 --> 00:13:46,367
Alone

327
00:13:47,135 --> 00:13:47,903
Okay and I think

328
00:13:48,159 --> 00:13:49,695
One of the ways that

329
00:13:50,207 --> 00:13:50,975
You are hoping

330
00:13:51,231 --> 00:13:52,767
Computers will be able to do this

331
00:13:53,023 --> 00:13:54,559
Gets a little bit back to

332
00:13:54,815 --> 00:13:56,607
That sort of data crunching

333
00:13:57,119 --> 00:13:59,167
Brute Force aspect but this is

334
00:13:59,423 --> 00:14:03,775
Right where maybe a computer could go into the scientific literature and read a hundred thousand

335
00:14:04,031 --> 00:14:05,823
A million papers that are relevant

336
00:14:06,079 --> 00:14:06,847
Does something like maybe

337
00:14:07,359 --> 00:14:10,175
Oncology the onset of cancer or something like that something that

338
00:14:10,431 --> 00:14:11,711
People can't do right

339
00:14:11,967 --> 00:14:13,247
Exactly what we're doing

340
00:14:13,503 --> 00:14:17,599
So talk a little bit about that ability to kind of look at the

341
00:14:17,855 --> 00:14:21,439
Information sphere in ways that just impossible but then

342
00:14:21,951 --> 00:14:23,231
What will the computer

343
00:14:23,487 --> 00:14:23,999
Be able to

344
00:14:24,255 --> 00:14:25,023
Gather from just

345
00:14:25,279 --> 00:14:26,559
All of all of that information

346
00:14:27,583 --> 00:14:29,631
Well so let me first describe what

347
00:14:29,887 --> 00:14:31,423
What was actually built and then

348
00:14:31,679 --> 00:14:32,959
And then I'll come back to you

349
00:14:33,215 --> 00:14:33,727
2 question

350
00:14:34,495 --> 00:14:35,519
What we have now is

351
00:14:36,287 --> 00:14:38,335
Big collections of programs

352
00:14:38,591 --> 00:14:39,103
That

353
00:14:39,359 --> 00:14:41,151
Read the scientific literature

354
00:14:41,407 --> 00:14:42,431
Temperature in

355
00:14:42,687 --> 00:14:47,039
Cell signaling biology cell signaling is all of these molecular processes

356
00:14:47,295 --> 00:14:47,807
Mapreduce

357
00:14:48,063 --> 00:14:49,855
Effects in cells including cancer

358
00:14:50,111 --> 00:14:52,159
Machines can read those papers

359
00:14:53,439 --> 00:14:53,951
At the moment

360
00:14:54,207 --> 00:14:55,231
And as you said can we Hunters

361
00:14:55,487 --> 00:14:56,255
Thousands of paper

362
00:14:57,279 --> 00:14:58,559
And out of every paper

363
00:14:58,815 --> 00:15:01,631
The machine extract a little piece

364
00:15:01,887 --> 00:15:03,423
Of biological mechanism

365
00:15:03,935 --> 00:15:09,823
You know this molecule phosphorylates that molecule or binds with this molecule that kind of thing but every paper

366
00:15:10,335 --> 00:15:13,151
Really talks about only a couple of little things like

367
00:15:14,175 --> 00:15:16,735
It may be a 10-page paper but the main results is like

368
00:15:16,991 --> 00:15:17,503
Tiny

369
00:15:18,015 --> 00:15:19,295
So after you read

370
00:15:19,551 --> 00:15:20,831
300000 papers

371
00:15:21,343 --> 00:15:21,855
You have

372
00:15:23,135 --> 00:15:24,159
Half a million

373
00:15:24,671 --> 00:15:30,559
Tiny little fragments of a big complicated mechanism it'll. Little picture pixels of what might be a picture

374
00:15:30,815 --> 00:15:31,327
That's right

375
00:15:31,583 --> 00:15:32,863
Now you have to put it all together

376
00:15:33,631 --> 00:15:35,423
And so that's the second big step

377
00:15:35,679 --> 00:15:39,519
In Big mechanism is to assemble all of these fragments into a biologic

378
00:15:39,775 --> 00:15:40,287
Medical model

379
00:15:41,055 --> 00:15:44,383
Third step is to reason with that biological model to solve problems

380
00:15:44,895 --> 00:15:46,175
How would I drug this cancer

381
00:15:46,687 --> 00:15:47,711
So

382
00:15:48,735 --> 00:15:51,039
This is giving me a sense of where

383
00:15:51,295 --> 00:15:52,575
Our two different kinds of intelligence

384
00:15:53,087 --> 00:15:55,647
Who's really come together because we like to be able to tell

385
00:15:55,903 --> 00:15:56,415
Stories

386
00:15:56,671 --> 00:15:57,439
We like to have

387
00:15:57,695 --> 00:15:59,487
Causal explanations mechanism

388
00:15:59,999 --> 00:16:01,791
Why things happen in the world

389
00:16:02,559 --> 00:16:05,375
And we are sort of good at that but we are not

390
00:16:05,631 --> 00:16:06,655
Great at at

391
00:16:06,911 --> 00:16:08,703
Seeing how a hundred thousand

392
00:16:09,215 --> 00:16:09,983
Points

393
00:16:10,239 --> 00:16:10,751
And.

394
00:16:11,007 --> 00:16:11,519
Connect

395
00:16:11,775 --> 00:16:12,543
We can see how

396
00:16:12,799 --> 00:16:13,823
1020 + 30

397
00:16:14,591 --> 00:16:15,615
Where's the computer now

398
00:16:15,871 --> 00:16:17,919
Can bring in a hundred thousand points

399
00:16:18,431 --> 00:16:20,479
But if we're working with Attitude say

400
00:16:20,735 --> 00:16:24,063
Computer look at those points and also tell a causal story

401
00:16:24,575 --> 00:16:30,719
Then we're beginning to kind of work together am I getting yet a little bit of what you're seeking yeah and I want to be clear about why

402
00:16:30,975 --> 00:16:33,791
I think this is revolutionary and to do that I want to go back

403
00:16:34,047 --> 00:16:34,559
2

404
00:16:34,815 --> 00:16:37,375
The 50s when DARPA was started

405
00:16:37,631 --> 00:16:38,143
Does a response to

406
00:16:38,399 --> 00:16:38,911
Sputnik

407
00:16:39,423 --> 00:16:40,703
The United States

408
00:16:40,959 --> 00:16:41,983
Began

409
00:16:43,263 --> 00:16:49,407
To emphasize sciences and Engineering for the United States also started to reward specialization

410
00:16:49,919 --> 00:16:50,943
In The Sciences

411
00:16:52,223 --> 00:16:54,015
And we've gone to the point now

412
00:16:54,527 --> 00:16:55,039
Where

413
00:16:55,295 --> 00:16:58,879
I can't understand what the guy in the office next door

414
00:16:59,135 --> 00:16:59,647
Does

415
00:16:59,903 --> 00:17:02,975
We have become highly highly highly specialized hyperspace

416
00:17:03,231 --> 00:17:03,999
Hyper specialized

417
00:17:05,279 --> 00:17:08,095
The speed at which we read has not increased

418
00:17:08,863 --> 00:17:10,655
So we read more narrowly

419
00:17:11,679 --> 00:17:12,703
Now here's the problem

420
00:17:13,983 --> 00:17:16,543
The world's existential problems

421
00:17:17,311 --> 00:17:18,079
Do not fit

422
00:17:18,591 --> 00:17:21,663
Neatly into any one academic Department

423
00:17:23,199 --> 00:17:24,991
They are systemic problems

424
00:17:26,271 --> 00:17:28,319
Am I can't think of a worse way

425
00:17:28,575 --> 00:17:30,111
The song of a systemic problem

426
00:17:30,623 --> 00:17:31,903
When to get a bunch of people

427
00:17:32,159 --> 00:17:35,743
Who are experts in the tiniest aspects of that system

428
00:17:37,279 --> 00:17:38,559
What we need is a big picture

429
00:17:39,839 --> 00:17:40,351
And

430
00:17:40,607 --> 00:17:42,655
Where humans can't machines must

431
00:17:42,911 --> 00:17:43,679
And humans can't

432
00:17:44,447 --> 00:17:47,263
You know I'm doing well 320 papers week

433
00:17:48,543 --> 00:17:51,615
But in order to understand the system I need three three hundred thousand paper

434
00:17:51,871 --> 00:17:54,687
So this is very interesting and in a way which you're saying if you look

435
00:17:55,199 --> 00:17:56,479
Even just a structure

436
00:17:56,991 --> 00:18:01,087
Of a university or even a company you have sort of departments

437
00:18:01,599 --> 00:18:05,951
And Amber we're almost institutionalizing an inability

438
00:18:06,207 --> 00:18:09,535
To synthesize in this very broad-based way that your suggest

439
00:18:09,791 --> 00:18:12,095
But the institutions continue to sort of

440
00:18:12,351 --> 00:18:14,655
Put us into these compartments words you're saying

441
00:18:14,911 --> 00:18:19,519
We now are in a place where we can combine our desire to synthesize with

442
00:18:19,775 --> 00:18:20,799
The powers of computer tab

443
00:18:21,055 --> 00:18:22,335
For new kind of bug

444
00:18:22,591 --> 00:18:24,383
Era of synthesis new kind of scholarship

445
00:18:24,639 --> 00:18:29,503
That's why I view it as revolutionary it's not just that a machine can read a large number of paper

446
00:18:30,271 --> 00:18:32,575
It's the by doing so we have a chance

447
00:18:33,087 --> 00:18:33,855
Just a chance

448
00:18:34,367 --> 00:18:37,183
Understanding the systems on which we depend for our survival

449
00:18:37,439 --> 00:18:39,743
That really is exciting to me

450
00:18:40,255 --> 00:18:45,887
But as you know there's a great dialogue going on in society now about you know what it means for

451
00:18:46,143 --> 00:18:47,167
Computers to get smarter

452
00:18:47,423 --> 00:18:47,935
Where to get more into

453
00:18:48,447 --> 00:18:49,471
Get smarter like us

454
00:18:49,727 --> 00:18:52,799
And intelligent like us were smarter or intelligent in their own ways

455
00:18:53,311 --> 00:18:56,639
And this brings up some concerns it brings up excitement and concern

456
00:18:57,663 --> 00:18:59,455
I'd love to hear what you're excited about

457
00:18:59,967 --> 00:19:00,479
As

458
00:19:00,735 --> 00:19:01,759
The computer the ball this

459
00:19:02,015 --> 00:19:03,551
In fact as you have a role in that

460
00:19:04,319 --> 00:19:05,599
And also what gives you some pause

461
00:19:06,879 --> 00:19:07,391
If

462
00:19:07,647 --> 00:19:11,487
People understood just how little machines were capable of

463
00:19:14,303 --> 00:19:14,815
I think

464
00:19:15,071 --> 00:19:15,583
You wouldn't be

465
00:19:16,095 --> 00:19:16,607
Hearing

466
00:19:17,375 --> 00:19:18,655
So much of the snow

467
00:19:18,911 --> 00:19:22,751
There are, but I just want to push back a little bit there because it's a 19

468
00:19:23,263 --> 00:19:24,799
48

469
00:19:25,311 --> 00:19:29,663
Bell Labs rolled out a single transistor it was an ugly looking thing

470
00:19:30,431 --> 00:19:31,967
And now you can get a chip

471
00:19:32,223 --> 00:19:34,527
That has billions on the on something yet

472
00:19:35,551 --> 00:19:36,575
Fits snugly in my

473
00:19:36,831 --> 00:19:37,343
My palm

474
00:19:37,855 --> 00:19:39,391
Those are Worlds Apart

475
00:19:39,647 --> 00:19:41,439
There was nothing much that little

476
00:19:41,695 --> 00:19:42,719
Single switch could do

477
00:19:43,231 --> 00:19:45,279
And maybe do something in the telephone system

478
00:19:45,535 --> 00:19:49,887
Initially and now we have microprocessors that do we know Wonders on

479
00:19:50,143 --> 00:19:51,679
Even on our home computer so

480
00:19:51,935 --> 00:19:52,447
So

481
00:19:52,703 --> 00:19:55,775
If we add time to to the picture here

482
00:19:57,055 --> 00:20:01,151
Do you still think the people do not have justification of some concerns

483
00:20:02,175 --> 00:20:05,503
I think the people are right to be concerned

484
00:20:05,759 --> 00:20:06,271
About

485
00:20:07,295 --> 00:20:09,087
Fielding new technology

486
00:20:09,599 --> 00:20:10,623
Second

487
00:20:10,879 --> 00:20:11,391
Do harm

488
00:20:12,415 --> 00:20:13,695
You know self-driving cars

489
00:20:13,951 --> 00:20:14,719
Could I suppose

490
00:20:15,487 --> 00:20:16,767
Get people into traffic Act

491
00:20:17,023 --> 00:20:17,535
Accidents

492
00:20:18,815 --> 00:20:19,327
Corsodyl

493
00:20:19,583 --> 00:20:21,631
What are the solute

494
00:20:23,423 --> 00:20:25,983
The reason I'm not all that concerned

495
00:20:26,751 --> 00:20:29,311
Is the this is not by any means the first

496
00:20:29,567 --> 00:20:30,079
Time

497
00:20:30,335 --> 00:20:32,127
The society has come to grips

498
00:20:32,383 --> 00:20:35,967
With threats posed by new technologies and we've always figured out

499
00:20:36,991 --> 00:20:38,527
How to deal with those threats

500
00:20:39,295 --> 00:20:40,575
In one way or another

501
00:20:41,087 --> 00:20:42,111
Society

502
00:20:42,623 --> 00:20:43,647
Finds ways

503
00:20:43,903 --> 00:20:45,183
To offset the cost

504
00:20:45,695 --> 00:20:47,231
Associated with new technology

505
00:20:47,487 --> 00:20:49,535
We simply build it into the cost of doing business

506
00:20:50,815 --> 00:20:52,863
Not till we learn how to manage the written we manage the risk

507
00:20:53,887 --> 00:20:56,191
And that reminds me of some specific ways DARPA

508
00:20:56,447 --> 00:20:59,263
Is working to manage the risks of a coming era

509
00:20:59,519 --> 00:21:00,287
Artificial in

510
00:21:00,543 --> 00:21:01,823
Intelligence and machine learning

511
00:21:02,335 --> 00:21:07,199
I'm thinking here of programs like explainable AI which your fellow program manager

512
00:21:07,455 --> 00:21:08,735
David gunning is running

513
00:21:09,503 --> 00:21:12,063
And in that program he's got the goal of

514
00:21:12,319 --> 00:21:15,391
Developing artificial intelligence and machine learning techniques

515
00:21:15,647 --> 00:21:16,159
That

516
00:21:16,416 --> 00:21:22,560
Not only produce results and gather data and make decisions to help you and partners manage and operate the

517
00:21:22,816 --> 00:21:24,096
Complex systems in our world

518
00:21:24,352 --> 00:21:28,448
But they are systems that do this in ways that are transparent to the humans in the loop

519
00:21:28,960 --> 00:21:32,288
And that way the machine Behavior remains understandable unexplainable

520
00:21:32,544 --> 00:21:34,080
At least in theory crustable

521
00:21:34,848 --> 00:21:40,736
I want to move away from specific programs and asked you about

522
00:21:40,992 --> 00:21:41,504
DARPA

523
00:21:42,272 --> 00:21:43,808
As a

524
00:21:44,576 --> 00:21:50,464
Part of the overall Innovation ecosystem and and what I'm thinking about there as other elements in the

525
00:21:50,720 --> 00:21:53,792
Tamar say academics

526
00:21:54,304 --> 00:22:00,448
About her fundamental source of questions and doing maybe fundamental research getting new data that hadn't been out there

527
00:22:00,704 --> 00:22:01,472
Before I'm thinking about

528
00:22:01,984 --> 00:22:03,520
Entrepreneurs were thinking about how to

529
00:22:03,776 --> 00:22:05,568
How to apply science in into

530
00:22:05,824 --> 00:22:08,640
And turn that into various that small and large

531
00:22:08,896 --> 00:22:09,408
Technologies

532
00:22:09,920 --> 00:22:12,480
Answer weird DARPA fits into

533
00:22:12,992 --> 00:22:13,504
All of that

534
00:22:13,760 --> 00:22:17,856
Dash in in as we sit in the very beginning and Beyond being a driver

535
00:22:18,112 --> 00:22:18,624
BowTech

536
00:22:20,160 --> 00:22:23,232
Well of course darvaza very distinguished history is it

537
00:22:23,488 --> 00:22:24,000
The driver of

538
00:22:24,256 --> 00:22:25,024
Technology

539
00:22:25,280 --> 00:22:27,840
And we we could talk about why it's being so so

540
00:22:28,096 --> 00:22:28,608
Successful

541
00:22:29,376 --> 00:22:32,192
Then maybe I could related a bit to my personality

542
00:22:32,448 --> 00:22:36,032
Experience which side work for DARPA as a warmer

543
00:22:36,544 --> 00:22:37,312
For 30 years

544
00:22:37,568 --> 00:22:39,872
Before coming here as a program manager

545
00:22:40,384 --> 00:22:40,896
And

546
00:22:41,408 --> 00:22:44,736
I have to say you know I thought I knew DARPA pretty well

547
00:22:44,992 --> 00:22:48,576
But it wasn't till I got in the building that I realized I was a really icing

548
00:22:48,832 --> 00:22:51,392
A pretty narrow slice of what DARPA does

549
00:22:51,648 --> 00:22:52,160
Starbucks

550
00:22:52,416 --> 00:22:55,488
Sits at the intersection of government-industry Academia

551
00:22:55,744 --> 00:22:57,024
And other kinds of research

552
00:22:57,280 --> 00:22:59,840
And it brings it all together it's it's

553
00:23:00,096 --> 00:23:01,888
It's got this a big picture

554
00:23:02,144 --> 00:23:03,680
Of how Innovation happens

555
00:23:04,192 --> 00:23:05,472
I in the United States

556
00:23:06,240 --> 00:23:07,776
And it's been very successful

557
00:23:09,056 --> 00:23:11,872
Making it possible for everybody to do what they do best

558
00:23:12,384 --> 00:23:15,712
You know the words that goes on in academe it tends to be if I might

559
00:23:16,480 --> 00:23:19,040
Say a little conservative academics

560
00:23:19,296 --> 00:23:20,064
I don't know

561
00:23:20,320 --> 00:23:22,624
People will be surprised to hear this but I think academics

562
00:23:23,136 --> 00:23:25,696
Tend to be pretty conservative in the problems they

563
00:23:26,208 --> 00:23:27,488
They they taco

564
00:23:27,744 --> 00:23:31,072
Siddhartha's role in Academia is often to say

565
00:23:32,096 --> 00:23:33,888
Let's take on something that's impossible

566
00:23:34,400 --> 00:23:36,448
And we're going to pay to get it done

567
00:23:36,960 --> 00:23:39,776
You know so that's what that sort of the message to Academia

568
00:23:40,544 --> 00:23:41,312
Of the message

569
00:23:41,568 --> 00:23:43,360
The government is look what's possible

570
00:23:44,128 --> 00:23:45,920
We just changed your view of what what

571
00:23:46,176 --> 00:23:47,712
What technology can do

572
00:23:47,968 --> 00:23:51,040
Think about how you can use it think about how you can

573
00:23:51,808 --> 00:23:55,136
I use it to achieve darpa's mission of creating an

574
00:23:56,160 --> 00:23:58,208
Avoiding strategic surprise

575
00:23:58,720 --> 00:24:00,512
Write and listen to you talk about

576
00:24:00,768 --> 00:24:03,328
Darkest place in The Innovation ecosystem in

577
00:24:03,584 --> 00:24:05,632
And moving technology forward it also

578
00:24:06,144 --> 00:24:08,448
Reminds me a little bit of what you were saying

579
00:24:08,704 --> 00:24:09,216
About

580
00:24:09,472 --> 00:24:10,496
Big mechanism

581
00:24:10,752 --> 00:24:13,824
In bringing forth a new kind of synthesis nubility

582
00:24:14,080 --> 00:24:14,592
You take many different

583
00:24:14,848 --> 00:24:15,360
Four categories of

584
00:24:15,616 --> 00:24:16,640
Nothing can bring them together

585
00:24:17,408 --> 00:24:22,528
One thing the DARPA seems to do is to bring communities together that do

586
00:24:23,552 --> 00:24:24,832
In ways that might not be

587
00:24:25,088 --> 00:24:28,416
Very easy for the performers in their own institutions

588
00:24:28,928 --> 00:24:32,000
But here is a program manager you in a way I can bring together 5/6

589
00:24:32,512 --> 00:24:33,280
Performers together

590
00:24:33,536 --> 00:24:35,072
And create a community just didn't exist

591
00:24:35,584 --> 00:24:40,704
So we talked about Altra specialization a moment ago and you just use the word disciplinarian and

592
00:24:40,960 --> 00:24:42,496
And I got really interested in the word

593
00:24:42,752 --> 00:24:44,032
Interdisciplinary

594
00:24:45,056 --> 00:24:45,568
Because

595
00:24:45,824 --> 00:24:48,128
It occurred to me that I heard it everyday

596
00:24:49,152 --> 00:24:49,920
At the University

597
00:24:50,432 --> 00:24:51,456
I might hear it never

598
00:24:51,712 --> 00:24:52,480
Adorable

599
00:24:53,248 --> 00:24:56,832
And I've come to view the word interdisciplinary as

600
00:24:57,600 --> 00:24:58,880
Standing for a problem

601
00:24:59,136 --> 00:25:00,672
Not standing for solution

602
00:25:01,184 --> 00:25:03,744
And the reason that we don't hear that word of DARPA

603
00:25:04,000 --> 00:25:04,768
Is that

604
00:25:05,024 --> 00:25:06,048
We just take it for granite

605
00:25:06,560 --> 00:25:09,120
Everything we do at DARPA is interdisciplinary

606
00:25:09,632 --> 00:25:15,776
All of my teams are interdisciplinary I have machine reading people I have linguicide biologists

607
00:25:16,032 --> 00:25:17,312
It's just taken for granted

608
00:25:17,568 --> 00:25:21,408
Right I mean I look at the P&R pyrite the projects

609
00:25:21,664 --> 00:25:22,944
Which is another way of thinking about it

610
00:25:23,968 --> 00:25:28,064
Problem driven way of going about R&D so if you have the end

611
00:25:28,320 --> 00:25:31,392
Part of an endpoint in mind you don't know exactly where you're going because

612
00:25:31,648 --> 00:25:32,416
He's our Leading Edge

613
00:25:32,672 --> 00:25:33,440
Areas

614
00:25:33,696 --> 00:25:34,720
But you have some sense

615
00:25:35,488 --> 00:25:36,000
Then

616
00:25:36,256 --> 00:25:36,768
Really

617
00:25:37,024 --> 00:25:43,168
You're not saying this is a biology problem or a physics problem or an engineering problem it's just a problem that has to be solved

618
00:25:43,424 --> 00:25:44,448
No matter what

619
00:25:44,704 --> 00:25:46,752
Mindset or skillset you need to bring in

620
00:25:47,008 --> 00:25:49,568
And it turns out that that may be a huge variety

621
00:25:49,824 --> 00:25:51,872
Yeah when people get to the project

622
00:25:52,384 --> 00:25:52,896
Hyundai

623
00:25:53,664 --> 00:25:58,784
They're trained in machine learning on suddenly a cancer biologist is up there speaking

624
00:25:59,040 --> 00:26:00,832
Their eyes get big in the room cats

625
00:26:01,088 --> 00:26:01,600
Quiet

626
00:26:02,112 --> 00:26:04,416
And after a few weeks

627
00:26:04,672 --> 00:26:05,184
Or Mom

628
00:26:05,696 --> 00:26:06,208
There

629
00:26:06,464 --> 00:26:07,488
The happiest people

630
00:26:08,000 --> 00:26:10,048
Because this is the way science should be done

631
00:26:10,816 --> 00:26:11,328
And

632
00:26:11,584 --> 00:26:12,096
They got

633
00:26:12,352 --> 00:26:14,400
To participate in that kind of science

634
00:26:15,168 --> 00:26:21,312
On that note I think we we've run out of our time for this discussion though I'm going to be eager to follow

635
00:26:21,568 --> 00:26:22,080
Up with you

636
00:26:22,336 --> 00:26:27,456
Some other times and so I just want to thank you Paul for joining me in the studio

637
00:26:27,968 --> 00:26:31,296
Before this really great discussion. I've enjoyed it very much thanks so much Island

638
00:26:32,064 --> 00:26:34,368
And thank you listeners for joining us

639
00:26:34,624 --> 00:26:37,184
And I hope you join us again for the next

640
00:26:37,440 --> 00:26:38,720
Voices from DARPA

641
00:26:42,048 --> 00:26:43,840
For more information about Paul Cohen

642
00:26:44,096 --> 00:26:46,144
Is programs in the rest of what DARPA does

643
00:26:46,400 --> 00:26:49,728
And to find this and other episodes of voices from DARPA

644
00:26:50,240 --> 00:26:51,264
Visit us online at

645
00:26:51,520 --> 00:26:52,288
DARPA. Bill
