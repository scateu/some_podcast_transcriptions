
2
00:00:11,780 --> 00:00:31,130
Stealth technology, the internet, GPS in the palm of your hand on the most operation technology, is a driver of our times since its founding in nineteen fifty eight, in the midst of the cold war, doubt the defence advanced research projects agency has been a driver of technology.

3
00:00:31,510 --> 00:00:36,840
Welcome to Voices from DARPA a window onto DARPA's core of program managers.

4
00:00:37,120 --> 00:00:39,652
Their job, to redefine what is possible.

5
00:00:39,652 --> 00:00:43,431
My name is Ivan Amato , and I'm  your DARPA host.

6
00:00:43,431 --> 00:00:47,522
Today, I am pleased to be talking with Dr. Sergey Bratus.

7
00:00:47,522 --> 00:00:50,711
Sergey joined DARPA as a program manager in the agencies'

8
00:00:50,711 --> 00:00:55,209
Information Innovation Office in 2018, he brings into the agency,

9
00:00:55,209 --> 00:01:01,212
what you might think of as a six cents for the suring of a deeply hidden security vulnerabilities

10
00:01:01,212 --> 00:01:08,961
in the oceans of software and the communications practices underlying our civilian and military technologies and systems.

11
00:01:08,961 --> 00:01:10,183
Prior to coming to DARPA,

12
00:01:10,183 --> 00:01:16,593
Sergey had been at Dartmouth College, beginning in 2002 as a post doctoral research associate, and most

13
00:01:16,593 --> 00:01:21,745
recently as research associate professor in the computer science department,

14
00:01:21,745 --> 00:01:27,676
he began his professional career at BBNtechnologies where he worked on natural language processing.

15
00:01:27,676 --> 00:01:33,328
I find that professional element fascinating because the BBN-DARPA connections spanned

16
00:01:33,328 --> 00:01:39,461
back to 1960s when the two work together on some of the foundations of Internet. Back to Sergey,

17
00:01:39,461 --> 00:01:46,849
he received his undergraduate education at the Moscow Institute of Physics and Technology and earn his PhD

18
00:01:46,849 --> 00:01:49,220
in mathematics from Northeastern University.

19
00:01:49,220 --> 00:01:55,211
He has published over one hundred technical papers, and his research has received several awards, including

20
00:01:55,211 --> 00:01:59,980
the 2012 Black Hat Pony Award for most innovative research.

21
00:02:00,000 --> 00:02:03,060
That award, pony award is a prestigious (有声望的) one

22
00:02:03,060 --> 00:02:07,140
that recognizes achievements of security researchers and security community.

23
00:02:07,730 --> 00:02:19,450
Doctor Sergey Bratus, thanks for making some time to talk with me today about your many and very efforts to increase every safety in the paralysis, cyber domains that we are immersed in.

24
00:02:19,450 --> 00:02:20,470
Thank you for being here.

25
00:02:20,720 --> 00:02:22,080
Thank you for having me here, Ivan.

26
00:02:22,270 --> 00:02:28,720
Let's start with the origin story of your interests in computer science and cyber security.

27
00:02:29,160 --> 00:02:38,700
I think one of the things that fascinate the public about scientists and engineers is just where there are sort of in some ways, hybrid specialized interests come from.

28
00:02:38,700 --> 00:02:41,330
[Q] So did you grow up in a geeky household ?

29
00:02:41,620 --> 00:02:47,560
[Q] Did you encounter an engaging professor at the Moscow Instruments of Physics and Technology ?

30
00:02:47,670 --> 00:02:48,770
[Q] Where did you interest come from?

31
00:02:49,220 --> 00:02:50,890
Oh, computers were a miracle.

32
00:02:51,370 --> 00:03:03,590
I grow up on the Soviet Union, and we would get a slow trick of imported technology, which is so wonderfully contrasted with the rest of life.

33
00:03:03,830 --> 00:03:07,280
They were something from the future.

34
00:03:08,100 --> 00:03:12,612
And so even though the technology that was available

35
00:03:12,612 --> 00:03:18,316
to a school student was perhaps decade behind,

36
00:03:18,316 --> 00:03:20,565
it was never less a miracle,

37
00:03:20,565 --> 00:03:29,100
and it had an enormous attraction over the executives myself, we wanted to know how it worked,

38
00:03:29,100 --> 00:03:35,770
and we wanted to be able to program something like those games that we saw on those computer screens.

39
00:03:36,930 --> 00:03:41,815
And so we did, but as I was growing up in the Soviet Union, you could

40
00:03:41,815 --> 00:03:54,030
see the slow progression of technology being important from the rest, and we were left behind by some people listening ten to fifteen years.

41
00:03:54,650 --> 00:04:16,020
There was a bit of luck in that, because in my age, I go to see the very basics of computing, starting with programming micro calculators, where my appears in the west might have seen, might have been already seen IBM PC XT, which was an incredible miracle of technology.

42
00:04:16,770 --> 00:04:20,070
And Sergey, just so that the listeners have a sense of timing here.

43
00:04:20,270 --> 00:04:25,360
You say that you, you really encountered computers for the first time when you're in middle school.

44
00:04:25,360 --> 00:04:26,882
So what years were those actually?

45
00:04:26,882 --> 00:04:31,850
we're talking 197x, late 1970s, early 1980s

46
00:04:32,350 --> 00:04:33,020
Okay, thank you.

47
00:04:33,020 --> 00:04:34,660
So I took you off track, I'll right on that

48
00:04:34,910 --> 00:04:51,779
So making computers do things was a huge time sink, because we're people in california might have had access to storage devices and floppies.

49
00:04:51,779 --> 00:04:57,482
we actually had to retype our Texas Instruments

50
00:04:57,482 --> 00:05:00,518
kind of a clone [...] programs.

51
00:05:00,518 --> 00:05:07,005
Still, it was an incredibly magical experience, but that was my introduction to computers.

52
00:05:07,005 --> 00:05:18,120
My introduction to security came when I was a grad student at Northeastern working on my degree, mathematics and Linux was exploding on the scene.

53
00:05:18,120 --> 00:05:20,000
Everyone wanted to run a Linux server.

54
00:05:21,060 --> 00:05:24,420
The internet was still the wonderful place where you met.

55
00:05:24,420 --> 00:05:27,510
Like minded geeks [..] wasn't anything else.

56
00:05:27,920 --> 00:05:30,849
And so I set up my Linux server.

57
00:05:30,849 --> 00:05:38,170
I followed every bit of, the how-to instructions, and it worked, and I was happy.

58
00:05:38,460 --> 00:05:45,590
And then in about two weeks, that server was compromised and taken over, and I found it serving ...

59
00:05:45,810 --> 00:05:47,600
I don't know ..

60
00:05:47,600 --> 00:05:56,230
Music that I could not quite understand or pieces of a game are probably pirated, that I knew nothing about.

61
00:05:56,430 --> 00:06:11,676
It got, as the saying was at the time, a pond compromise taken over as it happened with many university computers in the 1990s, and I wanted to know how. I did everything by the book.

62
00:06:11,676 --> 00:06:13,876
I thought I could understand

63
00:06:13,876 --> 00:06:17,520
the way programs were written by that time I was already competent(有能力的)

64
00:06:17,550 --> 00:06:24,200
C programmer, I thought, and I thought I understood that environment and those programs.

65
00:06:24,330 --> 00:06:27,680
Turned out I did not, and the hackers did. [Host] right.

66
00:06:27,680 --> 00:06:38,020
So you had a very personal experience with personal violation showing up a right at your own computer station that really got you hooked and concerned about these security issues.

67
00:06:38,280 --> 00:06:41,580
I probably owe who ever did that a beer.

68
00:06:42,480 --> 00:06:49,780
Right, so now you wanna go find out who that person is and shake their hand, because they essentially were central in the rest of the trajactory of your career.

69
00:06:49,910 --> 00:06:58,120
I might say that, and so I went down the rabbit hole of a hacking and computer security, rather than being a mathematician

70
00:06:58,370 --> 00:07:07,051
One of the quick question just cause i'm serious in the timing of in your educational, professional development and world history.

71
00:07:07,051 --> 00:07:12,336
You got to undergraduate degree in Moscow, and then you got your graduate degree in Northeastern

72
00:07:12,336 --> 00:07:18,620
So can you tell me, how is it that you made the transition from the then Soviet Union to United States?

73
00:07:19,370 --> 00:07:24,360
I saw the late Soviet Union.

74
00:07:24,360 --> 00:07:41,260
I grew up with the totalitarian(极权) society that it was, and I wanted out at the time, it was nearly impossible to do in any legal fashion.

75
00:07:41,720 --> 00:07:45,460
But luckily, the soviet power was collapsing.

76
00:07:45,620 --> 00:08:01,600
It collapsed between 1991 and 1993, and so I could, in fact, go out and study abroad, if an American university would take me and several offered.

77
00:08:01,850 --> 00:08:13,050
And so I left. Quite a few people were more enthusiastic about the prospects of poor Soviet Russian and poor Soviet States, unfortunately, they were proven wrong.

78
00:08:13,830 --> 00:08:16,150
All right, well, their losses are our gain.

79
00:08:16,150 --> 00:08:21,690
So happy that you did actually make it out and clearly embrace the opportunities that were here.

80
00:08:21,970 --> 00:08:48,154
Sergey, after getting your degrees where you worked first BBN, then you segwey into academy at Dartmouth where you build the computer science and security program that included the what you have described as a called quote-unquote "hidden curriculum(课程)", this one derived from the mindset and innovations of the hacker community, which is sounds fascinating to bring that into account of a computer science program and necessary.

81
00:08:48,154 --> 00:08:49,510
I think the right thing to do surely.

82
00:08:49,510 --> 00:08:59,650
So please talk about how these professional experiences contributes to your approach now to cyber security, and how they lead to your job at DARPA

83
00:09:00,030 --> 00:09:11,630
starting in the 2018. I am very grateful to Dartmouth for letting me do this for taking me on as a research of shoot on one of their cybersecurity efforts.

84
00:09:12,340 --> 00:09:19,110
I started with a machine learning application of a cyber security.

85
00:09:19,600 --> 00:09:35,496
But by that time, I was already interested in how an exploitation worked, how exploits were written, how vulnerabilities were discovered and being a mathematician by education

86
00:09:35,496 --> 00:09:38,034
I wanted to systematize this.

87
00:09:38,034 --> 00:09:51,030
So I started showing up at the hacker conventions, such as the DefCon, and what I realized very soon was that there was a curriculum(课程) there, which the community came up with.

88
00:09:51,600 --> 00:09:58,180
It was distributed and split up between various minds and groups.

89
00:09:58,180 --> 00:10:12,820
But there were, a consistent sets of things that newcomers learned, and even though they had some interaction with how we took computer science and computer programming in academia(学术界), they were not quite the same.

90
00:10:12,870 --> 00:10:28,350
And in many aspects, ah, they actually, went deeper on how things worked, and so I started systematizing this discipline(学科), which I maintained it has become as of at least late 1990s.

91
00:10:28,440 --> 00:10:46,750
And I tried to extract that hidden curriculum, and I had support from my supervisors of Dartmouth doing that, and I have support to bring in students to the computer hacking conferences and then exposing them to this hidden curriculum.

92
00:10:46,750 --> 00:10:56,910
And it turned out that it translated to impressive undergraded and then graduate dissertations(学位论文), all in all, I find that this work is not done.

93
00:10:57,230 --> 00:10:57,622
Ivan Amato: Right

94
00:10:57,622 --> 00:11:05,350
Well, it of course is not done because of there's innovation going on, both in those were seeking new and more powerful exploits,

95
00:11:05,350 --> 00:11:15,860
and those who are worried about that and trying to to come up with countermeasures(反制措施) and defenses against that and everybody in there has to be brilliant, so it's kind of an amazing dynamic going on.

96
00:11:15,860 --> 00:11:41,465
So now, before we talk about your programs, and I think it's scared of algebra's out of listeners who might not know about some of the hazards and wait and sort of, all the software we use, and perhaps how they are even contributing to some of the hazards, and in practices that they engage in the, info sphere, I really want to talk about the way you think about an engaged cyber space in the info sphere.

97
00:11:41,465 --> 00:11:50,080
We sort of began to get into that a little bit, but you know, as I've looked over your programs and really try to understand where you are coming from, and which you are trying to achieve.

98
00:11:50,290 --> 00:11:59,930
As I looked over your Dartmouth College page, your lab page, a sort of metaphor(隐喻) came to my mind about you, which is, and maybe one way of thinking about it is

99
00:12:00,000 --> 00:12:07,960
All of us.  Most of us are drivers, and when we were out there driving, we're paying attention to the various hazards of the road, you know, very traditional things.

100
00:12:07,960 --> 00:12:10,096
What's happening with the street lights ?

101
00:12:10,096 --> 00:12:14,665
Are we going to be able to make it through that yellow, are their children on the side of the road ?

102
00:12:14,665 --> 00:12:18,756
You know, what's the weather is.  It looks like there's about to be a downpour(倾盆大雨), right?

103
00:12:18,756 --> 00:12:23,699
All of us sort of have a sense of these hazards are their part holes coming in the condition of the road.

104
00:12:23,699 --> 00:12:34,100
you know, I imagine that you are looking at the info sphere, kind of driving through that world with that same kind of heads up view on these kind of obvious hazards.

105
00:12:34,250 --> 00:12:44,000
But more than that, I kind of imagine you having almost the sixth sense in being able to see even what might be hidden hazards

106
00:12:44,000 --> 00:12:55,740
you know, let's say, there's a sink hole, and it's just now, as I'm coming upon it about to open up with my cars gonna to go in there, something that you could not see from the surface, but somehow you can see through the road.

107
00:12:55,740 --> 00:13:05,700
And you see that sink hole about to start, I get the feeling you have that sixth sense in the information technology and the cyber sphere to see what we really need to worry about.

108
00:13:05,990 --> 00:13:09,620
Okay, that's me terribly describing your mind.

109
00:13:09,770 --> 00:13:11,480
You know your mind better than me.

110
00:13:11,700 --> 00:13:20,635
So, talk to me about that cognitive framework that you bring in to this cyber rich world that we live in.

111
00:13:20,635 --> 00:13:24,420
On the ex three vision of vulnerability is a lot to claim.

112
00:13:24,770 --> 00:13:41,130
I certainly do not claim that what I could claim is a lot of trepidation(不安) and reluctant(不情愿) using some technologies that I know are not as dependable or as simple as they could be.

113
00:13:41,360 --> 00:13:44,150
I am the person with no personal smart phone.

114
00:13:44,610 --> 00:14:02,410
I am the person who, before engaging with the website tries to see what the website looks like with all the executable bits, a javascript, disabled, and mostly it looks like nothing, which is too bad.

115
00:14:02,560 --> 00:14:23,360
Because for most of those websites, and for most of those tasks that I want to complete on them, they have no business executing code on my computer and then pulling code from their associates, maybe commercial advertising or analysis associates, and then executing their code on my computer.

116
00:14:23,780 --> 00:14:26,190
And then the code from their associates as well.

117
00:14:26,510 --> 00:14:31,196
So you consider these all to be almost like nested vulnerabilities.

118
00:14:31,196 --> 00:14:31,900
They are indeed.

119
00:14:31,990 --> 00:14:38,680
One of the best examples of this is probably the thing that everyone uses every day, the web based email.

120
00:14:38,990 --> 00:15:11,340
But when I look at the web browser, I see a machine for denying the user the understanding of where those are graphic elements in the email were in the overall pain of the browser up come from or where they eat if you click on them, it is the browser's goal to seamlessly blamed all of the content and hide the possible directions.

121
00:15:11,550 --> 00:15:19,620
But at the same time, it doesn't let me see what my next action would actually bring about.

122
00:15:20,190 --> 00:15:28,030
Now for me, I can second guess this for a typical user of such a webmail.

123
00:15:28,580 --> 00:15:30,340
This is the tool order.

124
00:15:30,820 --> 00:15:39,520
Imagine we make our trust decisions and based on the province of what we hear and see them directly.

125
00:15:40,030 --> 00:15:46,580
And here we were denied any visual cues or any cues at all to that province.

126
00:15:46,920 --> 00:16:15,830
Speaking of a protocol, this is a very slow process, but some people could see that bottle hole ten years ago, it was actually hit. One of my programs documents deals with another search photo are peaceful of electronic documents that we all exchange, and we are to not click on if we can't really verify where it came from.

127
00:16:15,830 --> 00:16:24,940
But then, of course, see the previous point about webmail most of the time you are denied any cues as to where it actually came from.

128
00:16:25,460 --> 00:16:49,760
But of course, it is our job to click on those documents, read them, send them onwards(向前), any ambiguity in the description of these formats is insecurity, and that insecurity will hit us ten years or or five years from now, from all from when it was introduced, people might say, well, it is okay.

129
00:16:49,760 --> 00:16:51,630
We have anti-virus programs.

130
00:16:52,510 --> 00:16:58,550
We can check, and we have firewalls, and we have other devices that could just check for mals.

131
00:16:59,100 --> 00:17:12,504
However, it's typical because of the format, ambiguities for all the readers and interpreters of electronic documents to disagree about what those documents actually contain.

132
00:17:12,504 --> 00:17:22,040
It's been a hacker's sport to make a file like a PDF document appear differently in different viewers.

133
00:17:22,670 --> 00:17:28,270
It will similarly use a little different to the anti-virus or an application firewall.

134
00:17:28,450 --> 00:17:39,830
And so if you can't really agree with all your electronic helpers and applications want what is actually in the document, what better way to hide malaysia ?

135
00:17:40,170 --> 00:17:51,140
And again, this is something that fundamental computer science can tell you that will result at in those.

136
00:17:51,180 --> 00:17:57,783
But as we call the parsing differentials of those data formats and those documents.

137
00:17:57,783 --> 00:18:03,519
I'm glad that you have began to talk about your programs you started with safe documents.

138
00:18:03,519 --> 00:18:10,350
Actually that's one of the easier ones of yours to say one of the other easier ones is assured micro patching or AMP.

139
00:18:10,350 --> 00:18:20,350
I'm actually just gonna read all of the DARPA names because they are so DARPA. And DAPRA is known for its names and acronyms just for listeners to hear them.

140
00:18:20,390 --> 00:18:25,780
And then we're not gonna acceptably really go through each one, because we would be here for quite a long time.

141
00:18:25,780 --> 00:18:29,190
I would love to, but we can't have a five-hour podcast.

142
00:18:29,190 --> 00:18:33,400
We lose everybody, but let me just read them because they are beautifully multisyllabic(多音节的).

143
00:18:33,780 --> 00:18:35,610
And they gave some sense of what you are up to.

144
00:18:35,610 --> 00:18:44,300
So here we go, Artificial Intelligence Mitigations of Emergent Execution, or AIMEE.

145
00:18:44,300 --> 00:18:50,428
verified security and performance enhancement of large legacy software or V-SPELLS

146
00:18:50,428 --> 00:18:54,863
recovery of symbolic mathematics from code or ReMath

147
00:18:54,863 --> 00:18:59,131
hybrid AI to protect integrity of open source code.

148
00:18:59,131 --> 00:19:06,709
And we've already mentioned SafeDocs and Assured Micro Patching(AMP), and there is even one more,  I think this is the newest one that got approval is

149
00:19:06,709 --> 00:19:13,641
is called, HARDEN and that's short for hardening development toolchains against emergent execution engines.

150
00:19:13,641 --> 00:19:40,067
What a mouthful that is, it sounds like quite an ambitious set of programs to decrease our vulnerabilities, as we been talking about, but since we can't really go into any depth with these, certainly not all of that. Maybe you can pick and choose and sort of walk through your programs you spend, you know, as little or as much times you want on this one or that one, it just to give us a sense of what, in fact, you are worried about.

151
00:19:40,067 --> 00:19:47,990
And what kinds of problems you're trying to solve, all the interests of increasing security for our war fighters are also for all the civilians out there.

152
00:19:48,210 --> 00:20:01,880
Certainly, and I would borrow a phrase from one of the famous security researchers, who said, the point of our profession, is making computers that we could finally trust.

153
00:20:02,370 --> 00:20:07,720
Which, of course, hurricanes to the fact that we cannot trust computers as we make them now.

154
00:20:08,000 --> 00:20:10,300
But, and who, who said that, who is that famous person ?

155
00:20:11,000 --> 00:20:16,130
It is Felix Linder, a researcher from berlin.

156
00:20:17,430 --> 00:20:25,218
Now we cannot trust computers we built today, and we can not trust software we built today.

157
00:20:25,218 --> 00:20:31,210
And part of the reason is, even if we build them exactly to the specification.

158
00:20:31,280 --> 00:20:51,535
And even if there is no ambiguity, but all the morsel, if there raised some ambiguity(含糊) in that a specific issue, we end up building what we intend, and something else. That something else turns to be a lot friendlier to the attackers, to the exploiters.

159
00:20:51,535 --> 00:20:54,161
Then we've ever intended to be.

160
00:20:54,161 --> 00:21:02,170
It's as if packaged with your shiny work station or your server is the kit for exploiting that server.

161
00:21:02,620 --> 00:21:16,663
And this is what I refer to as emergent execution uh, emergent properties of computing systems, properties that we never met them to have needed the hardware and other software, not the combination there are of

162
00:21:16,663 --> 00:21:29,500
But yet they allow the adversary to reprogramme computers, reuse existing, well-debugged pieces of software before attack purposes.

163
00:21:30,160 --> 00:21:40,290
And this is the aspect of the computers that I would like to reduce, mitigate and eliminate where possible.

164
00:21:40,390 --> 00:21:43,890
Right, so maybe I can ask you to take that another level further.

165
00:21:43,890 --> 00:21:46,930
We have given us kind of the helicopter view.

166
00:21:47,020 --> 00:21:48,270
And then your programs.

167
00:21:48,270 --> 00:21:53,240
I imagine are designed to go after a specific categories of vulnerabilities.

168
00:21:53,240 --> 00:21:57,750
So maybe just talk about two of the ones that may be our particular interest in reports.

169
00:21:57,780 --> 00:22:03,101
So here is, a are likely to find save dogs or save documents.

170
00:22:03,101 --> 00:22:15,510
Looks at the information interchange formats, the formats in which data arrives at our computers and arrives at our software, and will also sometimes exploit them.

171
00:22:16,080 --> 00:22:26,150
Now, how do we build code that can safely intake a data that might be hostile or might have been manipulated ?

172
00:22:26,150 --> 00:22:39,460
How do we make software that agrees on what is in the message between the various computing components that are involved in the the flow of our email of our documents ?

173
00:22:40,130 --> 00:22:47,770
How do we, as we say, parse the data securely, or how do we intake data securely?

174
00:22:47,970 --> 00:23:16,120
This is a SafeDocs, and then, of course, now, that we found some vulnerabilities or ambiguities, we want to fix those vulnerabilities in the date intake, and very typically, those vulnerabilities are like a single check on the input data that was assumed was done, but was actually never done by the actual software doing the data and take the passer.

175
00:23:16,570 --> 00:23:33,202
So how do we patch those vulnerabilities usually is a simple check, but the problem with a simple change to any binary software is that you have to make sure that you are not destroying something else. You are not

176
00:23:33,202 --> 00:23:40,850
damaging the baseline functionality of your device and the methods and tools for insuring it is AMP.

177
00:23:40,930 --> 00:23:47,875
I just have to say, so, what's fascinating about that description to me is that there is a parallel in genetic engineering.

178
00:23:47,875 --> 00:24:05,288
We're, if you're going to make a change, even a varies tiny point change, changing one omenos at a protein, or or just one DNA nuclear tide, sometimes that will have effects on, other proteins that you never thought would be involved, given your initial intention.

179
00:24:05,288 --> 00:24:09,186
So it's kind of the same way, right, a patch going into legacy software.

180
00:24:09,186 --> 00:24:13,700
You'll, you're after, you know, it fixes and try to increase security, but you don't know.

181
00:24:13,770 --> 00:24:19,138
Maybe there is another set of changes that are deleterious(有害的) that you would would regret.

182
00:24:19,138 --> 00:24:26,250
That's right, well, each and every one of us, we are computing devices [laugh] besides other the things.

183
00:24:26,460 --> 00:24:29,950
So this is a very valid analogy(类比).

184
00:24:29,950 --> 00:24:39,950
And then, of course, you might want to check how you could add components or add features to a system without disrupting it.

185
00:24:39,950 --> 00:24:42,730
And this is the V-SPELL program.

186
00:24:43,160 --> 00:24:46,260
So let me just go to one that gets back to your.

187
00:24:46,260 --> 00:24:53,625
I would say earlier interest, you know, your interests as a mathematician is the recovery of symbolic mathematics from code.

188
00:24:53,625 --> 00:24:55,000
So this is sort of working backwards.

189
00:24:55,000 --> 00:25:03,010
It sounds like from the software, to mathematical formulations that maybe were at the heart of what the programmer was trying to do.

190
00:25:03,010 --> 00:25:05,600
Now, why is this an important ability?

191
00:25:05,960 --> 00:25:34,950
It is extremely important when you encounter legacy software as you rely more, as we all rely more and more on algorithms controlling our power, power, medical devices and or even our cards, you want to make sure that the intended algorithm are with the engineer planned to put in that device is actually what the device does.

192
00:25:34,950 --> 00:25:49,320
So connecting back the binary form of software to the symbolic form of mathematics that the software and codes, it is an extremely important step in making sure that our devices are trust worthy.

193
00:25:49,900 --> 00:26:04,350
Very often, you don't have the source code in legacy software, the company that may, the thing the device went out of business, or it might not have gone out of business, but it actually lost the source code.

194
00:26:04,800 --> 00:26:07,260
This has happened to companies begin small.

195
00:26:07,620 --> 00:26:22,680
What would like to do is still be answer the question of does this books do, what it what was intended to do, and what was it in control engineering terms?

196
00:26:22,900 --> 00:26:39,445
Interesting question comes to mind now that as you work backwards from software to, sort of, the original mathematical formulations and algorithms, does that uniquely to one mathematical formulation was impossible that you, you might have several.

197
00:26:39,445 --> 00:26:45,620
And then you still left with the question of what was the actual original intent in the regional mathematical formulation?

198
00:26:45,990 --> 00:26:58,940
You certainly end up with the several and in fact the whole continue, because there are many different ways to write down the same as medical formula, and many more to encode that formula in code.

199
00:26:59,250 --> 00:27:13,770
And of course, not all code comes from mathematical formulas, but for the well engineered systems, for the so called control processers that control things such as engines or generators.

200
00:27:14,240 --> 00:27:24,390
There is a well-engineered symbolic mathematical theory of how they work, and we should be able to discern(分辨) that in code.

201
00:27:24,390 --> 00:27:27,616
This is, what ReMath attempts to do.

202
00:27:27,616 --> 00:27:30,830
right. This is something like embedded processors in the grid.

203
00:27:31,060 --> 00:27:40,440
And there are certain other things you can bring in to kind of rule out 5 candidate mathematical formulations, cause you know what it should look like in this particular engineering category.

204
00:27:40,510 --> 00:27:41,280
That's right.

205
00:27:41,280 --> 00:27:44,330
This aims to help the subject [...] experts.

206
00:27:44,500 --> 00:27:50,780
This aims to put together the specialist in the binary and in the control algorithms.

207
00:27:51,010 --> 00:27:53,556
Or control engineers

208
00:27:52,556 --> 00:27:54,150
Q: When you say binary, what do you mean?

209
00:27:54,430 --> 00:28:01,840
The executable code, as a compiled form of it that finally goes into the memory of the device on controllers and it's operation.

210
00:28:01,840 --> 00:28:19,242
We're only getting started.  I could keep asking questions because what you do fascinates me, and I want to know more and more, but I'm actually gonna suggest that listener to who have the common trigue to go to your program manager webpage on the website, and then to take a tour themselves to get at least some additional taste of all of your programs.

211
00:28:19,242 --> 00:28:24,289
You know, as we come to the end of our time here, I want to get into a couple of just bigger questions.

212
00:28:24,289 --> 00:28:33,530
This is the innovation, ecosystem and technology and society types of questions, what fascinates me about you is that you really have had experience in the three kind of major sectors.

213
00:28:33,530 --> 00:28:45,835
We tend to think about in the innovation ecosystem, right, so you started your career in industry in BBN and spent nearly twenty years in academy at DARPA, and you might return to that at the end of your time here in DARPA.

214
00:28:45,835 --> 00:28:48,993
And then here you are doing government work at DARPA since 2018.

215
00:28:48,993 --> 00:29:06,185
So when you look at those three players, universities and industry and government in the overall innovation ecosystem, specifically when it comes to the to sort of cyber security technology, how do you see each of those players contributing.

216
00:29:06,185 --> 00:29:07,820
It's a great question.

217
00:29:08,680 --> 00:29:13,950
I would say that, of course, the industry looks to deploy product.

218
00:29:14,550 --> 00:29:22,320
Academia explores new ideas and follows publishing trends.

219
00:29:23,300 --> 00:29:35,250
The role of DARPA has been to, at least in the success that I have seen has been to pursue things that could not be immediately made them to product.

220
00:29:35,660 --> 00:29:39,209
Or the industry might not believe could be made into products

221
00:29:39,209 --> 00:29:49,970
and encourage that kind of exploration, when which you could not justify(证明...有理) to your manager, to your shareholders as an industry worker.

222
00:29:50,300 --> 00:29:56,760
You mean, in that case, because there is a sense that there is, there is too much risk to go ahead to do that responsibly in a business context.

223
00:29:56,980 --> 00:30:08,300
But then, if DARPA comes in and has the benefit of managers like you, who can have programs that demonstrate, take the risk down in certain areas, then a company might say, okay, let's take this to a finish line.

224
00:30:08,300 --> 00:30:08,840
That's right.

225
00:30:08,890 --> 00:30:28,913
Whereas with the academia, well, you may have heard the phrase of publish appearash, which means that and academic research or not to have a successful career or any career at all is expected to produce at least several papers a year aimed at a difficult first-tier(第一类) conferences or journals.

226
00:30:28,913 --> 00:30:56,120
Now, those have some idea of which research directions are promising and interesting, but these often fail to encompass(围绕) significant parts of reality, including industrial reality, or even the parts of the industry, does not think about now, has been behind a several DARPA successes that I have experienced personally to define a new direction.

227
00:30:56,830 --> 00:31:06,760
Define a new trend and puts some grand funding behind the trend in order to get academia to listen

228
00:31:06,760 --> 00:31:09,500
Well, this is the need that you might be missing.

229
00:31:09,780 --> 00:31:20,780
This is the cool thing that might, with time create its own first tier publication venue(会场) of journal and conferences.

230
00:31:21,120 --> 00:31:24,020
And there, I believe, DARPA has been greatly successful.

231
00:31:24,210 --> 00:31:31,171
Thinking about this, what a great finish line, what a great result is a DARPA of which is to take a technology.

232
00:31:31,171 --> 00:31:46,534
Neither take the risk down so that someone else will pick it up, in sort of, transition, but a military service or to industry for additional development, sometimes programs just segway to another program to build on what has accomplished in the prior work

233
00:31:46,534 --> 00:31:58,670
when you scanning your own mind, your programs and the many research performers who are working on them who like to come to you now again, say, Sergey, Sergey

234
00:31:58,670 --> 00:32:10,000
Look what I've done. can you mention one or two of the maybe the more mature accomplishments that you think have a good chance of transition and becoming actual technologies in our lifes?

235
00:32:10,000 --> 00:32:30,850
One of the things that really excites me, it is on the SafeDocs program we've been working with the PDF association, which is an industry by the united, unites many stakeholders in the portable document format to produce a machine readable, unambiguous specification of the format.

236
00:32:31,750 --> 00:32:39,710
This is the first time ever that this has been attempted for a major format, with billions of documents out there.

237
00:32:40,020 --> 00:32:52,370
And of course, you cannot reinvent that format for that reason, because people would not take kindly to their documents being simply deemed and compliant and not opening.

238
00:32:52,370 --> 00:33:13,769
But I think we are on our way to reforming how the standards process, the international standards process at the international standardization organization, deals with the information interchange formats and how we might make our electronic documents much more trust worthy

239
00:33:13,769 --> 00:33:31,610
so that we would not actually be told to not click on documents and could rely on computers to securely process the data that comes in a documents and communications in the many sensor sheets that surround us.

240
00:33:31,700 --> 00:33:44,150
Okay, and let you spend one more minute on this PDF example that you bring up, and so that listeners who might not be in this world of increasing security, reducing vulnerabilities as they interact with, say, PDF documents.

241
00:33:44,280 --> 00:33:57,180
What is the security gain that you get by moving toward that kind of standardization that you just mentioned, and the, disambiguation on the part of the platform on which showing up.

242
00:33:57,180 --> 00:33:59,030
How does that increase our security?

243
00:33:59,030 --> 00:34:13,570
Directly and immediately remember the time of your training when starting to use any computing system, when you're told to never click on attachments from people you do not trust

244
00:34:13,570 --> 00:34:14,530
Why is that ?

245
00:34:15,190 --> 00:34:25,580
It's because documents these days are not equivalent of a simple sheet of paper with some passive content that you can read or ignore it [...]

246
00:34:25,760 --> 00:34:37,520
They are sophisticated programs that interact with the software on your computer, make it do things, trigger emergent properties.

247
00:34:37,680 --> 00:34:49,950
Emergent are parts in that software that no one wanted there, no one intended to put there in the first place, and that we could locally really know as the exploit.

248
00:34:50,980 --> 00:34:59,640
So when you talk to not click on documents, well, this is the part of the present that I would like to exclude from the future.

249
00:35:00,000 --> 00:35:06,778
It'll take a lot of effort, but unambiguous definitions of what you expect to find there.

250
00:35:06,778 --> 00:35:09,906
And what is denied and what is expected.

251
00:35:09,906 --> 00:35:11,210
isn't a three piece of it

252
00:35:11,210 --> 00:35:16,345
Super helpful for for someone like me who sees that I don't click, I don't clicks.

253
00:35:16,345 --> 00:35:18,131
Try to make that my practice.

254
00:35:18,131 --> 00:35:29,620
But now I understand that that in some ways that are hedge against some creative person who might have found one of these emergent executable pathways into my computer.

255
00:35:29,900 --> 00:35:33,000
Yeah, which are typically known as vulnerabilities.

256
00:35:33,150 --> 00:35:41,964
But because we don't know all of the vulnerabilities that could be in there, the broad brostroke solution of not clicking on it sort of solves a lot of problems.

257
00:35:41,964 --> 00:35:45,440
But you're saying, we know, that's not really good solution.

258
00:35:45,500 --> 00:35:47,050
Yeah, actually it doesn't work.

259
00:35:47,050 --> 00:35:53,100
Whatever your job is, you're intended to read things.

260
00:35:53,400 --> 00:35:55,790
Edit them, send them on.

261
00:35:56,780 --> 00:36:11,690
I don't think there is any professions these days that doesn't include some kind of form filling or manual reading, or any one of those tasks that do take electronic documents, so you can't just not click.

262
00:36:12,520 --> 00:36:19,100
So I often ask of my, my discussion leaders, who I presume our tech files, because here this is DARPA, right ?

263
00:36:19,210 --> 00:36:29,470
Um.. here's the question. I, I was always like to find out if there are technology that you dreamed about when you were in middle school or later, this don't have to be DARPA technologies at all.

264
00:36:29,820 --> 00:36:39,050
But just, you know, when you just sort of look back in your wish for, you say, oh, if that technology existed I would just love it, are there technologies like that for you?

265
00:36:39,640 --> 00:36:49,410
Of course, I mean ，I am the child of the space exploration age, or the a tail end there're of.(?)

266
00:36:49,630 --> 00:36:59,630
And so flying cars that can go to the moon, a rockets that teenagers could pilot.

267
00:36:59,630 --> 00:37:08,650
If you look back at some of those novels of Heinlein and others, that's what you see.

268
00:37:08,650 --> 00:37:21,500
And we are getting some not the flying cars yet, but certainly spacecraft, and that can land vertically, used to be straight Sci-Fi

269
00:37:21,500 --> 00:37:22,503
till it was not

270
00:37:22,503 --> 00:37:22,880
[Host] right.

271
00:37:22,880 --> 00:37:26,529
We do see that I have to say that the idea of millions of teenagers of

272
00:37:26,529 --> 00:37:31,565
piloting their own rocket is about the most frightening vulnerability I possibly can imagine,

273
00:37:31,565 --> 00:37:36,101
but maybe we can educate the teenagers to operate these things safely,

274
00:37:36,101 --> 00:37:37,990
I just have the image ever I actually do kind of love.

275
00:37:38,220 --> 00:37:44,070
One final question before I show you my gratitude for talking with me.

276
00:37:44,070 --> 00:37:48,529
And that's just, is there something, Sergey, that I should've asked you that I did not or

277
00:37:48,529 --> 00:37:52,670
just something else that on your mind that you think would be adventurous(新奇的) to our listeners.

278
00:37:52,980 --> 00:37:59,930
If I could say one thing on the technology in general, it is that, uh, it is exciting.

279
00:38:00,900 --> 00:38:09,098
But at the same time it brings large and unknown failure modes and vulnerabilities,

280
00:38:09,098 --> 00:38:18,158
getting too enthusiastic about technology to the point of mandating its use is hardly ever a great idea in my book,

281
00:38:18,158 --> 00:38:23,795
you can call me a techno-fobe(排科技主义) or a combined techno-file and techno-fobe (?)

282
00:38:23,795 --> 00:38:34,290
but mandating of the use of any particular technology also means mandating the use of the vulnerabilities that come with it.

283
00:38:34,730 --> 00:38:42,800
And so any such decisions, any sessions enthusiasms should be tampered by the understanding that this is what happens.

284
00:38:43,810 --> 00:38:44,140
[Host] right

285
00:38:44,140 --> 00:38:52,989
And so one way I think about what you just said is that a question that has to be there in the technology development process is

286
00:38:52,989 --> 00:38:55,528
what could possibly go wrong, right ?

287
00:38:55,528 --> 00:38:59,980
And that all we should be part of the practice that is sort of hygiene(保健?) for technology development.

288
00:39:00,000 --> 00:39:04,248
That is true, but I would also take it further.

289
00:39:04,248 --> 00:39:13,100
I would say that listening to rejectionists of any particular technology is underrated(被低估).

290
00:39:13,780 --> 00:39:23,400
They might, in fact, be right in certain ways that a people more enthusiastic about the technologies might not have foreseen(预见)

291
00:39:24,450 --> 00:39:25,950
So we must deal with caution here.

292
00:39:26,580 --> 00:39:32,546
I believe, love that balanced perspective of being excited in a techno feel of sense

293
00:39:32,546 --> 00:39:38,487
but also having that sense of respect and eyes wide open and caution and fear of unintended consequences that

294
00:39:38,487 --> 00:39:42,754
justified a little bit of a techno-fobe component, as well as you move forward.

295
00:39:42,754 --> 00:39:45,567
So that's really, really interesting to hear.

296
00:39:45,567 --> 00:39:48,082
Sergey, we're out of time.

297
00:39:48,082 --> 00:39:54,620
So let me just thank you for helping me understand a bit more about the cyber security and insecurity landscapes.

298
00:39:55,010 --> 00:40:01,111
And I have to say, I am really hardened that people with your expertise and attentions,

299
00:40:01,111 --> 00:40:06,090
which is to say, people exactly like you in particular, I am happy around the case.

300
00:40:06,160 --> 00:40:08,170
It was just a real blast for me to talking to you.

301
00:40:08,540 --> 00:40:10,960
Thank you for having me and it's great to be here.

302
00:40:12,010 --> 00:40:17,980
And thanks listeners for sharing this time with us, I hope you join us again for the next Voices from DARPA.

303
00:40:20,510 --> 00:40:26,891
Thanks also, to Tom Shotrage for his partnership and producing this program,

304
00:40:26,891 --> 00:40:30,241
for more information about Dr. Sergey Bratus

305
00:40:30,241 --> 00:40:35,072
the programs he and colleagues in the agency's Information Innovation Office,

306
00:40:35,072 --> 00:40:38,640
and many other breaks through technologies DARPA's working on,

307
00:40:38,640 --> 00:40:39,926
visit DARPA.mil

308
00:40:39,926 --> 00:40:49,350
And for links that enable you to download this podcast, go to the Voices from DARPA page on DARPA's website.
