1
00:00:11,570 --> 00:00:30,960
Scoff technology , the internet GPS in the column of your hand on tournament technology is a driver of our times since its founding in nineteen fifty eight , in the midst of the cold war , in doubt , the defence advanced research agency has been a driver of technology . 

2
00:00:31,420 --> 00:00:38,750
Welcome to a voice from drug , a window on the dark as core of program managers , their job to redefine what is possible . 

3
00:00:39,060 --> 00:00:41,915
My name is iphone motel on your job host today . 

4
00:00:41,915 --> 00:01:01,310
I am pleased to be talking with that to boost draper , a program manager since twenty nineteen in the agencies information innovation office , we are recording our conversation from our respective homes as we do our parts to slow spot of covered nineteen , because we are not in , according to do , you might hear ambient sounds like traffic and birds like we say a little bit about boost . 

5
00:01:01,310 --> 00:01:32,469
He joined the DARPA from colorado state university , where he is unlearned from the department of computer science and much published research leader who has been a principal or cool principle investigator , twenty oriented projects in a diversity of areas , amounts are biological inspired machine vision , reinforcement learning on management vehicles , facial recognition and action recognition by computer systems and community ring through gesture throughout his education , it was computer science . 

6
00:01:32,469 --> 00:01:33,066
All the way . 

7
00:01:33,066 --> 00:01:40,040
Blues urged his bachelor's degree from male university and his master degree in PHTfrom the university of messages at . 

8
00:01:40,040 --> 00:01:50,127
He also has been a generous community builder in the artificial intelligence are in the community , having health leadership positions in the planning and organization of many conferences . 

9
00:01:50,127 --> 00:01:59,080
And now he is being all of that CS training , that his computer size training and confidence and credit to dark blue stripper , thanks for joining today . 

10
00:02:00,000 --> 00:02:21,909
Yeah , it looks to me like you knew , even as a young man , which is the seven year undergraduate , yell that you in computer science were a match and working on , see how that love of computer science is still part of who you are when we talk about your programs , particularly in intersections with artificial intelligence and the relationship between computers and people . 

11
00:02:21,909 --> 00:02:24,869
But i'm fascinated by this embrace of computer science . 

12
00:02:24,869 --> 00:02:27,040
I developed to know the origins of that. 

13
00:02:27,040 --> 00:02:33,179
When I went to college , I never touched the computer , because , well , it was one thousand nine hundred and eighty , and they were the current . 

14
00:02:33,179 --> 00:02:41,680
My fashioner result was going to be a flashy major , and I found I was a bit of not bird's flash student because I loved logic , and I wasn't that fund of ancient greek . 

15
00:02:41,800 --> 00:02:48,450
I said about the same time I took a computer science course , and I certainly realized where applied logic was going , and how much fun it was . 

16
00:02:48,450 --> 00:03:05,030
Three of the new logic , billions of second plus a year at that time was not had a large program in artificial intelligence , and they are just immediately fit into everything I wanted to do in terms of of learning about reasoning in perception and how people think and why we believe what we believe that. 

17
00:03:05,030 --> 00:03:16,677
You've got your first academic appointment as post up in nineteen ninety three , and since nineteen ninety six , you , colorado is the university of the computer science department of professional home . 

18
00:03:16,677 --> 00:03:28,490
So what was the sequence events that lower you from this one time academic life , and I still part of your life , and you can go back to what loads you from there to dark and become a program and result. 

19
00:03:28,970 --> 00:03:35,126
Well , you are eating the medicines , always multiple reasons why why we do things , and certainly one of them was patriotism . 

20
00:03:35,126 --> 00:03:42,401
If you were a chance to give back to the country that given so much to me , but it was also part of it was an electoral moment as well . 

21
00:03:42,401 --> 00:03:48,060
I spent as much of my career working on record computer vision , trying to get computers to see . 

22
00:03:48,160 --> 00:04:00,940
And in the last ten years or so , there had been real break rules in that area , which is why you now see things like autonomous vehicles and face recognition on facebook and all of these sorts of things . 

23
00:04:01,000 --> 00:04:08,600
And so it certainly felt to me like , there is a sea change , and that I spent a lot of my life time to figure out how to get computers to see . 

24
00:04:08,920 --> 00:04:10,780
And now the question was great . 

25
00:04:10,780 --> 00:04:11,660
We can do that . 

26
00:04:11,660 --> 00:04:19,192
What should they look , and how are we going to use this , and how are we going to integrate these intelligence systems and into artificial intelligence ? 

27
00:04:19,192 --> 00:04:32,450
And that's a very hard thing to do from the perspective of the single laboratory , but at a place like dark , or you can create programs to help define the field and increase in electrical communities of people that are trying to tackle brand new problems . 

28
00:04:32,450 --> 00:04:36,530
And that's an opportunity so you can do it dark , but you just can't do anywhere. 

29
00:04:36,640 --> 00:04:53,630
You're touching out one of the things that I find most fascinating institutionally about darker programmers who do get in this position where , where they can really be community builders that can really have a major role in the direction that an entire field I can see that you coming from the trenches in the sense . 

30
00:04:53,630 --> 00:04:59,920
And then looking at the top as a way of giving some direction to , they feel that you had really become central to when I was a graduate. 

31
00:05:00,000 --> 00:05:08,920
I worked on the dark of a funded project early in the days of computer vision , back when darker flag computers could see in nobody else thought they ever would . 

32
00:05:08,920 --> 00:05:15,661
And so he said , now that we thought of reached a level of success of just visions with a chance to go back to the organization . 

33
00:05:15,661 --> 00:05:16,539
What is the next step ? 

34
00:05:16,539 --> 00:05:21,630
What are the next big things we need to work on , and that was just too exciting , and possibly for me to pass up. 

35
00:05:21,630 --> 00:05:25,150
Okay , so let us move into your job experience . 

36
00:05:25,150 --> 00:05:28,670
And you've been at the age seasons twenty eighteen . 

37
00:05:28,670 --> 00:05:34,888
You inherited a few programs that were started by previous program managers , which is held things often worked at dark . 

38
00:05:34,888 --> 00:05:42,358
Others are kind of a handle of the book on at times , but you also started some of your own , and we'll talk about in all of these . 

39
00:05:42,358 --> 00:05:48,011
Actually , the one I want to start with is known as god that spelled GARD. 

40
00:05:48,011 --> 00:05:52,790
That's the account for guarantee AIreal business against reception . 

41
00:05:53,070 --> 00:05:59,290
And this falls within what list for me has been a little known arena of AAcold , adversarial air . 

42
00:05:59,290 --> 00:06:18,495
The , you know , we already know that AItools , such as facial recognition relied algorithms that data sets the people can pose and design and courage means that human biases and assumptions can get built into the systems , but guardia's , starting with the assumption that every series will deliberately try to mess with AIsystem . 

43
00:06:18,495 --> 00:06:22,940
So I want you to talk to be about these threats and what you hope to achieve the problem. 

44
00:06:22,940 --> 00:06:30,395
Well , I mentioned earlier than the last in australia's computer vision is suddenly becomes something that is robust , becomes something as useful . 

45
00:06:30,395 --> 00:06:33,304
And so we're starting to use it , nor kinds of systems . 

46
00:06:33,304 --> 00:06:34,940
Think about soldiers and cars . 

47
00:06:34,940 --> 00:06:35,850
Think about it . 

48
00:06:36,050 --> 00:06:55,852
And if you're sitting in a self driving car , you really want to make sure that it works correctly and buying largely well , unless there's somebody lose some adversaries out there trying intentionally to break the world little less than ten years ago , there is a research who discovered that you could add a little bit of noise to an image , and as a human being , you wouldn't notice it . 

49
00:06:55,852 --> 00:06:59,980
But if they added the right kind of noise , they could break the computer region . 

50
00:07:00,000 --> 00:07:20,420
AI system will think with the wrong logic , and people said , okay , that theoretically , you can do in the love you had to add , you know , exactly the right numbers to exactly the right tickets , and then alone comes on researchers who , but is sticker on a step , but they put it in just the right spot , such that as you drove by it , the camera would look at it and go . 

51
00:07:20,420 --> 00:07:21,570
That's not a stop sign . 

52
00:07:22,070 --> 00:07:29,470
That's a speed limit , sound , and all of the certain things got scary , right , if you are the south driving car , you want to drag eyes that shop shop . 

53
00:07:29,820 --> 00:07:47,697
So we begin to realize that there were things that actual series could do intentionally to try to support your assistant , and as air systems become more and more part of of safety critical systems , this was going to be a major issue , and hence the area of vascular editorial eye was born . 

54
00:07:47,697 --> 00:07:54,873
How do you make an AI system that cannot be missed , but somebody else , anything interesting causing the senses . 

55
00:07:54,873 --> 00:07:58,521
This is brand new , and it's AI and thai jack , but it's sort of . 

56
00:07:58,521 --> 00:08:06,730
It's an old story of you used to be the in the military , you , you looked at your enemy , human arguments , and so your enemy developed camouflage . 

57
00:08:07,220 --> 00:08:10,420
And then we did great hours for people came up with stealth . 

58
00:08:11,190 --> 00:08:15,530
Now we're using artificial intelligence programs to look at camera data . 

59
00:08:15,530 --> 00:08:21,560
Look at that late day to look at all kinds of instruments that people will try to foreign for it. 

60
00:08:21,980 --> 00:08:27,230
God is really looking at this , this sort of one language of deception . 

61
00:08:27,230 --> 00:08:45,460
But now in a artificial intelligence context , tell me a little bit about what kind of technological directions that you and your performers that is to see the researchers who you are a well contract with under this program will take and trying to defend against such deceptions. 

62
00:08:45,860 --> 00:08:47,600
We're taking it a two pronounced attack . 

63
00:08:47,960 --> 00:08:50,730
We could call it practice , on one hand , in theory of the other . 

64
00:08:51,400 --> 00:08:59,420
So for the practice , we are building in evaluation framework allows anyone to come up and say , here is my assistant . 

65
00:08:59,420 --> 00:09:08,621
I've come what defends for it , and we have the system that will automatically attack it growing to all of our knowledge and tested the value , waited , and using . 

66
00:09:08,621 --> 00:09:16,055
This is trying to get people to come up with air rhythms that are not acceptable to being full was not accessible at the same time . 

67
00:09:16,055 --> 00:09:22,647
Think about an episode is you never know if they're gonna do , maybe they thought of a tricky habit . 

68
00:09:22,647 --> 00:09:32,962
So at the same time , I really had to to push the theory behind it , and three little time come up with systems that we can prove cannot be supported within certain reasonable bells . 

69
00:09:32,962 --> 00:09:47,970
And so we have a practice side of this program , which is time to create new learning algorithms that will be less acceptable to attacks and the same time trying to come up with a theory that don't tell us how successful we are at that , and what the limits of that are . 

70
00:09:47,970 --> 00:09:53,238
There may be certain things that some economists do it if they turn off your camera , you're not going to see you then . 

71
00:09:53,238 --> 00:09:59,980
So you are trying to change where the theoretical limits are , while the same time developing a fundamental new defence of our groups. 

72
00:10:00,000 --> 00:10:07,420
And what about on the level of the data sets for learning and for training air are there vulnerability? 

73
00:10:07,450 --> 00:10:08,570
There are these . 

74
00:10:08,570 --> 00:10:10,880
There is , there is a lot of fun , different ways . 

75
00:10:10,880 --> 00:10:15,570
One of my detectives and one of them is what we call informally poisoning . 

76
00:10:16,210 --> 00:10:22,250
That is to say someone can hand you a training set that has been that has been altered in sexual way . 

77
00:10:22,500 --> 00:10:27,003
The system you learn based on that data will do the wrong shape . 

78
00:10:27,003 --> 00:10:35,759
And if they're clever , the system you learn will do the right thing most of the time , but be food , and they want to take your own sense . 

79
00:10:35,759 --> 00:10:38,050
They care about an episode , data poisoning . 

80
00:10:38,180 --> 00:10:43,830
And that is absolutely one of the ways you can attack an air system , and it is one of the things that time to develop. 

81
00:10:43,930 --> 00:10:49,100
This is sort of reminds me of every example of , you know , where the solution becomes the problem , right ? 

82
00:10:49,100 --> 00:10:58,100
Because in a sense , we want AIto be a solution and helpful in a lot of ways , but because it has vulnerabilities , it also does stand the chance of becoming a problem . 

83
00:10:58,100 --> 00:11:06,660
And of course , this is where I guess god comes in and trying to anticipate that vulnerability in potential problem and figuring out and manage that in the future. 

84
00:11:07,130 --> 00:11:13,900
Even unfortunately , I have always the royal technology , right , we love it because it doesn't have a new force , but with. 

85
00:11:14,750 --> 00:11:17,150
Okay , so we have a few more programs against these . 

86
00:11:17,150 --> 00:11:17,870
Lets move on . 

87
00:11:17,870 --> 00:11:28,853
One of them is related to this one , and is got a dozy of a name that leads , in this case to two economists , period by preparation and is getting out sort of defense against various air . 

88
00:11:28,853 --> 00:11:40,680
In another way , i'm referring here to for the academic QED for RML, and that is sort of for qualifying and symbol diversity for robust machine learning . 

89
00:11:41,380 --> 00:11:44,500
So bruce makes sense of that name for me . 

90
00:11:44,500 --> 00:11:51,430
And I was nervous and tell us how a success with this program will defend against those who might recognize. 

91
00:11:51,580 --> 00:11:55,291
So is the same general set up where you want to use an AIsystem . 

92
00:11:55,291 --> 00:12:17,163
Let's say , you want to use it to drive your toilets to be a good , good difference for many , of course , and what you want to do is make sure that an absolute campaign and everything we have this guarantee program , which is really about this long term effort to create a new area , bring new approaches to defending these AI systems , but that's going to take a while . 

93
00:12:17,163 --> 00:12:21,450
And we have AIsystems that we wanna be able to defend today . 

94
00:12:21,620 --> 00:12:24,670
So how do we do that right now ? 

95
00:12:24,670 --> 00:12:35,682
Our best defense of AIsystem is for economic sample , and the idea behind an example that maybe if I have an eye system , maybe you can foot . 

96
00:12:35,682 --> 00:12:45,480
But what if I have ten AI systems or twenty AI systems , or one hundred AI systems , all trying to recognize that subsidy , can you hold all of them ? 

97
00:12:45,700 --> 00:12:50,110
And the answer is , you might be able to follow them if there are two similar to each other . 

98
00:12:50,780 --> 00:12:59,980
But if I have ten or twenty , and I programs that are all you know , trained on different data , i'll try to do the same tasks , but doing it slightly differently . 

99
00:13:00,000 --> 00:13:02,096
That is hard to fool all of . 

100
00:13:02,096 --> 00:13:21,140
So the idea of the QED for our male program is trying to measure the diversity within your own symbol of classifiers and trying to train them such a way that , although you may fall , one of them , you want for all the classifiers all the time , and therefore we can still get the system as a whole work. 

101
00:13:21,380 --> 00:13:37,438
What fascinates me about the way you just said , that is its kind of the AI annual work to the idea that a diversity of people , diversity of mine said the diversity of makes you better and makes you more able to do things . 

102
00:13:37,438 --> 00:13:39,750
And so this is kind of an AI version of that. 

103
00:13:39,750 --> 00:13:41,586
And that's exactly what it is . 

104
00:13:41,586 --> 00:13:44,570
No AI is perfect , just like no person is perfect . 

105
00:13:44,950 --> 00:13:47,500
But you know , you get a lot of them together . 

106
00:13:47,500 --> 00:13:48,710
You hope to get a better seat. 

107
00:13:49,190 --> 00:13:53,840
Let's now move on to a couple of other programs that I think also are related in a way . 

108
00:13:53,840 --> 00:13:55,310
These are true that you inherited . 

109
00:13:55,460 --> 00:13:59,226
One is called communicating with computers recede up . 

110
00:13:59,226 --> 00:14:10,140
You see , and mother is learning with less labelling , which will talk about , and just a bit , the first one communicating with computer seems a bit like couples therapy for artificial intelligence and human intelligence . 

111
00:14:10,140 --> 00:14:29,536
Because if he had this , I think it , but you tell , tell me if I got this right is the challenge of enabling people to be human as the communicate with computers , which is to say that we should build language gestures , which is funny , because even though we're not together , we're talking on the phone , I actually am gesturing a very gesture in my own communication . 

112
00:14:29,536 --> 00:14:34,210
And also , we have words , we've gestures , facial expressions , and it seems like , what do you want hearing ? 

113
00:14:34,210 --> 00:14:40,140
This program is for computers to get all that as we communicate with this system is that right ? 

114
00:14:40,140 --> 00:14:42,160
And if so , how are you going about that ? 

115
00:14:42,160 --> 00:14:43,830
And what is the status of the program? 

116
00:14:44,040 --> 00:14:45,630
This program is nearly due to my heart . 

117
00:14:45,630 --> 00:14:49,340
I was actually a researcher on that program before I came to dark . 

118
00:14:49,340 --> 00:15:00,800
And together the program , the idea of the communicating with computer program is that computers are becoming less of a simple tool and more perfect partner . 

119
00:15:00,800 --> 00:15:06,004
So you don't really worry about how you can unique with the hammer you can pick up and drive . 

120
00:15:06,004 --> 00:15:08,606
And then you know , I thought you're going to do . 

121
00:15:08,606 --> 00:15:21,590
But as we got these smaller eye systems , the smaller eye systems were going to , perhaps that we don't , you know , for example , they may have gotta , often study some topic on the internet and have collected a lot of information . 

122
00:15:21,590 --> 00:15:27,877
They may have to change the scale , and over , you know , hours and hours of video that you haven't seen from a variety of reasons . 

123
00:15:27,877 --> 00:15:30,269
They may have information you don't have . 

124
00:15:30,269 --> 00:15:36,373
And the question is , how are you going to get to that because you don't know what the computer loves . 

125
00:15:36,373 --> 00:15:38,675
We had to throw up with people all the time . 

126
00:15:38,675 --> 00:15:43,170
It's called the conversation , right , and this is what we want to be able to do . 

127
00:15:43,170 --> 00:15:49,320
We want to have an appeal to peer conversation with the computer , not just a symbol . 

128
00:15:49,320 --> 00:15:50,840
You know , it gives you many using you . 

129
00:15:50,840 --> 00:15:52,020
So like what I don't know what . 

130
00:15:52,740 --> 00:15:57,130
And it turns out that period of your communication use really hard . 

131
00:15:57,130 --> 00:15:59,360
People are amazingly complex . 

132
00:15:59,360 --> 00:16:02,133
And we do , we use jesus , we use facial expression . 

133
00:16:02,133 --> 00:16:07,112
We use procedure , right , purchase of the inflation of our voice , right ? 

134
00:16:07,112 --> 00:16:12,740
We use all of these sources of information and without them , and communication is very hard . 

135
00:16:12,740 --> 00:16:14,294
They've got text , they go and eat . 

136
00:16:14,294 --> 00:16:18,180
Misunderstanding is you have over text because you don't have those things. 

137
00:16:18,180 --> 00:16:25,020
That channels of immigration , yeah , there are so many kind of flaming conversation is in the email on the web . 

138
00:16:25,050 --> 00:16:33,580
Taxi exchanges that if only we could see a brown , that's further a little bit or a little smile , perhaps we would have gotten more clearly . 

139
00:16:33,580 --> 00:16:36,570
What are conversing partner , we're trying to. 

140
00:16:36,920 --> 00:16:39,780
That she said it was so busy being sarcastic or funny is that. 

141
00:16:39,970 --> 00:16:41,260
Hello , everybody . 

142
00:16:41,370 --> 00:16:43,050
And so how would this actually happen ? 

143
00:16:43,050 --> 00:16:46,460
It sounds to me like then a computer would have a camera and watch me . 

144
00:16:46,460 --> 00:16:53,275
And then there be in a some system that would see these various parts of my face in different ways , or what my hands are doing . 

145
00:16:53,275 --> 00:16:53,475
it . 

146
00:16:53,475 --> 00:16:57,660
We've then incorporate that into its interpretation of the communication. 

147
00:16:58,100 --> 00:17:05,047
Gets exactly right , so we to them that we've got a camera that can see the human and a microphone says , you can hear them . 

148
00:17:05,047 --> 00:17:08,277
And what are things we discovered is it has to be too way . 

149
00:17:08,277 --> 00:17:15,438
So we also put up the screen with an editor that is the computer , because it's not just enough of the computer to recognize your gestures . 

150
00:17:15,438 --> 00:17:19,629
You have to recognise the computer gestures between the computer has suggestion . 

151
00:17:19,629 --> 00:17:22,074
So what happens if you got camera in a microphone ? 

152
00:17:22,074 --> 00:17:23,684
That's what you knew listening to you . 

153
00:17:23,684 --> 00:17:29,156
Meanwhile , you're also looking at the computer and listen to the computer so you can have a genuine two way conversation . 

154
00:17:29,156 --> 00:17:33,180
But the interesting thing is , in all these , advertisers have to have facial expression . 

155
00:17:33,530 --> 00:17:34,780
They have to just share . 

156
00:17:35,360 --> 00:17:43,280
They have to pass in a procedure in their voice , and all those things turned out that if you do them wrong , it's actually destructed . 

157
00:17:43,520 --> 00:17:50,580
But if you do them right , it adds a tremendous amount of conversations before I came to diagram as working on this project is performer . 

158
00:17:50,910 --> 00:17:54,220
We had to set up in the lab with a pile blocks in you in the computer . 

159
00:17:54,220 --> 00:18:00,885
We joined to build something , and we would bring students in , and we bring , and sometimes even like bicycle students . 

160
00:18:00,885 --> 00:18:03,720
And our problems , we couldn't get them to leave the lab . 

161
00:18:03,720 --> 00:18:07,440
They had so much fun talking to the computer and interacting with the computer. 

162
00:18:07,650 --> 00:18:08,880
That they just do not go home . 

163
00:18:09,280 --> 00:18:16,740
Now he would accumulate the furthest progress that a performer , one of the research , certainly program has gone the furthest , had gone. 

164
00:18:16,800 --> 00:18:18,363
How would you describe that ? 

165
00:18:18,363 --> 00:18:21,880
I would alter your questions by the inside on the kitty too ? 

166
00:18:22,520 --> 00:18:30,960
What if it is the system for , for building blocks where people woke up , and it's looking at your body , just shows it immediately knows for considerable things . 

167
00:18:31,220 --> 00:18:34,130
It knows when you are interacting with it when you talking to someone else in . 

168
00:18:35,120 --> 00:18:36,170
But where are you looking ? 

169
00:18:36,750 --> 00:18:47,060
What do you say , you wear your standing and you can do physical tasks with that like the little things on the box to the other thing that we did is there is a system at the stevens institute . 

170
00:18:47,060 --> 00:18:59,740
This system does interactive jazz in provincial , so you , you have jazz musician who starts in improvising , and then the system picks up and picks over for a bit neat , starts in private . 

171
00:18:59,740 --> 00:19:06,493
And they asked that the league backing forth , creating in private , national jazz pieces , and it's been really impressive watching them do this . 

172
00:19:06,493 --> 00:19:10,530
I don't didn't concert , but not a number of venues , and it's been really impressed. 

173
00:19:10,620 --> 00:19:18,379
Okay , then bringing those sort of applications back to what I guess the mission of double it is a day in the front of that defensive . 

174
00:19:18,379 --> 00:19:27,720
Can you just sort of take me through a scenario , the communicate with a computer in as much more human human festival will help me in a better future situation. 

175
00:19:28,180 --> 00:19:40,167
Well , you know , I think one of the biggest areas here is , if you think about the intelligence clearly and military intelligence , military intelligence is based on lots and lots of tiny pieces of information . 

176
00:19:40,167 --> 00:19:54,800
And the promise is no one person cleaning to read the more until the idea is , you can put all the information to a program , and then have the commanders who are planning the mission , talk to that program to find out what , but it knows which relevant to the current task . 

177
00:19:54,800 --> 00:20:02,240
So it is really important for things like military planning , or you wanted to incorporate the a diversity of information sources. 

178
00:20:02,240 --> 00:20:05,670
Okay , and so I wanted to move to another one of your programs . 

179
00:20:05,670 --> 00:20:14,498
You've got quite a portfolio that I think is related to this , in the sense that is really at making computers better communicators , better learners . 

180
00:20:14,498 --> 00:20:33,430
In fact , that words in the title of this one , learning with less labelling and the way accelerate on the website is described , the program aims to make the process of training , machine learning models more efficient by reducing the amount of label the data required to build a model by six orders or more of magnitude . 

181
00:20:33,430 --> 00:20:46,350
Select a million for the more , and by reducing the amount of data needed to adapt models to new environment to tens to hundreds of labeled examples , I guess , is supposed of many , many more examples it takes and training . 

182
00:20:46,380 --> 00:20:50,930
I've said all the things , but tell me , what is the goal that programme and satisfied? 

183
00:20:51,050 --> 00:20:54,451
First of all , about the state of the art in the moment . 

184
00:20:54,451 --> 00:21:10,650
So the state of the air in the eyes , we have a really good systems , for example , that we have a lot due computer vision that can recognize objects , very useful skill , but the systems are typically trained on maybe one hundred million images , and is part of that training . 

185
00:21:10,650 --> 00:21:17,647
Someone had to identify what each one of those hundred million images was that we've been by a label by temperatures . 

186
00:21:17,647 --> 00:21:20,403
Go in and buy him and say , you know , this is a cat . 

187
00:21:20,403 --> 00:21:24,172
This is a , yeah , is it a lot of labour and that a lot of labour . 

188
00:21:24,172 --> 00:21:35,326
It turns out that the natural language processing , where we've been also europe , and because understanding in generating english with this also been tremendous brakes , who is recently the scales even bigger . 

189
00:21:35,326 --> 00:21:37,826
Basically , people are turning on the internet . 

190
00:21:37,826 --> 00:21:46,357
They're using billions of input samples , but it's really hard to get that much training data labeled for our data unlabeled disease . 

191
00:21:46,357 --> 00:21:59,263
But getting that let me labels is very , very expensive , very , very timely , and frankly , in a lot of circumstances , it's not feasible at in the military circumstance , you might have sensitive data . 

192
00:21:59,263 --> 00:22:03,202
You can show it people who get that many labourers , or you don't have the time . 

193
00:22:03,202 --> 00:22:08,606
Maybe it's not a sensitive , but you need to answer tomorrow , it's going to take your year to label . 

194
00:22:08,606 --> 00:22:10,407
So we have to get an assistance . 

195
00:22:10,407 --> 00:22:22,854
I can learn not solving on the basis of tens of millions of samples are billions of samples , but on a handful of samples , saying systems that can learn from a very small certainty that the goal , this program is . 

196
00:22:22,854 --> 00:22:28,230
He said , our goal is to reduce the amount of training by a factory of the new year. 

197
00:22:29,060 --> 00:22:38,014
In some ways , it sounds like you're trying to make computers aids as smartest children , where it doesn't take nearly that many examples . 

198
00:22:38,014 --> 00:22:51,370
You know , when you , once they get the idea that something some kind of creature out there is a creatures in using the system of dogs , and that's a dog once they get , apparently takes three or four examples , prevent to learn what scholarly. 

199
00:22:51,370 --> 00:22:55,770
Or or even less than that , children are amazing , and AI is not in a reluctant level . 

200
00:22:55,770 --> 00:22:58,449
Children and children learn just amazingly fast . 

201
00:22:58,449 --> 00:23:00,198
But we do want to get to go in . 

202
00:23:00,198 --> 00:23:01,988
My children were two and three . 

203
00:23:01,988 --> 00:23:06,562
There is this annoying stage , and they're constantly asking you what everything is . 

204
00:23:06,562 --> 00:23:09,346
What's this , what's this , but it is , think about it . 

205
00:23:09,346 --> 00:23:19,357
The number of times they asked for any single logic really smile , so they learned very , very quickly and as well in the resembles , and we would like to be able to to get there . 

206
00:23:19,357 --> 00:23:21,547
The obvious promise is no free lunch . 

207
00:23:21,547 --> 00:23:31,524
The system works really well , because it got all of these data and what we want to do is , is , say , okay , then we have to pull that information from somewhere else . 

208
00:23:31,524 --> 00:23:41,670
Some of the techniques to think of ecological transfer learning , which says , okay , i've never solved this problem , but i've learned the system to do something similar . 

209
00:23:42,100 --> 00:24:10,940
Can I pull that knowledge over , right , we have when we call sales , supervise learning where you make a task with your data that , you know , the answer for , like you've rotated some amount , and then the system has to learn how much you rotate it , because you have the answer for that , right , and so you can do themselves football systems and the really exciting , cutting edge are what we refer to as few shot learning systems , or even zero shot learning systems . 

210
00:24:11,100 --> 00:24:18,910
Or you learn on either you a small number of examples , or one example , or a few cases , even zero examples. 

211
00:24:19,250 --> 00:24:21,120
How can you learn on zero examples? 

212
00:24:21,370 --> 00:24:31,370
Glad you asked , so I am willing to bet that that you , in your listeners or responsibility to do not know what a crack it is. 

213
00:24:31,580 --> 00:24:32,990
Cool , I go to the. 

214
00:24:33,170 --> 00:24:35,210
But it is a great rebel world . 

215
00:24:35,210 --> 00:24:38,067
It is a great wild world to achieve enthusiasm . 

216
00:24:38,067 --> 00:24:39,292
But now here is a foot . 

217
00:24:39,292 --> 00:24:45,210
If I did , you want to pictures and say , find the quarter , you be able to consider what the quarter looks like . 

218
00:24:45,390 --> 00:24:52,830
But now let me tell you something , a quarter is a subspecies of zebra that only has straights on a half of its party . 

219
00:24:53,050 --> 00:24:59,890
That sentence alone with what you already know about , what zebra is look like is enough to recognize. 

220
00:25:00,000 --> 00:25:03,200
God , I love it , zero examples , but , but you give me the context . 

221
00:25:03,200 --> 00:25:04,600
You give me a definition . 

222
00:25:04,600 --> 00:25:08,800
I just wonder , because you brought a language acquisition of your own kids . 

223
00:25:08,800 --> 00:25:25,700
And I was delighted to witnessing two boys acquire language , and it is often by the question in what is this is that exactly part of your overall program , which is to say , they're teach computers to know when they should a human partner . 

224
00:25:25,700 --> 00:25:26,670
What something is that? 

225
00:25:26,880 --> 00:25:33,700
Yes , a financial effect , the buzz word for that is active learning , where you give the data system or open your own label data . 

226
00:25:33,700 --> 00:25:36,090
It continues to tell me what this one is. 

227
00:25:37,170 --> 00:25:41,140
So bruce , let's just talk about one more program . 

228
00:25:41,140 --> 00:25:47,570
And this one is one of your own design congratulatory , because it was just accepted . 

229
00:25:47,570 --> 00:25:50,360
Got a green light from a leadership at darker . 

230
00:25:50,360 --> 00:25:57,090
This is perceptually enabled the task guidance , and because it is new , you can really talk about any results yet . 

231
00:25:57,090 --> 00:25:59,740
But just what , what's the basic idea of this program? 

232
00:26:00,330 --> 00:26:11,370
The basic idea this program is thought of thinking about assistance we have now , like syria or alexa , by the way , syria came out of the dark program fifteen years . 

233
00:26:12,320 --> 00:26:13,291
Seriously , right . 

234
00:26:13,291 --> 00:26:14,652
Where are you using it ? 

235
00:26:14,652 --> 00:26:19,900
But it can be very frustrated , fearing the middle of building something and say , say , what should I . 

236
00:26:20,500 --> 00:26:36,610
Her answer is , the world is full of possibilities , because , of course , you have no idea what you do , and you can see what you do when you do that in context for that , we want to do is create the sort of assistance or agents AI systems that have their politics . 

237
00:26:36,940 --> 00:26:59,810
So in the future , threatening the military context , pretty much everybody's walking sense of pretty much everyone is gonna camera , pretty much everyone's gotta microphone on them , and more and more will be having augmented reality so that they will have screens that we know they can drive down further eyes and show them and talk to them to get this great possibility for air . 

238
00:27:00,030 --> 00:27:09,730
I've got all this input cameras until you see my reference here , you hear an augmented reality to display things for you and give you information . 

239
00:27:10,080 --> 00:27:16,310
What we need is in the middle is an assistant that would you start to do some tasks . 

240
00:27:16,700 --> 00:27:27,360
So maybe you're an airplane mechanic and your plane , and you're fixing the breaks on an airplane right as you start , that recognizes what you doing is read the manual . 

241
00:27:27,690 --> 00:27:36,290
It knows what you should do if you make a mistake , it warns you , if you forget what to do next , you can to say , hey , what are you , and it will tell you . 

242
00:27:36,290 --> 00:27:44,180
And in an emergency situation , or maybe you are not a mechanic , but you have to fix this break right then it goes . 

243
00:27:44,180 --> 00:27:46,320
Okay , you have done this before , and you walk you through it . 

244
00:27:46,580 --> 00:27:59,090
But doing that , I can help people do physical tasks , and , but in a way that makes them more efficient , have fewer mistakes and allows them to do a wider range of tasks than they currently can today . 

245
00:27:59,090 --> 00:27:59,980
Where am it? 

246
00:28:00,000 --> 00:28:08,561
Think it sounds like it builds on just started against a lot of low technique , lots of professionals to use , which is literally a checklist right again . 

247
00:28:08,561 --> 00:28:11,480
And another happens with some pilots around their planes . 

248
00:28:11,630 --> 00:28:20,050
You know , some doctors actually use checklists , and in some ways , it sounds like this is just taking this to a new and maybe more generalized label. 

249
00:28:20,610 --> 00:28:24,309
But I tried to double pull the lower of wind . 

250
00:28:24,309 --> 00:28:34,827
Checklists were introduced in the surgery would only happen in common practice in the late nineties , early two thousands , the mortality rate dropped by over forty five percent . 

251
00:28:34,827 --> 00:28:48,750
The chocolate stop people from , and now you go even one step further , right , and you have the system that watching you do things , and you can see when you make a stake , and you can warn you , and it can help you if you forget what to do . 

252
00:28:50,030 --> 00:28:51,520
It's sorry if they do it yourself . 

253
00:28:51,520 --> 00:28:52,570
Revolution on story. 

254
00:28:53,330 --> 00:28:57,810
Okay , we have just converted me to checklist , so I think i'm going to bring those into my life now . 

255
00:28:58,380 --> 00:29:08,350
So now , before we run at a time , I just wanted to give you an opportunity to stand back and share some bigger picture , views about computer science and air . 

256
00:29:08,350 --> 00:29:09,760
I mean , this is something amazing . 

257
00:29:09,760 --> 00:29:15,060
A doctor , so many program managers are working and really powerful technology can have double edges . 

258
00:29:15,060 --> 00:29:15,290
right ? 

259
00:29:15,290 --> 00:29:22,020
So I am interested in what excites you about current trends and future possibilities in these areas . 

260
00:29:22,020 --> 00:29:30,020
And what sorts of unintended parallels consequences were you and sort of you are the things that you want to do , you don't disappoint. 

261
00:29:30,430 --> 00:29:31,600
But we started off the exciting set . 

262
00:29:31,600 --> 00:29:42,243
There is a lot of really exciting things going on , one of which is a notion that perception , whether it's sufficient speech , whatever it could be tackled , whatever . 

263
00:29:42,243 --> 00:29:51,900
But perception is coming together with intelligence , we have these AI programs that that are purely logical to do things like medical diagnosis . 

264
00:29:51,900 --> 00:30:01,020
Three years now , we've got it , our purposes I can see in here and putting those two things together , putting intelligence exception together . 

265
00:30:01,350 --> 00:30:04,990
I think it's going to create all kinds of really. 

266
00:30:05,050 --> 00:30:06,338
Exciting possibilities . 

267
00:30:06,338 --> 00:30:07,811
So just get concrete with me . 

268
00:30:07,811 --> 00:30:10,021
You know , it was wonderful examples there . 

269
00:30:10,021 --> 00:30:13,520
What , when you say it's going to be really exciting , what happens to your? 

270
00:30:13,520 --> 00:30:15,128
But one of them is a struggle . 

271
00:30:15,128 --> 00:30:17,630
I just described where something can be solved . 

272
00:30:17,630 --> 00:30:21,561
The second strategies , constantly looking over your children , helping you do things . 

273
00:30:21,561 --> 00:30:23,170
But I would like to go further . 

274
00:30:23,170 --> 00:30:24,600
I would love to have a child . 

275
00:30:24,600 --> 00:30:29,091
Imagine this is an eye program almost as a partner that with you all the time . 

276
00:30:29,091 --> 00:30:37,970
I really bad and remembering people's names when I meet them , and I would just love to walk into a , and I see that face that I know is so familiar . 

277
00:30:38,100 --> 00:30:41,610
And this little bugging my ear says , oh , that's jane . 

278
00:30:41,610 --> 00:30:43,250
You met her last year at TVP. 

279
00:30:43,565 --> 00:30:48,707
Yeah , no , I am really , really bad with the names , danny growth , but and so what ? 

280
00:30:48,707 --> 00:30:56,030
What about the others like , you know that I looked at you in the question , which is you think that does essentially keep. 

281
00:30:56,060 --> 00:31:06,900
But night , well , one of the things that could , that , I think , considered a lot of people list is privacy as we have more and more systems , more and more sensors are just that , you know , a system looking over your shoulder . 

282
00:31:07,260 --> 00:31:08,630
You don't want that to be crazy . 

283
00:31:08,960 --> 00:31:12,760
Do we still have privacy and how to set work in this model ? 

284
00:31:12,970 --> 00:31:27,330
And I think I am trying to push toward what I hope is the solution there , because right now , A, Itend to be these big systems trained on billions of examples that had been sucked up from all over the place . 

285
00:31:27,490 --> 00:31:31,640
But there are there many people that have access to the machinery , and they dated to make this . 

286
00:31:31,640 --> 00:31:44,910
All , I think that what happening is , as we get better at AI, as we learn on fuel samples , and as we all become towards changing platforms , it began to the opportunity for much more personalize . 

287
00:31:45,320 --> 00:31:52,870
So I got my assistant is helping me do my task , but that's all my data information back to me . 

288
00:31:53,060 --> 00:31:58,870
Nothing going off to a central weapon is a very good that , you know , this notion of a personalized day . 

289
00:31:58,870 --> 00:32:05,580
I, Ithink we , something that we can trust and enjoy working with much more than something that is his centralized. 

290
00:32:06,650 --> 00:32:10,040
In its first name , one other area of concern that comes to my mind . 

291
00:32:10,220 --> 00:32:29,110
You know what we've been hearing about it in the news , a little bit more in recent years is just how biases get built into the system is , partly as because of whatever datasets are used for learning and other examples , facial recognition programs that are more error program when it comes to faces of color than , say , occasion , faces that kind of by us being though . 

292
00:32:29,110 --> 00:32:30,760
What do you think about those kind of? 

293
00:32:30,960 --> 00:32:35,979
You know , the attitude issues , first and foremost , the real , I doubt a lot of work in face recognition . 

294
00:32:35,979 --> 00:32:42,210
If you don't train it very carefully , you do good boys , and there is all kinds of other examples , banking records , other things . 

295
00:32:42,400 --> 00:32:45,290
It's a very really human wonder , has to be dealt with . 

296
00:32:45,860 --> 00:32:50,660
That said , I had a colleague who really changed by thinking on it one day . 

297
00:32:50,880 --> 00:33:03,520
This is a colleague in the business school who was worried about bias , and he was looking at an air system that had been trained on historical records in the head , absorbed the biases of those records . 

298
00:33:03,520 --> 00:33:11,410
And he said , in other provinces to miss biased , li said , yes , he said , but the opportunity is the system can be fixed . 

299
00:33:12,420 --> 00:33:17,090
It's really hard to get biased out of social organizations . 

300
00:33:17,390 --> 00:33:21,680
It's easier , right as hard as it is , as much as important , promise it . 

301
00:33:21,850 --> 00:33:26,030
It's potentially easier to get it out of technical systems that out of social ones. 

302
00:33:26,030 --> 00:33:34,656
I presume , as we become more aware of these issues and what the technical bases are underlying them that we will actually get better at creating systems . 

303
00:33:34,656 --> 00:33:35,860
I don't have the bike. 

304
00:33:35,890 --> 00:33:41,560
Races to begin with , that's right , and it's actually wrapped a little bit back to the first program . 

305
00:33:41,560 --> 00:33:51,503
We talk about this guard , because one of the ways you can think of what an angel series doing when they full your system , is there taking advantage of the biases you didn't recognize . 

306
00:33:51,503 --> 00:33:56,140
And that if we buy systems that we can trust that are reliable , that are defensible. 

307
00:33:56,330 --> 00:33:58,210
They will also be less biased . 

308
00:33:58,640 --> 00:34:01,441
Okay , it seems like pending against the sessions . 

309
00:34:01,441 --> 00:34:05,043
We can play on ourselves , that alone adversaries perpetrating on us . 

310
00:34:05,043 --> 00:34:05,944
So says , needing , okay . 

311
00:34:05,944 --> 00:34:13,330
So one more question as young here and asked that , you know , what is the question that I thought you were expecting me to ask that I didn't answer about. 

312
00:34:13,760 --> 00:34:25,220
To me , I think one of the things that worries me is the rate of technological change is increasing , and it's fun for building better and better technologies that do greater and greater things for . 

313
00:34:25,990 --> 00:34:31,780
But the same level , it is hard as individuals to handle that kind of rate of change . 

314
00:34:32,050 --> 00:34:44,830
The older I get more worried about him , and it's really so that we have to find ways to help these machines help us , because the worlders is expanding rapidly at its fun . 

315
00:34:44,830 --> 00:34:52,280
And there's all kinds of opportunities there , but it's also hard as an individual to keep up with and figuring out how we all people who said. 

316
00:34:52,740 --> 00:35:08,948
If one of the great challenges that was a really fun conversation , bruce is one of thank you for taking me on the store with at least some of what is going to take , move forward with AI, you know , with our eyes wide open and your work and source of invasion is going to take to lean the balance to our day . 

317
00:35:08,948 --> 00:35:12,570
I feel safe and constructive versus paralysis and destructive . 

318
00:35:12,570 --> 00:35:17,460
So thanks for lending me and our listeners your time and expertise . 

319
00:35:17,880 --> 00:35:21,540
Glad to do it , and thanks listeners for sharing this time with us . 

320
00:35:21,840 --> 00:35:30,550
I hope you join this again for the next Voices from german , thanks also to bend selection for his partnership in producing this program . 

321
00:35:32,210 --> 00:35:41,232
For more information about blue stripper , the programs he runs in agency's information invasion office , and the other breaks with technologies dark is working on . 

