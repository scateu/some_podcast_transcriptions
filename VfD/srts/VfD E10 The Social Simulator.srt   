1
00:00:11,770 --> 00:00:17,760
Stop technology , the internet GPS in the column of your hand on tournaments. 

2
00:00:19,800 --> 00:00:32,120
Technology is a driver of our times since its founding in nineteen fifty eight , in the midst of the cold war , darbar , the defence advanced research projects agency has been a driver of technology . 

3
00:00:32,700 --> 00:00:41,530
Welcome to voices from darpa , a window on the dark as core a program managers , their job to redefine what is possible to be . 

4
00:00:42,320 --> 00:00:46,900
My name is iphone a mutton on your double host today , and please to have with me in the studio . 

5
00:00:46,900 --> 00:00:52,620
Jonathan felt a program manager since twenty fifteen , endorses information innovation office . 

6
00:00:53,590 --> 00:00:58,260
Jonathan , run , the ph d in computer engineering from the university of cambridge in england . 

7
00:00:58,660 --> 00:01:07,202
But along the way , here in degrees , electric engineering , computer engineering and brain in cognitive sciences , all from the massachusetts institute of technology . 

8
00:01:07,202 --> 00:01:20,022
Jonathan , a pitt minister , starts with deliberate blindness to traditional disciplinary in search of new research and development territories , were perhaps some of the most consequential opportunities for technology development . 

9
00:01:20,022 --> 00:01:26,850
Resigned , adopted his principal research interests lie at the intersection of the computational and behavior for scientists . 

10
00:01:27,220 --> 00:01:47,450
So thanks johnson for joining me in the studio today , it's awesome to be here before we actually dive into some of the really good stuff about how you got to dark , but how you thinking about technology program that you recently got going on a few other things i've got to ask you something that I learned about you and your family , just discussions your dark . 

11
00:01:48,070 --> 00:01:52,570
And i'm afraid here to the naming of your children suggested that. 

12
00:01:52,760 --> 00:01:53,850
Tell us , we will be sure . 

13
00:01:53,850 --> 00:02:04,688
So my wife is also a scientist that we had a rather long and likely discussion about our name , algorithms and how you , depending on the general child , you might want to heart constantly . 

14
00:02:04,688 --> 00:02:06,606
You might want to solve vales . 

15
00:02:06,606 --> 00:02:12,170
And we also been scientists started to think about names of maybe met some of those criteria . 

16
00:02:12,170 --> 00:02:18,790
So we named our children tesla and fairly , and we thought very hard about that , because it's pretty nerdy . 

17
00:02:19,350 --> 00:02:24,190
And we want people to also call them tests and farewell , should they want to turn it down? 

18
00:02:24,270 --> 00:02:27,420
One of that , and just how have your daughter is? 

19
00:02:27,470 --> 00:02:38,250
Wanted having such a usual name like that , they've loved it , and we made a point of going to the royal society in london with where they have a much fairly original label queen . 

20
00:02:38,280 --> 00:02:41,810
Oh , not really nice , small , not very busy museum . 

21
00:02:42,120 --> 00:02:42,300
it's. 

22
00:02:42,380 --> 00:02:43,220
In a lot of fun . 

23
00:02:43,220 --> 00:02:47,720
So I don't get an opportunity there to tell the curator , but you know what is going on. 

24
00:02:47,800 --> 00:02:52,210
What happened when you were that , of course , I think the reaction we tend to get is very positive . 

25
00:02:52,260 --> 00:02:57,006
Sometimes we tested that we do get asked about the rock band and occasionally about this . 

26
00:02:57,006 --> 00:02:57,765
I don't know . 

27
00:02:57,765 --> 00:03:06,240
You may have heard this a car company out there , and an important part of that story , of course , is who is neglected as hero and microsoft. 

28
00:03:07,270 --> 00:03:08,522
Beautiful connection . 

29
00:03:08,522 --> 00:03:15,412
So I have to say that quirky , but I say that was great affection , and it is a short sign of your devotion to science . 

30
00:03:15,412 --> 00:03:18,334
So let's actually not talk about your background . 

31
00:03:18,334 --> 00:03:20,840
And I mentioned the degrees that you were gone . 

32
00:03:20,880 --> 00:03:27,470
So I like to hear about that those interests and how you ended up actually is getting an opportunity to work here. 

33
00:03:27,660 --> 00:03:45,160
WOW , yes , or go away back to the ability plus , and my father with some sort of gives you visit a day point on , oh , at nineteen , seventy nine , okay , and my father with , with some great insights and no personal computers , we need these and write it in . 

34
00:03:45,240 --> 00:03:52,550
And I don't know if you recall these old magazines like bright magazine , you would type in programs , and you would type in computer games . 

35
00:03:53,060 --> 00:03:56,545
And I said that I said , dad , I wanna make my computer games . 

36
00:03:56,545 --> 00:03:58,390
And he said , here's the manual song . 

37
00:03:58,390 --> 00:04:08,700
And it prompted in front of me , an exciting , and I started programming , and I started to fall in love later , once I got to undergraduate . 

38
00:04:08,700 --> 00:04:15,410
I'm sitting out of fortunate to overlap with my sister at the same university she was studying cooking assigns . 

39
00:04:15,410 --> 00:04:17,860
This is amazing how people think how they behave . 

40
00:04:17,860 --> 00:04:19,060
All of the motivations for that . 

41
00:04:19,060 --> 00:04:20,430
That's fascinating . 

42
00:04:20,430 --> 00:04:22,170
That's what I want to study . 

43
00:04:22,170 --> 00:04:23,390
And she looked at me in and away . 

44
00:04:23,390 --> 00:04:28,470
The older sister , kenneth said , jonathan , if you don't do computer science , you're crazy . 

45
00:04:28,470 --> 00:04:31,990
So I did both , and that's been my career right now . 

46
00:04:31,990 --> 00:04:34,570
Darpa , did you know about it and seek it out ? 

47
00:04:34,780 --> 00:04:52,360
Doubles such an amazing place that is hard when you failed doing research and development and leading other people in doing it to not know about dark , but not know about the amazing things the dark has done so for me , it was , it was very natural to . 

48
00:04:52,540 --> 00:05:01,030
But I can imagine , at some point , appropriately , in my career , I would love to serve a dark and spend for five years in my life . 

49
00:05:01,030 --> 00:05:18,160
You're helping arriving at the scene of incredible empowerment that with the , where , with all that you get to really makes majority things happen , not just the , oh , i'm going to run a program , but no , i'm going to in a read a similar book with the best people in the world . 

50
00:05:18,160 --> 00:05:20,690
I am going to change a whole discipline . 

51
00:05:20,790 --> 00:05:22,200
It's an amazing . 

52
00:05:22,680 --> 00:05:29,080
And when you do all of that , and you tied back to national security and feeling like you're serving your country , it's a great feeling. 

53
00:05:29,700 --> 00:05:39,533
Yeah , when one of the things I find a most fascinating about dark is the sort of melting of disappointment boundaries , which is not so easy to do with many other institutions . 

54
00:05:39,533 --> 00:05:43,910
You got our university , and typically , you're still in biology department or chemistry . 

55
00:05:43,910 --> 00:05:46,723
Here are those kinds of boundaries . 

56
00:05:46,723 --> 00:05:52,913
Almost are irrelevant , because it's much more of a projects directed approach . 

57
00:05:52,913 --> 00:05:54,320
You sure , oh yeah , I. 

58
00:05:54,320 --> 00:06:03,070
And that's part of the superpower should get as a dark program manager is you can , you can remembering sister grabbing my error , and then you should think about the sector . 

59
00:06:03,250 --> 00:06:05,450
You can grab people by the year and go . 

60
00:06:05,450 --> 00:06:18,070
I've watched this field for my , my case in twenty five years , and it's absolutely ridiculous that these people are working together , or there is a huge opportunity if I can bring these people together in the right way . 

61
00:06:18,450 --> 00:06:19,670
And that's what we try to. 

62
00:06:20,080 --> 00:06:30,180
So let's talk about how your own mind said is changing another to hear a darker and will move from that come into the program that you began to wrap up the moment . 

63
00:06:30,360 --> 00:06:33,667
So you may have made your mission here to focus on hard problems . 

64
00:06:33,667 --> 00:06:51,070
One of them being the modeling of large scale human behavior by weight , computer simulations that I would like to first talk to me about your views about our increasing connectiveness global information environment , and how that's guiding what you hope to achieve here in your time. 

65
00:06:51,630 --> 00:07:01,800
Yeah , I, Iget so excited when I think about the fact that people are interacting in the economy ever increasingly computer mediated fashions . 

66
00:07:02,680 --> 00:07:12,500
Now I have this opportunity through these kind of computer middle interactions to study human behavior at a scale that never been done before . 

67
00:07:12,720 --> 00:07:16,348
And what's exciting is people are starting to think about that world . 

68
00:07:16,348 --> 00:07:18,940
So you see some behavioral scientists using mechanical. 

69
00:07:18,970 --> 00:07:22,240
For example , actually , most people would not know what mechanics oh means . 

70
00:07:22,240 --> 00:07:22,430
so. 

71
00:07:23,080 --> 00:07:44,960
Sure , so amazon mechanical turk is a crowd sourced platform , so I could say , good amazonian kitchen , and I would like to twentieth people to do some simple experiment , which is to say , you know , click on this color box when you see it type of experiment or collaborate on the project , and let me what you do . 

72
00:07:45,160 --> 00:07:51,910
So in the social sciences , there's been a huge object in people using this particular platform . 

73
00:07:51,910 --> 00:07:58,660
It's just one think about the fact that when you call that it has died on the drivers that has dead on the people that are getting picked up . 

74
00:07:59,170 --> 00:08:12,040
Think about these , but think about the fact that they have millions and millions and millions of users around the world , they can do interesting studies and differences between cultures that we could never conceive at that scale before . 

75
00:08:12,460 --> 00:08:15,270
It's an incredibly exciting time for the behavior on social. 

76
00:08:15,370 --> 00:08:26,770
Right , and just one word moment on the mechanical turk , what's fascinating , but even the name of that is is associated with a famous example of an automation , mcdonald's mechanical turned with connection. 

77
00:08:27,380 --> 00:08:35,640
I think amazon original vision was a mechanical turk , where it's not tomatoes with the human insight. 

78
00:08:35,850 --> 00:08:45,000
When this was a chess playing a toronto , and that the was the center of all kinds of discussions when the first came out in the innovation to reveal the event in the. 

79
00:08:45,000 --> 00:08:56,573
I think the messages that there are new average , increasing opportunities for interacting with humans in a way that would let us understand , not just how they are going to act in a particular instance . 

80
00:08:56,573 --> 00:08:59,010
But what are the kind of causal underpinning ? 

81
00:08:59,040 --> 00:09:00,710
Thanks , oh , as behaviors . 

82
00:09:00,710 --> 00:09:03,680
And why do people act in a certain way in a certain situation? 

83
00:09:04,230 --> 00:09:10,840
Interesting , so I think that is a good secret way into a discussion about the program that you have begun . 

84
00:09:11,060 --> 00:09:20,286
And it's called the computation , simulation of online social behavior program , known in a short form as a social theme . 

85
00:09:20,286 --> 00:09:29,650
You've described its goal as developing innovative technologies for high computational simulation of online social behavior . 

86
00:09:29,650 --> 00:09:30,880
But I look at a flash that out. 

87
00:09:30,930 --> 00:09:39,345
For our listeners here , one of the things to point out when I am rattling off these opportunities about understanding human behavior is understanding human behaviour is hard . 

88
00:09:39,345 --> 00:09:41,908
And I feel far from solved problem . 

89
00:09:41,908 --> 00:09:48,460
So we often joke , we wish we had the easy problems like the physicists . 

90
00:09:48,460 --> 00:09:49,840
Humans are tough . 

91
00:09:49,870 --> 00:09:52,010
So this program is a fundamental research program . 

92
00:09:52,010 --> 00:09:55,770
It's not saying we're going to successfully model human behavior . 

93
00:09:55,770 --> 00:10:00,670
It says we're going to try to start the elephant . 

94
00:10:00,910 --> 00:10:08,010
Where can I get a very , very tiny teaspoon and start to neighbor at this giant problem of what can we understand about behavior ? 

95
00:10:08,010 --> 00:10:17,400
So the goal of this program is to really start to tackle the issue of creating valid simulations of valid models . 

96
00:10:17,670 --> 00:10:28,220
And there's a lot of folks in the modelling world who will build beautiful models and not do such a great job of proving that they are correct . 

97
00:10:28,910 --> 00:10:36,755
Then there's people who are gonna , do behaviour experiments , but then don't bother to cut a fight that in some sort of computation representation . 

98
00:10:36,755 --> 00:10:42,546
So how do you think about bring all of that together in a way where you can say , yes , we build this matter . 

99
00:10:42,546 --> 00:10:50,620
We build this competition of simulation , and we know for some circumstances , it works with some level of accuracy . 

100
00:10:50,620 --> 00:10:54,200
We know when we have things that are right , and when we have things that are right. 

101
00:10:54,610 --> 00:11:05,090
Right , and you're bringing in again , this massive ability to scale , operations to scale up in a massive way , because you will be tapping in and a sort of almost crowd sourcing way . 

102
00:11:05,090 --> 00:11:09,140
And then , when , by reaching out through the social media channels. 

103
00:11:09,320 --> 00:11:19,876
Absolutely , so one of the things that is different today is this notion of scale that we have all of these computer media communications . 

104
00:11:19,876 --> 00:11:38,520
And if we can do all of the appropriate privacy and ethical considerations correctly , which is things like informed , concerned , you must ask someone if you're going to use the data , and then can we then look at this data in aggregate , we're not talking about individuals who are talking about group at scale . 

105
00:11:38,520 --> 00:11:44,320
Millions of people who decide workers spread a piece of information or not . 

106
00:11:45,080 --> 00:11:55,320
So we're going from online social behavior , which is potentially a very big space to a relatively simple behaviour , which is the spread of information . 

107
00:11:55,320 --> 00:12:00,044
So why would you tell me to start great movie , what motivates that ? 

108
00:12:00,044 --> 00:12:01,009
How does that happen ? 

109
00:12:01,009 --> 00:12:06,796
And can we look at the various factors surrounding that as a function of which environment are we in ? 

110
00:12:06,796 --> 00:12:09,304
Is it something that you would tweet about ? 

111
00:12:09,304 --> 00:12:11,620
Is it something you might post on facebook ? 

112
00:12:11,720 --> 00:12:15,301
Can we do that as a function of the information itself ? 

113
00:12:15,301 --> 00:12:23,730
What kinds of information are more likely to spread , and can we do that as a function of the properties of the population as a whole world ? 

114
00:12:23,730 --> 00:12:28,252
This is a population that really is very connected and likes to spread information . 

115
00:12:28,252 --> 00:12:30,702
This is a population that is more disconnected . 

116
00:12:30,702 --> 00:12:32,210
It doesn't do as much of that . 

117
00:12:32,210 --> 00:12:37,770
So how to all of those factors in the act and study those and say what we actually know , and how will we know it? 

118
00:12:37,820 --> 00:12:44,660
So if you were trying to make this little bit more concrete for listeners , what kinds of questions do you think ? 

119
00:12:44,700 --> 00:12:58,620
Okay , do you know you will be asking of the researchers who will be working with you on the social program that they are either relevant to national security or other society important categories. 

120
00:12:58,700 --> 00:13:05,330
So I think one of the things in the spokeswoman were really focused on is societal benefit as relates to national security . 

121
00:13:05,330 --> 00:13:07,100
So what's a great example of this ? 

122
00:13:07,100 --> 00:13:12,130
So , you know , the us military has a mission called community in assistance in disaster relief . 

123
00:13:12,330 --> 00:13:25,694
So when there is a tsunami or a flood or a typhoon in a foreign country , we may be asked to go and see if we have to combat in the situations is a spread , for example . 

124
00:13:25,694 --> 00:13:45,025
So , so there's a recent story about a rumour spreading that the bottle water that the us military was bringing was containing mind control substances , and they are going to use it to control the population , patently false , but it LED to a lot of people getting very sick because they weren't drinking safe water . 

125
00:13:45,025 --> 00:13:54,770
So there is a very concrete example who could understand why that particular message got traction , why it spread the , we could maybe help a little bit better in such situations. 

126
00:13:55,150 --> 00:13:57,830
Now , I guess moving in in a national security direction . 

127
00:13:57,830 --> 00:14:14,060
Those of phrase I read , maybe on your program page that really catches my interests in its resulting conflicts without false , which sounds like a terrific idea of the talk to me a little bit about that in the relationship to the kind of working on her. 

128
00:14:14,210 --> 00:14:26,450
Yeah , but the us military is very , very good at the connective parts of operations are , in fact , arguably without pure in many ways. 

129
00:14:26,730 --> 00:14:30,120
And I just want to point out for listeners by kennedy . 

130
00:14:30,120 --> 00:14:33,960
That means things that are moving , and you can think of it as a metal moving through air of the. 

131
00:14:34,010 --> 00:14:40,676
Among other things , so the military also tries to think about operations other than war . 

132
00:14:40,676 --> 00:14:50,590
So when we get into these imagining assistance situations , or we are trying to advise local forces about what's going on . 

133
00:14:51,010 --> 00:14:57,709
There is a lot of opportunity for us to make a huge difference without metal moving through air to use your phrase . 

134
00:14:57,709 --> 00:14:59,980
That seems like a very important thing . 

135
00:15:00,030 --> 00:15:08,180
Nobel goal to me , I wonder , I get very passionate about any time you can save lives without having to be aggressive . 

136
00:15:08,180 --> 00:15:09,140
I think that's important . 

137
00:15:09,710 --> 00:15:10,380
Yeah , this is. 

138
00:15:10,700 --> 00:15:20,200
Makes me understand a little bit more about you and your passion for wanted to come here and having any of some sense that is possible for you to move the . 

139
00:15:20,200 --> 00:15:29,523
The actual practice of warfare away from a canadian and bloody one into something that we're root work and conflicts are resolved without that kind of forcing . 

140
00:15:29,523 --> 00:15:30,140
And what is? 

141
00:15:30,170 --> 00:15:35,930
Comes with it , it's hard to not come into work in the morning and be passionate that kind of. 

142
00:15:36,220 --> 00:15:38,560
That kind of statement , okay , course , nothing is easy . 

143
00:15:38,560 --> 00:15:47,781
So the kinds of research that you are doing in which you're scaling up , you're looking at a massive amount of social , by way of social media . 

144
00:15:47,781 --> 00:15:51,847
So this is where people are revealing things about themselves . 

145
00:15:51,847 --> 00:15:54,558
There are ethics issues , including privacy . 

146
00:15:54,558 --> 00:15:59,980
So how are you thinking about those issues as you move forward in your progress there? 

147
00:16:00,000 --> 00:16:11,021
Front and senior at the level that I don't know that it's been pushed so far in front and not utilize why , when you study the behavioral sciences , and you go through here is how to do human behavior experiments . 

148
00:16:11,021 --> 00:16:15,780
I would keep thinking about billman and ghostbusters , where he's doing that . 

149
00:16:15,780 --> 00:16:22,770
The shock test with the to see if people have a piano , and he's breaking every ethical role there is in that . 

150
00:16:22,770 --> 00:16:23,900
It was very humorous . 

151
00:16:23,900 --> 00:16:28,153
But when you do behavioral experiments , you , you have to get informed consent . 

152
00:16:28,153 --> 00:16:31,140
And that means you have to have someone opt in to doing this . 

153
00:16:31,140 --> 00:16:33,193
You have to show that there is minimal risk . 

154
00:16:33,193 --> 00:16:38,070
You have to go through all the things as a behavioral scientist on lake . 

155
00:16:38,070 --> 00:16:40,100
Okay , now you turn to the computer . 

156
00:16:40,620 --> 00:16:52,420
They go , what there's this data , this data , they're like , what there's data that's about human beings or coming from human beings , and therefore privacy protections are hers . 

157
00:16:52,910 --> 00:16:54,030
A fun fact . 

158
00:16:54,030 --> 00:17:06,713
I don't know if you know this , but if if you look at what is the innocent user license agreements that you click through , without , there are things in there that gave companies this notion of informed consent to mess with your date . 

159
00:17:06,713 --> 00:17:07,881
I never read those . 

160
00:17:07,881 --> 00:17:10,605
So that's where we need to provide the leadership . 

161
00:17:10,605 --> 00:17:18,455
We need to say yes , if we are interested in people's data , and we want to understand behavior , and we want to do the science of of behavior . 

162
00:17:18,455 --> 00:17:20,752
We have to respect that from the outset . 

163
00:17:20,752 --> 00:17:32,420
So we've already run privacy and thinks for jobs , we have external privacy consultants that we work with and factory about the program that are stone making sure we address privacy appropriately. 

164
00:17:32,420 --> 00:17:33,941
I am interesting , so dark . 

165
00:17:33,941 --> 00:17:42,330
It is known for break loose and technology , but it almost sounds to me like you might be moving towards some new territory , even when it comes constant . 

166
00:17:42,330 --> 00:17:44,760
And these kinds of privacy network issues are. 

167
00:17:44,855 --> 00:17:59,100
Slowly , I know our director has said it's not just our responsibility to prevent or anticipate to teach the surprise from a technology standpoint , but also from how we actually conduct the research and development that gets that technology. 

168
00:18:00,000 --> 00:18:03,393
So I want to just talk a little bit more about social symbol . 

169
00:18:03,393 --> 00:18:04,591
What I like you to do . 

170
00:18:04,591 --> 00:18:07,785
Jonathan is , is given us a sort of a status report . 

171
00:18:07,785 --> 00:18:10,180
Where is this programme in its lifestyle ? 

172
00:18:10,180 --> 00:18:15,970
And then I ask you to get your topic and imagine the best success , but you can imagine with the program . 

173
00:18:15,970 --> 00:18:16,880
So first. 

174
00:18:17,020 --> 00:18:24,540
The sales report , so we have completed source selection , which is to say we received a number of pretty amazing proposals . 

175
00:18:24,620 --> 00:18:29,920
Now we go into the process of getting those folks won the contract and getting the programme. 

176
00:18:29,970 --> 00:18:38,600
Off the ground , and then , as it gets off the ground and open next couple of years , you are , as we call our original partner's performers as darkness . 

177
00:18:38,980 --> 00:18:40,470
What is your hope ? 

178
00:18:40,470 --> 00:18:48,240
What do you hope in several years when you bring the performers together , and you are having a moment of celebration that the program is completed . 

179
00:18:48,240 --> 00:18:51,070
But what do you hope will be the pair of the deliverable it is. 

180
00:18:51,460 --> 00:18:56,180
A few changes are changing the way this kind of research and development is done . 

181
00:18:56,180 --> 00:18:57,840
I don't think we are going to end up with . 

182
00:18:57,840 --> 00:18:59,670
The , here is a correct . 

183
00:19:00,030 --> 00:19:01,300
Well , how information spreads . 

184
00:19:01,300 --> 00:19:21,810
I think what we're going to end up with is a research community that much more rigorously , much more scientifically , the process of building these kinds of models , and everybody moves forward from that point out to this huge , massive , possibly unbounded space of understanding human behavior. 

185
00:19:21,810 --> 00:19:25,688
Right , and one of the things that are really fascinating about human behavior . 

186
00:19:25,688 --> 00:19:31,253
And I think about your structure in the program of thinking about it is that social structures are hierarchical . 

187
00:19:31,253 --> 00:19:31,590
We , you . 

188
00:19:31,590 --> 00:19:32,770
And I join them right now . 

189
00:19:32,770 --> 00:19:35,300
We are having a conversation as social structure . 

190
00:19:35,330 --> 00:19:37,710
Ben , our audio engineers with us . 

191
00:19:37,710 --> 00:19:41,510
So there are three people in our social structure in the studio , but go up from there . 

192
00:19:41,510 --> 00:19:48,300
And so because we then go to neighborhoods , we go to cities , we go all the way up to a global community , right ? 

193
00:19:48,300 --> 00:19:48,610
so. 

194
00:19:49,310 --> 00:19:52,866
Even each of those hierarchical levels , another overlapping . 

195
00:19:52,866 --> 00:19:55,377
So there are , you are in one neighborhood . 

196
00:19:55,377 --> 00:19:56,632
You are also in a town . 

197
00:19:56,632 --> 00:19:58,933
It's not necessarily all hierarchical . 

198
00:19:58,933 --> 00:20:01,570
Could you also make in the group of fathers ? 

199
00:20:01,570 --> 00:20:03,690
You may be in the group of americans . 

200
00:20:03,690 --> 00:20:06,670
You may be in the group of people that live on streets called. 

201
00:20:07,090 --> 00:20:16,060
Edison , straight , anyone you think about categorization mean , what can you learn about from in the social? 

202
00:20:16,105 --> 00:20:20,811
You're of each of those , and that's one of the interesting challenges were trying to think about . 

203
00:20:20,811 --> 00:20:22,660
The problem is , how do those different ? 

204
00:20:22,810 --> 00:20:27,540
Let's call the resolutions are scale that which we can consider behavior overlap and interact . 

205
00:20:28,220 --> 00:20:39,890
So how does your identity as a father overlap with your identity as an american overlap with your identity is in your age group , for example . 

206
00:20:40,200 --> 00:20:41,020
So they overlap . 

207
00:20:41,020 --> 00:20:41,880
They interact . 

208
00:20:41,880 --> 00:20:44,340
They may dominate in different situations . 

209
00:20:44,690 --> 00:20:45,860
So how do those ? 

210
00:20:45,940 --> 00:20:46,860
How do they operate ? 

211
00:20:46,860 --> 00:20:51,800
How do we understand a small organization differently than we understand the whole region of. 

212
00:20:52,010 --> 00:21:02,580
So in another interesting thing , I doubt is that so often , the technologies that programming roles are working on our powerful enough that they have tremendous promise . 

213
00:21:03,650 --> 00:21:25,380
But also some potential parallel , you know , and some interested in your view of getting your topic if your program really succeeds , we develop new ways of understanding social behavior at skills that we've never had a kind of access to before what excites you most about that kind of new way of understanding and. 

214
00:21:25,410 --> 00:21:27,800
When you think about it , what kind of gives you some parts ? 

215
00:21:28,000 --> 00:21:31,820
So I get very excited about the cycle benefit sites . 

216
00:21:31,820 --> 00:21:42,440
I get excited about making sure people get personated appropriately , making sure people get appropriate health care that during crisis they were able to guide people on an appropriate way . 

217
00:21:42,660 --> 00:21:52,447
I feel very strongly to those are the really beneficial aspects of this , but there's a dark side too , which is I wanna be prepared . 

218
00:21:52,447 --> 00:22:02,250
If other nation's government's groups decide to spread information that is so , and what do we do about that as a nation ? 

219
00:22:02,700 --> 00:22:05,590
So I like to think about it in kind of three boxes . 

220
00:22:05,910 --> 00:22:08,830
There's , you know , what is the USgovernment can do ? 

221
00:22:08,830 --> 00:22:18,360
We have a lot of laws and regulations that are very specific about how we communicate , both without population in foreign populations , the same as this kind of privacy in ethics . 

222
00:22:19,820 --> 00:22:23,430
We also have american corporations that may have different rules . 

223
00:22:23,430 --> 00:22:33,830
They may forget you to click on that any user license agreement , and then we have other folks in the world that have very different perspectives on how you might use this models of social behavior . 

224
00:22:33,830 --> 00:22:37,340
So i'm perhaps there's a persevere gym . 

225
00:22:37,340 --> 00:22:45,570
Perhaps there's a terrorist organization that I want to understand how they are pushing out their messages and how they are creating infants . 

226
00:22:46,020 --> 00:22:47,400
Why not think anyone else wants? 

227
00:22:47,510 --> 00:22:50,570
Right now , what another thing that came up in another conversation . 

228
00:22:50,570 --> 00:23:11,290
Uni , jonathan , a pad in which you can have revealed to me that not only are you thinking about really large scales , but you also thinking in terms of the snow , our skills that say in family units and the way our relationship to information technologies and changing the way we relate to each other and to our machines . 

229
00:23:11,290 --> 00:23:18,814
So I refer the issue of politicians that you have a little bit of a sample writing your household . 

230
00:23:18,814 --> 00:23:21,267
Tell me a little bit of a sweet . 

231
00:23:21,267 --> 00:23:23,420
What's your observing children? 

232
00:23:23,720 --> 00:23:29,081
Relate two machines now , this sexy , motivated some , some work that we're funding . 

233
00:23:29,081 --> 00:23:31,494
So with my children we've ever . 

234
00:23:31,494 --> 00:23:34,175
And alexa name is an ago in our home . 

235
00:23:34,175 --> 00:23:46,377
And they like , ask for jokes , but they also liked to ask for questions like alexa , what's the smallest thing in the universe and alex position at work , which is pretty cool . 

236
00:23:46,377 --> 00:23:51,330
They'll say electronic music , and then they did get me some juice . 

237
00:23:52,270 --> 00:23:58,480
And I say , with a second , you , let's not quite how you should speak to your father , and you say , please . 

238
00:23:59,100 --> 00:24:08,800
And that let me to , I think , quite a bit about adequate , and there's actually sociological models of adequate that describe wearing how we use phrases like , please . 

239
00:24:08,800 --> 00:24:09,890
And thank you with each other . 

240
00:24:10,420 --> 00:24:15,210
And to me , this is a very natural place to go when you think about information spreading . 

241
00:24:15,210 --> 00:24:16,410
Why does information spread ? 

242
00:24:16,410 --> 00:24:22,560
How do those places help or hinder that information may , may spread. 

243
00:24:23,280 --> 00:24:26,000
Are you asking your daughters too? 

244
00:24:26,050 --> 00:24:27,885
Be polite with a lecturer . 

245
00:24:27,885 --> 00:24:40,190
No , I haven't , but it raises a whole method conversation about how we interact with machines , and we see machines in the future as partners teammates . 

246
00:24:40,580 --> 00:24:41,700
Or do we see them as tools ? 

247
00:24:42,150 --> 00:24:50,140
And if we ever want to move notion of machines as tools , we have to think about some of these sociological principles of how we interact. 

248
00:24:50,820 --> 00:24:57,050
Okay , so that actually gets to another question for me , a big one that I wanted to ask you . 

249
00:24:57,050 --> 00:25:01,615
So you talking about how machines can are evolving along with us . 

250
00:25:01,615 --> 00:25:08,279
And when I think about robots and artificial intelligence , and these kinds of conversions is coming together . 

251
00:25:08,279 --> 00:25:21,770
Yeah , there are discussions out there about what happened if we develop artificial intelligence tools , we deliberate , but where we almost want to say , or we do want to say these are new types . 

252
00:25:22,550 --> 00:25:25,860
Being ethics comes in here in a huge way . 

253
00:25:26,260 --> 00:25:29,880
If this is the case , and this has worked in a big thing about machines . 

254
00:25:29,880 --> 00:25:32,860
Do we have to think about what their rights ? 

255
00:25:33,300 --> 00:25:37,940
I know you think about this or what , and I want you to tell me in our listeners. 

256
00:25:38,010 --> 00:25:40,037
How you are thinking about this year . 

257
00:25:40,037 --> 00:25:43,687
So so let me just back up from the notion of consciousness first . 

258
00:25:43,687 --> 00:25:45,310
And let's talk about emerges . 

259
00:25:45,310 --> 00:25:47,398
Emergencies are kind of fun work . 

260
00:25:47,398 --> 00:25:59,930
Because if you've started thinking about a society is something that comes out of a bunch of individuals , pretty interesting that isn't platform can appear almost almost as a surprise . 

261
00:26:00,030 --> 00:26:01,630
We have this organized city. 

262
00:26:01,720 --> 00:26:10,120
In the physics world , the chemistry relationship said the properties of water emerge out of hydrogen and oxygen , both of them gases . 

263
00:26:10,120 --> 00:26:11,910
In normal conditions . 

264
00:26:12,080 --> 00:26:14,304
Neither of those has properties avoidable . 

265
00:26:14,304 --> 00:26:19,308
When then combine an academic correction of four more than you have the emergent properties of water . 

266
00:26:19,308 --> 00:26:22,460
But I just want to connect with yourself , emergency and social. 

267
00:26:22,490 --> 00:26:24,630
Actually has a kind of quality and absolutely . 

268
00:26:24,630 --> 00:26:29,372
And if you go to terminate sounds , and you go to employees , you see the east . 

269
00:26:29,372 --> 00:26:32,150
You see this amazing american properties . 

270
00:26:32,150 --> 00:26:43,870
So it , it leads us to ask questions about artificial intelligence , and it leads us down a path to looking whether have been emergent in our action . 

271
00:26:43,870 --> 00:26:58,730
So if you follow the notion of flash crashes on , you have automated trading systems operating in a regulated environment competitively , and occasionally the interaction of ways is unexpected . 

272
00:26:58,850 --> 00:27:05,796
So we have to ask ourselves , if we're being honest , we could say we can't always anticipate all of these things . 

273
00:27:05,796 --> 00:27:17,590
So with all of the discussion today that you hear about safe AI double , I think , needs to be think ten years out , fifty years out , saying , what if there is something more than simply safety? 

274
00:27:17,650 --> 00:27:20,952
That we need to be considering all right , we'll genocide on . 

275
00:27:20,952 --> 00:27:34,587
I'm glad that we have a program manager like yourself was thinking about these things as go off without knowing how the future is going to follow in our new interactions with the massive medal people and mass of machinery structure . 

276
00:27:34,587 --> 00:27:37,980
So , so you're asking really fascinating questions . 

277
00:27:38,010 --> 00:27:42,310
This conversation is just been fantastic , and I want to thank you for sharing some time with me . 

278
00:27:42,480 --> 00:27:47,400
Of course , I am happy to share , and thanks listeners for sharing your time with us . 

279
00:27:47,630 --> 00:27:50,840
I hope you join us again for the next voices from dark . 

280
00:27:53,930 --> 00:28:02,340
For more information about jonathan thoughts , his social , same program and the other break through technology is dark , is working on visit darker than no . 

