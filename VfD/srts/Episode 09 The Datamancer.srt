1
00:00:13,312 --> 00:00:13,824
The internet

2
00:00:15,360 --> 00:00:15,872
Your hands

3
00:00:19,456 --> 00:00:21,248
Technology is a driver of our time

4
00:00:21,760 --> 00:00:23,040
Since its founding a 19

5
00:00:23,296 --> 00:00:24,576
58 in the midst of the Cold War

6
00:00:25,088 --> 00:00:25,600
DARPA

7
00:00:25,856 --> 00:00:27,904
The defense Advanced research projects agency

8
00:00:28,416 --> 00:00:29,184
Has been a driver

9
00:00:29,696 --> 00:00:30,208
Technology

10
00:00:30,720 --> 00:00:32,256
Welcome to Voices from DARPA

11
00:00:32,768 --> 00:00:35,328
A window onto DARPA score of program manager

12
00:00:36,096 --> 00:00:36,864
Their job

13
00:00:37,120 --> 00:00:38,144
To redefine

14
00:00:38,400 --> 00:00:38,912
What is pasa

15
00:00:39,936 --> 00:00:41,216
My name is Ivan Amato

16
00:00:41,472 --> 00:00:42,752
I'm your DARPA host

17
00:00:43,008 --> 00:00:45,312
And today I'm pleased to have with me in the studio

18
00:00:45,824 --> 00:00:46,848
Wade Shen

19
00:00:47,104 --> 00:00:49,408
Program manager since 2014 in DARPA

20
00:00:49,664 --> 00:00:51,456
Is information Innovation office

21
00:00:52,224 --> 00:00:53,504
Wade earned a bachelor's

22
00:00:53,760 --> 00:00:54,272
Degree in Electra

23
00:00:54,528 --> 00:00:55,040
Google Engineering in

24
00:00:55,296 --> 00:00:57,088
Computer science from the University of

25
00:00:57,344 --> 00:00:57,856
Sanya Berkeley

26
00:00:58,112 --> 00:01:00,928
Event attended the University of Maryland College Park which is

27
00:01:01,440 --> 00:01:02,464
About 20 miles from where we

28
00:01:02,720 --> 00:01:04,000
We are sitting in DARPA headquarters

29
00:01:04,256 --> 00:01:06,048
Where he received his master's

30
00:01:06,816 --> 00:01:07,328
Pseudoscience

31
00:01:07,840 --> 00:01:11,424
And prior to coming to door but wait worked at the MIT Lincoln Laboratory

32
00:01:11,680 --> 00:01:13,728
In the human language technology

33
00:01:14,752 --> 00:01:17,824
You can tell from the portfolio of program to run zadar bus

34
00:01:18,080 --> 00:01:20,128
That he is fascinated by language both

35
00:01:20,384 --> 00:01:21,920
Of the humankind end of the

36
00:01:23,200 --> 00:01:27,296
And you can tell also that is driven by a very DARPA s vision

37
00:01:27,552 --> 00:01:29,088
Of computers and human beings

38
00:01:29,344 --> 00:01:30,112
Working together

39
00:01:30,624 --> 00:01:32,672
In ways that extend what either type of

40
00:01:33,696 --> 00:01:34,464
Computer and tablet

41
00:01:34,720 --> 00:01:35,488
Or human intelligence

42
00:01:36,256 --> 00:01:37,024
Can do on it

43
00:01:37,280 --> 00:01:38,816
It's own so thanks wait for

44
00:01:39,072 --> 00:01:39,840
Joining me in the studio

45
00:01:40,352 --> 00:01:41,120
Thanks Ivan

46
00:01:42,144 --> 00:01:45,472
It would start out by talking about you wait a little bit about you

47
00:01:45,984 --> 00:01:46,496
Background

48
00:01:46,752 --> 00:01:48,544
How you ended up

49
00:01:50,592 --> 00:01:51,104
Sure

50
00:01:51,616 --> 00:01:53,152
So in a DARPA has his long

51
00:01:53,408 --> 00:01:54,432
String of research

52
00:01:54,688 --> 00:01:56,224
In communicating with

53
00:01:56,992 --> 00:01:58,272
Computers in various forms

54
00:01:59,552 --> 00:02:03,648
I've been involved in a number of those programs over many years

55
00:02:04,160 --> 00:02:07,232
From from days of being a graduate student through

56
00:02:07,744 --> 00:02:08,768
Answer my time at Lincoln

57
00:02:09,536 --> 00:02:14,144
And and what sort of natural progression I was working on a program as a

58
00:02:14,400 --> 00:02:15,424
As a pi and then

59
00:02:15,936 --> 00:02:18,752
You know I do the program manager really well and

60
00:02:19,008 --> 00:02:20,032
And you said hey you know you should

61
00:02:20,288 --> 00:02:21,312
Should think about coming to DARPA

62
00:02:21,568 --> 00:02:23,872
This is an opportunity to do things that

63
00:02:24,128 --> 00:02:25,664
You can't possibly do

64
00:02:25,920 --> 00:02:26,432
In the job that you

65
00:02:26,688 --> 00:02:27,200
Currently at

66
00:02:28,224 --> 00:02:31,040
Before we dive into some of the DARPA programs you oversee

67
00:02:31,552 --> 00:02:37,696
I'm hoping you can let us in on some of the overarching ideas you have about human Minds

68
00:02:37,952 --> 00:02:38,720
Computerminds

69
00:02:38,976 --> 00:02:39,488
The language

70
00:02:40,000 --> 00:02:44,864
Press in the context of these times of our time when so much of what we

71
00:02:45,120 --> 00:02:46,144
Do involves

72
00:02:46,912 --> 00:02:47,424
Interactive

73
00:02:48,704 --> 00:02:50,752
You know the sort of the history of this is that

74
00:02:51,264 --> 00:02:53,824
ARROW computers were good at various

75
00:02:54,080 --> 00:02:58,944
Kinds of things that humans weren't good at like doing mathematical calculations without errors

76
00:02:59,200 --> 00:03:00,992
Sina repeatedly and very quickly

77
00:03:01,504 --> 00:03:04,320
But the fact is that we didn't quite know how to harness that

78
00:03:04,576 --> 00:03:05,088
Solve

79
00:03:05,600 --> 00:03:07,392
Problems that we really cared about so any

80
00:03:07,648 --> 00:03:08,672
Serious problem

81
00:03:08,928 --> 00:03:10,976
Like decision-making of any kind

82
00:03:11,488 --> 00:03:14,048
Global scale policy anything that you might think of

83
00:03:14,304 --> 00:03:15,584
Yunnan requiring humidex

84
00:03:15,840 --> 00:03:16,608
Batista do

85
00:03:17,120 --> 00:03:19,168
Yeah that wasn't something that we would engage

86
00:03:19,424 --> 00:03:23,008
Computers in right it's just now that we're thinking about having computers drive car

87
00:03:23,776 --> 00:03:24,288
Right

88
00:03:24,544 --> 00:03:26,848
And that's a very basic function that

89
00:03:27,360 --> 00:03:28,128
We Trust

90
00:03:28,384 --> 00:03:29,664
Large portions of our popular

91
00:03:30,176 --> 00:03:30,688
Yuan to do

92
00:03:30,944 --> 00:03:32,992
And comes naturally to human beings with c

93
00:03:33,248 --> 00:03:33,760
Some practice

94
00:03:34,272 --> 00:03:37,600
But computers are just getting to the point where they can sense the world

95
00:03:37,856 --> 00:03:41,440
Well enough that they can do that and they can make decisions that are

96
00:03:41,696 --> 00:03:44,256
Are commensurate with what human beings can do

97
00:03:44,768 --> 00:03:46,304
On this very basic tasks

98
00:03:47,072 --> 00:03:52,192
And a number of us want computers to be smarter because we want them to be companions I can help

99
00:03:52,448 --> 00:03:53,216
Must do things right

100
00:03:53,728 --> 00:03:54,752
You know we want them to

101
00:03:55,008 --> 00:03:57,056
Help us solve problems that are really really hard

102
00:03:58,080 --> 00:04:00,128
How to make decisions that are much more complicated than

103
00:04:00,384 --> 00:04:01,152
Just driving a car for

104
00:04:01,920 --> 00:04:02,688
Right so let me just

105
00:04:02,944 --> 00:04:04,224
Stop Yuan on this idea

106
00:04:04,480 --> 00:04:04,992
Computer is making

107
00:04:05,248 --> 00:04:05,760
Decisions because

108
00:04:06,528 --> 00:04:07,552
You know for the life of me I

109
00:04:07,808 --> 00:04:08,576
I cannot really

110
00:04:09,088 --> 00:04:11,648
Always parse out how I make my own decisions

111
00:04:11,904 --> 00:04:12,672
I presume that I'm

112
00:04:12,928 --> 00:04:13,440
Bringing in

113
00:04:13,696 --> 00:04:17,791
Different kinds of data different elements and then there's some kind of algorithm going out of my own head

114
00:04:18,303 --> 00:04:19,071
By which I

115
00:04:19,327 --> 00:04:23,423
I make a decision about where I'm going to go today or if I'm going to buy this item versus

116
00:04:23,679 --> 00:04:24,191
That item

117
00:04:24,703 --> 00:04:27,263
So can you talk to me a little bit about

118
00:04:27,775 --> 00:04:29,055
What does it take to

119
00:04:29,567 --> 00:04:33,407
Put that mystery you know into a working in a working way into a computer

120
00:04:33,663 --> 00:04:34,431
The mystery of decision

121
00:04:34,943 --> 00:04:36,735
It isn't necessarily the case that we wanted mimic

122
00:04:37,759 --> 00:04:38,271
Anyway

123
00:04:38,527 --> 00:04:39,807
Human beings aren't always

124
00:04:40,063 --> 00:04:41,343
Great at making decisions

125
00:04:41,855 --> 00:04:47,231
Yeah you know about the study of of children and whether or not they'll take a Snickers bar now versus

126
00:04:47,487 --> 00:04:52,351
Universes waiting for 30 minutes and then getting five Snickers bars and you know they always choose the

127
00:04:52,607 --> 00:04:54,143
Is the satisfaction now

128
00:04:54,655 --> 00:05:00,799
And so we have all sorts of biases in her own decision-making that makes us make decisions that are suboptimal for our own

129
00:05:01,055 --> 00:05:01,567
Outcomes

130
00:05:02,079 --> 00:05:02,591
Right

131
00:05:02,847 --> 00:05:08,735
And this happens at huge scales and happens when we make political decisions that happen to a make economic decisions

132
00:05:09,247 --> 00:05:10,015
And so on and so forth

133
00:05:10,783 --> 00:05:14,623
And what you hope for is the ability to make

134
00:05:14,879 --> 00:05:16,927
Better decisions given an outcome goal

135
00:05:17,183 --> 00:05:17,951
What you have

136
00:05:18,463 --> 00:05:22,559
Iena based on better data and better understanding of

137
00:05:23,071 --> 00:05:24,351
The process is under the hood

138
00:05:24,607 --> 00:05:25,631
And that's why I think computers

139
00:05:26,143 --> 00:05:29,215
All right well I for one would personally like to be in a position where

140
00:05:29,471 --> 00:05:33,055
Where I can make better decisions on my own personal life if we can do that also on

141
00:05:33,311 --> 00:05:35,359
National and geopolitical scales

142
00:05:35,615 --> 00:05:38,175
All the better so all the power to you wait I hope

143
00:05:40,223 --> 00:05:42,015
Going to do now is just

144
00:05:42,271 --> 00:05:44,319
Talk to you little bit about your portfolio of

145
00:05:44,575 --> 00:05:50,719
Program start with the memex program and tell us a little bit about what that is about and

146
00:05:50,975 --> 00:05:52,767
What its status is now it's been used

147
00:05:53,535 --> 00:05:55,839
Yes at the premise behind the next program is

148
00:05:56,095 --> 00:05:56,863
This is really very simple

149
00:05:57,631 --> 00:05:59,935
It's the Thursday de out there on the internet

150
00:06:00,447 --> 00:06:04,543
That we can't quite get a hold of or make sense of for investing

151
00:06:06,079 --> 00:06:07,103
So are our

152
00:06:07,359 --> 00:06:08,895
Our program concept was

153
00:06:09,151 --> 00:06:10,175
How do we

154
00:06:10,431 --> 00:06:12,991
Help people who are doing investigations online and

155
00:06:13,247 --> 00:06:16,575
And we started with human trafficking because human trafficking is something to wear

156
00:06:16,831 --> 00:06:19,135
The point of sale is almost always online at least

157
00:06:19,391 --> 00:06:20,159
For sex trafficking

158
00:06:20,671 --> 00:06:23,487
We started with that particular domain

159
00:06:23,743 --> 00:06:25,023
Because we we noticed that

160
00:06:25,279 --> 00:06:26,303
The date is online

161
00:06:26,815 --> 00:06:28,351
You know people

162
00:06:28,607 --> 00:06:29,631
Buy and sell

163
00:06:29,887 --> 00:06:35,263
Human beings online in ways that are grotesque and and overt at the same time

164
00:06:36,031 --> 00:06:42,175
And yet because of the volume of the date of the South there because it's it's hiding in a huge sea

165
00:06:42,431 --> 00:06:43,455
Even more data

166
00:06:43,711 --> 00:06:46,783
It's actually really hard for investigators to

167
00:06:47,295 --> 00:06:47,807
Explorer

168
00:06:48,063 --> 00:06:50,623
Effectively and it's not just the data that's in the kind of

169
00:06:51,135 --> 00:06:52,671
Most of us think of is the normal web

170
00:06:52,927 --> 00:06:53,439
Which is index by

171
00:06:53,695 --> 00:06:54,975
Binaural search engines baidu

172
00:06:55,231 --> 00:06:59,071
Another places that's right it's in places like the Deep Web and the dark web

173
00:06:59,583 --> 00:07:03,935
Places that commercial search indexes don't spend a lot of time dealing with

174
00:07:04,447 --> 00:07:05,727
And you know our only

175
00:07:05,983 --> 00:07:09,567
Real view into that data is through commercial circuit

176
00:07:09,823 --> 00:07:13,407
We rely on them to index and make available to

177
00:07:13,663 --> 00:07:14,175
Search

178
00:07:14,431 --> 00:07:15,967
The content that's online

179
00:07:16,479 --> 00:07:17,247
And if it's not index

180
00:07:17,503 --> 00:07:19,039
Or available through Google

181
00:07:19,295 --> 00:07:20,575
Is very likely you're never going to see it

182
00:07:21,087 --> 00:07:24,671
And so portions of the darkweb where a lot of crime happens

183
00:07:24,927 --> 00:07:30,303
Portions of the Deep Web where lots of ads for Saxon for prostitution exist

184
00:07:30,559 --> 00:07:33,119
A lot of that isn't fully indexed by our commercial

185
00:07:33,375 --> 00:07:33,887
Search engines

186
00:07:34,399 --> 00:07:37,471
And so the premise of the program was collect the right data

187
00:07:37,727 --> 00:07:41,823
And then automatically organize that data in such a way that we can

188
00:07:42,079 --> 00:07:45,407
Explore that data and most importantly generate leads into

189
00:07:45,663 --> 00:07:47,711
Detect instances of

190
00:07:47,967 --> 00:07:48,735
About activity

191
00:07:49,503 --> 00:07:53,599
And so we have been working for the last almost three years now

192
00:07:53,855 --> 00:07:59,999
To build a system that would help investigators one chase down leads that they have but to also identify

193
00:08:00,255 --> 00:08:01,023
Delete automatically

194
00:08:01,791 --> 00:08:03,583
Potentially

195
00:08:03,839 --> 00:08:06,143
Potentially ads that are associated

196
00:08:06,399 --> 00:08:08,447
It was trafficking so that they can prioritize R&B

197
00:08:08,703 --> 00:08:09,215
Instigations

198
00:08:09,983 --> 00:08:15,615
And so the concept here is sort of back to this team of human machine interaction the concept here is

199
00:08:16,127 --> 00:08:18,687
How do you help the investigator get to the data that

200
00:08:18,943 --> 00:08:20,223
Salient for their particular

201
00:08:20,479 --> 00:08:22,015
Investigation

202
00:08:22,271 --> 00:08:25,343
And then how do you help them analyze data that they can't possibly NY

203
00:08:25,599 --> 00:08:26,111
Lights on their own

204
00:08:26,623 --> 00:08:29,439
You know one of the key findings in that program was that

205
00:08:29,951 --> 00:08:35,327
Pricing behaviors of organizations that are involved in trafficking look different than

206
00:08:35,583 --> 00:08:37,119
Pricing behaviors of

207
00:08:37,375 --> 00:08:38,911
If you don't normal

208
00:08:39,167 --> 00:08:40,959
Independent contractor process

209
00:08:41,471 --> 00:08:47,103
And you can detect those time you can detect those patterns but you can't see that by reading an individual add online

210
00:08:47,615 --> 00:08:50,431
You have to look collectively at a whole bunch of ads

211
00:08:50,943 --> 00:08:54,271
Author by the same person sometimes tens of thousands of them

212
00:08:55,295 --> 00:08:58,623
In order to understand the statistical pattern of how they price

213
00:08:59,135 --> 00:09:01,951
Right do they price risky behaviors differently

214
00:09:02,207 --> 00:09:04,255
Then the average in that Marketplace

215
00:09:04,767 --> 00:09:06,047
That's the kind of question that's

216
00:09:06,303 --> 00:09:11,167
Very very hard for an individual to answer without analytics that help them do that in Alice

217
00:09:12,447 --> 00:09:15,263
And so and Wade have has this tool memex

218
00:09:15,519 --> 00:09:19,615
Letter I guess the kind of deliverable that I imagine we all want which is sort of taking down

219
00:09:19,871 --> 00:09:21,663
Sex trafficking Rings or other criminal activity

220
00:09:21,919 --> 00:09:22,943
Yasso

221
00:09:23,199 --> 00:09:27,295
You know since the beginning of this program we have been engaged with

222
00:09:27,551 --> 00:09:33,695
Law enforcement agencies across the country and really across the world we have users in the UK and Canada and Australia

223
00:09:34,207 --> 00:09:36,255
And other places not just the United States

224
00:09:36,511 --> 00:09:37,535
Who are

225
00:09:37,791 --> 00:09:39,071
Everyday working with these

226
00:09:39,327 --> 00:09:43,423
Tools to arrest people at this point we have hundreds of arrests that have been

227
00:09:43,679 --> 00:09:45,471
Credited to the use of the memex tool

228
00:09:45,983 --> 00:09:48,031
And a number of different convictions

229
00:09:48,287 --> 00:09:49,055
That have happened out of that

230
00:09:49,823 --> 00:09:55,967
Well that sounds like at least a slightly improved world so that's great news what's a Segway

231
00:09:56,223 --> 00:10:00,063
To another one of your programs the data-driven discovery of

232
00:10:00,575 --> 00:10:06,719
Models program so Wade what are you what are you trying to do with this sand and what's the status of this program

233
00:10:06,975 --> 00:10:08,511
Thought in this program is that

234
00:10:09,023 --> 00:10:12,863
You know when we want to construct an empirical model of how the world works

235
00:10:13,375 --> 00:10:15,935
We use data to do that nowadays are stated everywhere

236
00:10:16,447 --> 00:10:17,215
And so the

237
00:10:17,471 --> 00:10:20,543
Omak for us to construct models of how the world works

238
00:10:20,799 --> 00:10:21,311
Isn't the

239
00:10:21,823 --> 00:10:26,687
You know isn't any longer the collection of the data itself necessarily but the actual

240
00:10:26,943 --> 00:10:27,711
Process of

241
00:10:27,967 --> 00:10:31,295
Constructing a model that process is something that's relegated to

242
00:10:31,551 --> 00:10:33,855
People who are typically called data scientist

243
00:10:34,111 --> 00:10:34,879
Machine learning

244
00:10:35,391 --> 00:10:36,671
Are statisticians right

245
00:10:36,927 --> 00:10:38,463
People with that kind of title

246
00:10:38,719 --> 00:10:39,487
Associated with them

247
00:10:39,999 --> 00:10:43,583
And though that the effort involved in constructing those models is

248
00:10:43,839 --> 00:10:44,607
Huge right it's

249
00:10:44,863 --> 00:10:47,423
Hundreds if not thousands of man years of effort

250
00:10:47,679 --> 00:10:50,751
Largely because the data is messy largely because

251
00:10:51,007 --> 00:10:54,079
How they model that data statistically requires lots of x

252
00:10:54,335 --> 00:10:55,359
Expertise in the areas

253
00:10:55,615 --> 00:10:56,127
The statistics of

254
00:10:56,383 --> 00:10:56,895
Machine learning

255
00:10:57,407 --> 00:10:59,455
And so what we've basically said is hey let's

256
00:10:59,711 --> 00:11:03,295
Take that out of the hands of those kinds of experts in automated

257
00:11:07,135 --> 00:11:08,159
But also I want to

258
00:11:08,415 --> 00:11:10,207
Listen to have a little bit more of a concrete set

259
00:11:10,463 --> 00:11:11,999
Have you been talkin and serve in general terms about

260
00:11:12,511 --> 00:11:13,535
Yo models

261
00:11:13,791 --> 00:11:14,303
And and

262
00:11:14,559 --> 00:11:15,071
System

263
00:11:15,327 --> 00:11:17,119
What might be some of the specific

264
00:11:17,375 --> 00:11:17,887
Say phenomena

265
00:11:18,143 --> 00:11:18,655
What you're talking about

266
00:11:20,703 --> 00:11:21,215
Model development

267
00:11:21,727 --> 00:11:24,543
Just to give you a couple of problems that are concrete

268
00:11:24,799 --> 00:11:25,823
The people have been thinking about

269
00:11:26,335 --> 00:11:30,943
One is you know how would you given different kinds of

270
00:11:31,455 --> 00:11:31,967
Genotypes

271
00:11:32,223 --> 00:11:34,015
Various forms of

272
00:11:34,271 --> 00:11:34,783
Wheat

273
00:11:35,039 --> 00:11:36,575
How would you predict the yield

274
00:11:36,831 --> 00:11:37,855
Of those varieties

275
00:11:38,111 --> 00:11:39,391
Sweet in their different environment

276
00:11:40,671 --> 00:11:46,559
That requires a model and if you could do that you could know what to plant any given year depending on what you

277
00:11:46,815 --> 00:11:48,607
Respect for the weather in

278
00:11:49,119 --> 00:11:50,143
The amount of rain

279
00:11:50,399 --> 00:11:55,263
And the particular soil location you could make decisions that were much smarter than we make

280
00:11:55,519 --> 00:11:56,031
Ignou

281
00:11:56,287 --> 00:11:58,335
And so one of the problems that were working on

282
00:11:58,591 --> 00:12:01,151
Is a question of how do we how do we

283
00:12:01,407 --> 00:12:02,175
Predict crappie

284
00:12:02,943 --> 00:12:04,223
Based on data

285
00:12:04,735 --> 00:12:09,343
And that data can come from genotype data can come from environmental observations of sensors

286
00:12:09,599 --> 00:12:10,111
He liked

287
00:12:10,367 --> 00:12:11,647
Taking pictures of crop fields

288
00:12:12,159 --> 00:12:14,719
I'm making come from you know your Farmers Almanac

289
00:12:14,975 --> 00:12:15,487
The tells you

290
00:12:15,999 --> 00:12:18,047
3 months from now what the weather is likely to be

291
00:12:19,327 --> 00:12:23,423
So those kinds of data can build a predictive model of What kinds

292
00:12:23,679 --> 00:12:25,215
Crop yields you can generate

293
00:12:25,471 --> 00:12:27,263
And if you can do that you can you know

294
00:12:27,519 --> 00:12:29,055
Highly affect the outcomes of Accra

295
00:12:29,823 --> 00:12:31,615
That's just one concrete example

296
00:12:31,871 --> 00:12:32,895
We probably can also link

297
00:12:33,151 --> 00:12:33,919
This to

298
00:12:34,175 --> 00:12:35,199
Big mission of DARPA

299
00:12:36,479 --> 00:12:38,015
In enhancing National Security when we

300
00:12:38,271 --> 00:12:39,039
Even when we're talkin about

301
00:12:39,295 --> 00:12:41,343
Food that relates to things like Foods

302
00:12:41,599 --> 00:12:42,879
Security so we can

303
00:12:43,135 --> 00:12:44,415
Really keep our Foods

304
00:12:44,671 --> 00:12:45,439
Supply

305
00:12:45,695 --> 00:12:46,463
Constantine

306
00:12:46,975 --> 00:12:47,999
At the levels we need that

307
00:12:48,511 --> 00:12:49,791
Does that's right

308
00:12:50,815 --> 00:12:53,631
That's right it did helps us to predict political instability

309
00:12:53,887 --> 00:12:55,423
Different states and countries that we care about

310
00:12:55,935 --> 00:12:58,495
So those kinds of models

311
00:12:58,751 --> 00:13:02,079
Are are always important socio-political models are important

312
00:13:02,335 --> 00:13:03,871
Can you predict whether a riot is

313
00:13:04,127 --> 00:13:04,639
Going to work her

314
00:13:05,151 --> 00:13:10,271
Can you predict that unrest political unrest of a certain type is going to result

315
00:13:10,783 --> 00:13:13,343
10 days from now in some kind of bad event

316
00:13:13,599 --> 00:13:16,415
Those are the kinds of things that you'd like to build models over

317
00:13:16,927 --> 00:13:19,487
What is the challenge that I'm getting a kind of

318
00:13:19,743 --> 00:13:20,767
Computer with access

319
00:13:21,023 --> 00:13:21,791
All kinds of data

320
00:13:22,303 --> 00:13:23,583
Generators

321
00:13:23,839 --> 00:13:26,399
Models I don't know where the human mind comes into this

322
00:13:26,655 --> 00:13:27,679
But to generate those models

323
00:13:27,935 --> 00:13:29,471
From the data and imperfect

324
00:13:31,775 --> 00:13:34,591
So they're sort of two real problems that we have to contend with

325
00:13:34,847 --> 00:13:36,127
So first of all we have

326
00:13:36,383 --> 00:13:38,431
Too much data have too many different kind

327
00:13:38,943 --> 00:13:43,807
And so the problem with that is that we don't know which combinations of the data are likely to

328
00:13:44,063 --> 00:13:45,087
Explain a particular outcome

329
00:13:45,343 --> 00:13:46,367
We care about so if we

330
00:13:46,623 --> 00:13:47,647
Care about crop yields

331
00:13:47,903 --> 00:13:51,487
We need to know the temperatures of veto of

332
00:13:51,743 --> 00:13:55,839
Days prior to a particular event or associated with crop yield outcomes 10 days later

333
00:13:56,351 --> 00:13:57,887
Right that's the kind of thing that

334
00:13:58,143 --> 00:14:00,447
You don't require some subject matter expertise

335
00:14:00,703 --> 00:14:02,239
In agriculture to be able to know

336
00:14:02,751 --> 00:14:03,775
Computers don't know that

337
00:14:04,031 --> 00:14:05,055
Symbiosis

338
00:14:05,311 --> 00:14:06,079
That's right

339
00:14:06,335 --> 00:14:06,847
That's right

340
00:14:07,103 --> 00:14:09,663
So what computers can do is calculated

341
00:14:09,919 --> 00:14:10,943
Statistics bacon

342
00:14:11,199 --> 00:14:12,991
Estimate how well correlated

343
00:14:13,247 --> 00:14:14,783
Particular variable is worth

344
00:14:15,039 --> 00:14:16,319
Particular kind of data is

345
00:14:16,575 --> 00:14:18,111
Torpedo outcome we care about

346
00:14:18,623 --> 00:14:19,391
And so

347
00:14:19,647 --> 00:14:23,231
Computers can discover patterns that human beings have a hard time

348
00:14:23,743 --> 00:14:26,047
Figuring out on their own

349
00:14:26,303 --> 00:14:29,631
But human beings are also very good at figuring out

350
00:14:29,887 --> 00:14:31,423
That some of these patterns are

351
00:14:32,191 --> 00:14:35,007
Some of these patterns are what we call Chance correlation

352
00:14:35,775 --> 00:14:40,383
And so what we would like to do in order to build a really effective model is to find variables that

353
00:14:40,639 --> 00:14:42,175
Matter factors that affect

354
00:14:42,431 --> 00:14:43,455
The outcome of crappie

355
00:14:43,967 --> 00:14:44,479
Princeton

356
00:14:44,735 --> 00:14:46,783
I'd like to be able to do that automatically

357
00:14:47,039 --> 00:14:52,671
But because some subject matter expertise is involved we need the help of a human being to help

358
00:14:52,927 --> 00:14:53,439
Curate

359
00:14:53,951 --> 00:14:54,463
This process

360
00:14:54,975 --> 00:14:57,023
And so in the d3m program

361
00:14:57,279 --> 00:15:03,423
The goal is to make and that's the data-driven Discovery Model

362
00:15:03,679 --> 00:15:05,727
The goal of that program is to

363
00:15:05,983 --> 00:15:09,055
Fundamentally change the category of Labor from

364
00:15:09,311 --> 00:15:12,639
Statistician in machine learning expert that constructs the model

365
00:15:12,895 --> 00:15:14,175
To machine

366
00:15:14,431 --> 00:15:15,711
Plus subject matter

367
00:15:17,759 --> 00:15:22,367
And so the idea is that we have a machine that automatically tests a whole bunch of

368
00:15:22,879 --> 00:15:24,415
And it does so in an efficient way

369
00:15:24,927 --> 00:15:29,535
And you know general for most of these problems are infinitely many models that could be used

370
00:15:30,047 --> 00:15:31,839
Answer the question is how do you find the right one

371
00:15:32,607 --> 00:15:35,679
The machines are very good at doing that testing in an automated fashion

372
00:15:36,191 --> 00:15:40,287
And if they can work with you and beings to constrain the kinds of models that they

373
00:15:40,543 --> 00:15:41,055
Explorer

374
00:15:41,311 --> 00:15:45,663
They can potentially find models very very quickly very effectively without the

375
00:15:45,919 --> 00:15:46,431
Need for

376
00:15:46,687 --> 00:15:47,455
Expert machine learning

377
00:15:47,967 --> 00:15:48,991
Personnel

378
00:15:49,503 --> 00:15:50,015
Or Davis

379
00:15:51,551 --> 00:15:52,063
Fascinating

380
00:15:52,575 --> 00:15:54,879
So let's move to the third program

381
00:15:55,135 --> 00:15:55,903
Quantitative

382
00:15:56,415 --> 00:15:56,927
Crisis

383
00:15:57,183 --> 00:15:57,695
Response

384
00:15:58,463 --> 00:15:59,231
Again a little bit of it

385
00:15:59,487 --> 00:16:00,511
Description of a program

386
00:16:00,767 --> 00:16:01,535
And what kind of frog

387
00:16:02,559 --> 00:16:05,631
So the goal in like you Ciara quantitative crisis response

388
00:16:05,887 --> 00:16:06,399
Program

389
00:16:06,655 --> 00:16:07,935
West of figure out

390
00:16:08,191 --> 00:16:09,983
How information affects p

391
00:16:11,007 --> 00:16:12,287
+ 2

392
00:16:12,543 --> 00:16:14,079
Build a way to measure that

393
00:16:14,847 --> 00:16:17,151
That's the fundamental goal in our program

394
00:16:17,919 --> 00:16:24,063
So you know with social media and fake news and propaganda being distributed by organizations

395
00:16:24,319 --> 00:16:24,831
Like Isis

396
00:16:25,343 --> 00:16:28,927
Write our goal was to figure out how does that turn into a radicalization

397
00:16:29,951 --> 00:16:32,511
How is it that videos online

398
00:16:33,535 --> 00:16:35,583
Convert people into Fighters

399
00:16:35,839 --> 00:16:36,351
On the battle

400
00:16:36,863 --> 00:16:39,423
So what we've been doing in that program is

401
00:16:39,679 --> 00:16:41,215
Building models again

402
00:16:41,471 --> 00:16:44,031
How human beings respond properly

403
00:16:45,055 --> 00:16:46,847
And how effective

404
00:16:47,103 --> 00:16:48,127
Spitzer propaganda

405
00:16:48,383 --> 00:16:48,895
AR

406
00:16:49,151 --> 00:16:51,199
By looking at measurements of

407
00:16:51,455 --> 00:16:52,735
How people react in place

408
00:16:54,527 --> 00:16:58,367
And so the fundamental goal there is to build what we call a measure of effective

409
00:16:59,135 --> 00:17:03,743
Which is really a way to measure concrete outcomes associated with

410
00:17:03,999 --> 00:17:06,559
Various bits of information that are put out their various bits

411
00:17:08,607 --> 00:17:12,959
So you know the in the last couple of years what we've seen is that organizations like Isis can reach

412
00:17:13,471 --> 00:17:15,263
Millions of people through social media

413
00:17:15,775 --> 00:17:21,919
And they effectively recruit a small number of them but still you know when you can recruit million small

414
00:17:22,175 --> 00:17:23,967
All percentages add up to a lot of Fighters

415
00:17:24,479 --> 00:17:26,271
Answer the question is how do they do that

416
00:17:26,527 --> 00:17:32,671
I want one hand and how effective are we at stopping them or at you know are they at actually

417
00:17:32,927 --> 00:17:33,695
Achieving that outcome

418
00:17:34,463 --> 00:17:37,535
And so what we've been building is essentially a gauge is essentially a meter

419
00:17:37,791 --> 00:17:38,559
That says

420
00:17:38,815 --> 00:17:42,655
Oh today that message that you put out has a higher degree of

421
00:17:42,911 --> 00:17:44,959
Potential for radicalizing people than the one that you

422
00:17:45,471 --> 00:17:45,983
Yesterday

423
00:17:46,495 --> 00:17:49,055
And why that matters is that it allows us

424
00:17:49,311 --> 00:17:51,615
People who are interested in countering radicalization

425
00:17:52,127 --> 00:17:52,639
2

426
00:17:52,895 --> 00:17:55,711
Estimate how well we're doing at preventing that radical

427
00:17:55,967 --> 00:17:56,479
Causation from

428
00:17:57,503 --> 00:18:00,063
Or Century building a meter that allows us to know whether or not

429
00:18:00,319 --> 00:18:00,831
We're doing well

430
00:18:01,343 --> 00:18:01,855
Or poorly

431
00:18:02,623 --> 00:18:04,159
A1 theme

432
00:18:05,439 --> 00:18:07,999
I seem to apply maybe all of these programs

433
00:18:08,511 --> 00:18:09,023
Is

434
00:18:09,279 --> 00:18:10,559
That idea of

435
00:18:10,815 --> 00:18:12,351
You know how can

436
00:18:12,863 --> 00:18:15,167
Human beings and their machines and their come

437
00:18:15,423 --> 00:18:19,519
Computers and all of their online resources how can all of these things work together

438
00:18:20,031 --> 00:18:21,567
It could have been a symbiotic way

439
00:18:21,823 --> 00:18:23,615
Play so that we drive

440
00:18:23,871 --> 00:18:24,639
Knowledge

441
00:18:24,895 --> 00:18:26,431
Wisdom from all of this interaction

442
00:18:26,687 --> 00:18:28,223
It reminds me of

443
00:18:28,479 --> 00:18:30,271
Really kind of the early days here of DARPA

444
00:18:31,039 --> 00:18:32,575
In particular I'm thinking of

445
00:18:32,831 --> 00:18:33,855
But one of our more famous

446
00:18:34,111 --> 00:18:34,623
Dinnerly

447
00:18:34,879 --> 00:18:39,231
Program managers Joseph Carl robnett licklider most people know him as

448
00:18:39,487 --> 00:18:39,999
Jcr like

449
00:18:41,023 --> 00:18:43,583
I'm who was even back in the 60s

450
00:18:44,095 --> 00:18:44,607
With the program matter

451
00:18:45,631 --> 00:18:46,655
I was articulating the

452
00:18:46,911 --> 00:18:47,423
What's this idea

453
00:18:47,935 --> 00:18:48,447
Forever symbiosis

454
00:18:48,959 --> 00:18:49,983
Between the human beings and

455
00:18:50,239 --> 00:18:55,615
And machine. Just wondering how how does it feel to be a program manager you know kind of working in this long long

456
00:18:57,151 --> 00:18:58,687
Well First Watch Company

457
00:18:59,199 --> 00:19:01,247
When you look at the history of program managers

458
00:19:01,503 --> 00:19:03,551
The DARPA and the various things that are pissed

459
00:19:03,807 --> 00:19:05,599
Produce over its lifespan

460
00:19:05,855 --> 00:19:07,391
We are all humbled by the

461
00:19:07,647 --> 00:19:09,439
Great outcomes that those folks had in

462
00:19:09,695 --> 00:19:10,463
In the program

463
00:19:11,231 --> 00:19:13,023
That they were produced out of here

464
00:19:13,279 --> 00:19:18,655
You know most of us just try to do our job but all of us are thinking bigger than the things that we could have done our

465
00:19:19,679 --> 00:19:22,495
And that's the thing that darpin genders and all of us

466
00:19:23,007 --> 00:19:26,335
It's the opportunity to explore an area of research

467
00:19:26,591 --> 00:19:28,639
It's much larger than anyone

468
00:19:28,895 --> 00:19:30,431
Research organization can do

469
00:19:31,967 --> 00:19:33,759
Before we close out of our conversation

470
00:19:34,015 --> 00:19:35,295
I think this relates a little bit

471
00:19:35,551 --> 00:19:36,063
What you just said

472
00:19:37,087 --> 00:19:38,623
It's going to stand back from any particular

473
00:19:39,135 --> 00:19:42,975
RAM and maybe share with us some of what you've observed

474
00:19:43,231 --> 00:19:43,743
Closest 24

475
00:19:43,999 --> 00:19:44,767
14 as a program out of

476
00:19:45,535 --> 00:19:47,071
About DARPA's

477
00:19:47,583 --> 00:19:49,375
Roll in the overall

478
00:19:49,631 --> 00:19:50,143
Innovation

479
00:19:50,399 --> 00:19:50,911
Ecos

480
00:19:51,423 --> 00:19:54,495
An ecosystem includes many players and stakeholders

481
00:19:55,007 --> 00:19:56,287
Scientists engineers

482
00:19:56,799 --> 00:19:57,567
In academe

483
00:19:57,823 --> 00:19:58,591
Industry

484
00:19:58,847 --> 00:20:01,407
And government lab those are some of the stakeholders entrepreneurs

485
00:20:01,919 --> 00:20:02,687
Venture capitalist

486
00:20:03,455 --> 00:20:05,759
The science policy community

487
00:20:06,015 --> 00:20:07,039
Ecosystem involves

488
00:20:07,295 --> 00:20:08,575
Most players in the commercial

489
00:20:09,087 --> 00:20:09,599
Armetta hold

490
00:20:10,623 --> 00:20:11,391
Other sectors

491
00:20:12,415 --> 00:20:14,719
So where do you think DARPA fits into this

492
00:20:15,231 --> 00:20:15,743
Overall

493
00:20:16,767 --> 00:20:17,279
Innovation

494
00:20:18,303 --> 00:20:24,447
Well it's it's interesting right so there are a lot of obviously even within the US government or number of organization

495
00:20:24,703 --> 00:20:25,215
Oceans of Fun Bass

496
00:20:26,495 --> 00:20:27,775
Define applied research

497
00:20:28,031 --> 00:20:28,799
Define various

498
00:20:29,055 --> 00:20:30,335
Projects along

499
00:20:30,591 --> 00:20:31,615
That continuum

500
00:20:32,127 --> 00:20:35,967
And I think DARPA has a very unique role it's it it's a role that

501
00:20:36,479 --> 00:20:37,503
Spans the gap

502
00:20:37,759 --> 00:20:39,807
Between basic research and applied science

503
00:20:40,575 --> 00:20:44,927
I often times we are looking for the applications that seem impossible

504
00:20:45,183 --> 00:20:46,463
Whether it's you know

505
00:20:46,719 --> 00:20:50,303
Launching drones off of flying aircraft

506
00:20:50,559 --> 00:20:51,071
Or

507
00:20:51,327 --> 00:20:56,447
You know detecting human trafficking online all of these things are things that

508
00:20:56,703 --> 00:21:01,567
Nowhere emerging capabilities three or four years ago but now have proven to be possible

509
00:21:01,823 --> 00:21:06,175
And so dark isn't a very unique place that allows us to

510
00:21:06,431 --> 00:21:07,711
Push the technology

511
00:21:08,223 --> 00:21:10,527
Beyond the theoretical stages

512
00:21:10,783 --> 00:21:12,575
To the point where we can actually

513
00:21:12,831 --> 00:21:15,903
See where the where the applications are going to be

514
00:21:16,159 --> 00:21:16,672
So

515
00:21:16,928 --> 00:21:17,440
We're not

516
00:21:17,696 --> 00:21:20,256
Builders of the ultimate technology right

517
00:21:20,512 --> 00:21:25,632
At the end of the day we found the research and that research eventually becomes productizing other forms

518
00:21:26,144 --> 00:21:31,264
If you look at the progression of Robotics and self-driving cars

519
00:21:31,520 --> 00:21:35,872
All of those AI technology for curated out of DARPA programs early on

520
00:21:36,384 --> 00:21:40,224
And have subsequently you know a 10-year Horizon after that

521
00:21:40,480 --> 00:21:42,016
You have become

522
00:21:42,528 --> 00:21:43,296
Productize mobile

523
00:21:43,552 --> 00:21:47,392
Industry has been able to take it up so we serve a very crucial role

524
00:21:47,648 --> 00:21:49,952
And the reason that we can serve that role is

525
00:21:50,208 --> 00:21:51,232
Twofold one

526
00:21:51,488 --> 00:21:52,512
The program manager

527
00:21:53,536 --> 00:21:54,048
These folks

528
00:21:54,304 --> 00:21:55,328
Come with the ideas

529
00:21:55,840 --> 00:21:57,632
And they can see the horizon

530
00:21:57,888 --> 00:22:04,032
They've been working in the research they understand the basic research is happening in that field and make a noise like a horizon view of lake

531
00:22:04,288 --> 00:22:05,312
Foods you you had

532
00:22:05,568 --> 00:22:09,664
Boots on the ground in particular of Technology

533
00:22:09,920 --> 00:22:16,064
That's right and we don't stay long and part of the reason we can't stay long is that we're going to lose view of the Horizon if we do right wing

534
00:22:16,320 --> 00:22:17,600
I need to be back in in the guts

535
00:22:17,856 --> 00:22:18,368
To that research

536
00:22:19,136 --> 00:22:22,976
And so all of us are here for a temporary. Of time and I think that was a brilliant

537
00:22:23,232 --> 00:22:25,792
Design decision in terms of how we structure DARPA

538
00:22:26,560 --> 00:22:28,352
The other thing I would say is that the

539
00:22:28,608 --> 00:22:33,216
Funding amounts in the Catalyst the DARPA provides in terms of scope of programs

540
00:22:33,472 --> 00:22:35,008
Is at the right levels

541
00:22:35,264 --> 00:22:36,800
To be able to do the kinds of projects

542
00:22:37,056 --> 00:22:39,104
That we can do is technology demonstrators

543
00:22:39,360 --> 00:22:40,128
What is early prototype

544
00:22:40,640 --> 00:22:43,456
Those are things that are really really hard to do without a

545
00:22:43,968 --> 00:22:44,736
High level of envy

546
00:22:45,760 --> 00:22:47,296
Because they often involve

547
00:22:47,552 --> 00:22:48,320
Multiple disc

548
00:22:48,576 --> 00:22:49,856
Coupons for multiple fields

549
00:22:50,368 --> 00:22:51,904
Who are at the edge of something

550
00:22:52,416 --> 00:22:55,744
But that's something requires them to all work together to build it

551
00:22:56,256 --> 00:23:02,400
And build early-stage prototypes of it and to fail multiple times potentially in the process

552
00:23:02,656 --> 00:23:03,168
Doing that

553
00:23:03,424 --> 00:23:04,960
Yeah you bring up for the failure in

554
00:23:05,216 --> 00:23:06,240
The tolerance for failure here

555
00:23:06,752 --> 00:23:09,056
To me that's one of the most interesting things about DARPA

556
00:23:09,312 --> 00:23:11,360
Because they're they're not all that many other

557
00:23:11,616 --> 00:23:13,664
Stakeholders in the in the Innovation ecosystem

558
00:23:14,176 --> 00:23:16,480
That can actually afford to do that if your company

559
00:23:16,736 --> 00:23:18,528
You might be able to feel a little bit but

560
00:23:19,040 --> 00:23:24,416
You've got to be able to deliver a technology you got to be able to deliver these to your to your stockholders eventually

561
00:23:24,672 --> 00:23:26,208
Where is here I guess

562
00:23:26,720 --> 00:23:28,256
Program managers like you can

563
00:23:28,512 --> 00:23:31,072
Probe technology possibilities

564
00:23:31,328 --> 00:23:32,096
And determined

565
00:23:32,608 --> 00:23:33,632
Is this something that

566
00:23:33,888 --> 00:23:36,960
He's had a good likelihood of moving for another word you can take the risk

567
00:23:37,472 --> 00:23:37,984
Down

568
00:23:38,240 --> 00:23:40,800
For others who then might take it to Ryan exactly

569
00:23:41,056 --> 00:23:45,920
So I worked in startup World prior to it going to Lincoln and one of the things I can tell you there is that

570
00:23:46,176 --> 00:23:48,736
Yeah there's actually relatively little tolerance

571
00:23:48,992 --> 00:23:49,504
Risk

572
00:23:49,760 --> 00:23:52,064
The kinds of risks that you can tolerate

573
00:23:52,320 --> 00:23:53,344
Are not the same as

574
00:23:53,600 --> 00:23:54,368
The kinds of risks that we

575
00:23:54,624 --> 00:23:55,648
Tolerate here at DARPA

576
00:23:55,904 --> 00:23:58,976
The concrete idea that you have in a startup better be

577
00:23:59,232 --> 00:24:02,048
Better be actionable as a product in three to four years

578
00:24:02,304 --> 00:24:03,072
Otherwise

579
00:24:03,584 --> 00:24:06,400
You know there's there's no sense in funding that

580
00:24:06,912 --> 00:24:12,032
There's all sorts of business-related risk execution related risk for technology risk camping

581
00:24:13,568 --> 00:24:14,848
The DARPA we can take technology

582
00:24:15,616 --> 00:24:16,128
Science

583
00:24:17,152 --> 00:24:18,688
And I think that's actually the fundamental

584
00:24:19,968 --> 00:24:20,480
To do what we do

585
00:24:21,248 --> 00:24:25,600
Like other program managers you are a technology developer

586
00:24:26,112 --> 00:24:27,904
Review for exercising your

587
00:24:28,160 --> 00:24:30,464
Science engineering and kind of Technology match

588
00:24:31,232 --> 00:24:31,744
How to eat a match

589
00:24:35,328 --> 00:24:36,096
Nocti

590
00:24:36,352 --> 00:24:40,448
So I'm just wondering if there is a a kind of fictional technology

591
00:24:40,704 --> 00:24:41,216
That you might have been

592
00:24:41,472 --> 00:24:43,264
Thinking about food out since you were a kid

593
00:24:43,776 --> 00:24:45,312
But you wish were real

594
00:24:46,080 --> 00:24:47,360
But isn't

595
00:24:48,128 --> 00:24:52,224
Well so that's that's a fun one you know being a language person

596
00:24:52,480 --> 00:24:54,528
The thing that end in one that worked on

597
00:24:55,296 --> 00:24:55,808
Translation

598
00:24:56,320 --> 00:24:57,088
Many years

599
00:24:57,856 --> 00:24:59,392
For years we've been

600
00:24:59,648 --> 00:25:00,672
Striving towards

601
00:25:01,696 --> 00:25:02,720
This kind of Babelfish

602
00:25:03,232 --> 00:25:03,744
Kind of

603
00:25:04,256 --> 00:25:10,400
Capability do you know what I mean though I never read the books by

604
00:25:10,656 --> 00:25:13,472
Douglas Adams Hitchhiker's Guide to the Galaxy

605
00:25:13,984 --> 00:25:19,360
You know it in the various Interstellar spaces right everybody speaks a different language

606
00:25:19,872 --> 00:25:21,920
So the solution to this is the Babel Fish

607
00:25:22,432 --> 00:25:26,528
It's the the fish that you put in your ear and then suddenly eat you can hear in your own language

608
00:25:27,040 --> 00:25:30,368
You know the translation the perfect translation of

609
00:25:30,624 --> 00:25:33,952
Do all of these alien species University translate Universal trans

610
00:25:34,208 --> 00:25:35,488
Play it right is it the exact

611
00:25:35,744 --> 00:25:36,256
Tweet from Star Trek

612
00:25:37,280 --> 00:25:38,816
Well you know this

613
00:25:39,072 --> 00:25:44,960
What's really fascinating is last couple years because of the work that's going on in deep neural networks and

614
00:25:45,216 --> 00:25:47,264
The cool work has been going on

615
00:25:47,776 --> 00:25:49,568
Bo Sinn DARPA funded research

616
00:25:49,824 --> 00:25:50,848
End end

617
00:25:51,104 --> 00:25:52,128
And commercially funded work

618
00:25:52,640 --> 00:25:54,176
We're really getting close to

619
00:25:54,688 --> 00:25:57,504
So there was this paper last year by Google

620
00:25:57,760 --> 00:26:01,600
The described the use of multiple languages

621
00:26:02,112 --> 00:26:05,440
How to do translation translating for multiple languages into a language

622
00:26:05,952 --> 00:26:09,024
I am in training those translators from various different

623
00:26:09,280 --> 00:26:09,792
Forms

624
00:26:10,048 --> 00:26:12,352
And what they discovered is that these neural networks

625
00:26:12,608 --> 00:26:14,144
Learn kind of a universal

626
00:26:14,656 --> 00:26:16,960
Semantic representation of language

627
00:26:17,472 --> 00:26:18,496
As part of

628
00:26:19,008 --> 00:26:20,544
The process of training this emergent

629
00:26:20,800 --> 00:26:22,336
It's an emergent property of

630
00:26:22,848 --> 00:26:24,384
How these neural networks were built

631
00:26:25,152 --> 00:26:31,040
And so what it leads to in long-run is potentially actually having a universal trans

632
00:26:32,064 --> 00:26:33,600
And that is going to be a really

633
00:26:34,624 --> 00:26:36,928
It just give it a shot so if we were to give listeners

634
00:26:37,440 --> 00:26:38,464
What you mean by neural net

635
00:26:39,488 --> 00:26:45,632
Yeah so so we use the term neural network it actually has very little.

636
00:26:45,888 --> 00:26:48,448
Do with neurons as in the cells in your brain

637
00:26:48,704 --> 00:26:50,752
But these are models of

638
00:26:51,008 --> 00:26:52,288
How your neurons work

639
00:26:52,800 --> 00:26:56,128
Start a very primitive models of how your neurons in your brain work

640
00:26:56,640 --> 00:27:00,480
That are composed together to form little small brain like you

641
00:27:01,248 --> 00:27:06,112
And what the Google guys did was they figured out how to build a neural network

642
00:27:06,368 --> 00:27:07,392
That could take information

643
00:27:07,648 --> 00:27:08,672
Drupal multiple languages

644
00:27:09,184 --> 00:27:10,208
Ian

645
00:27:10,464 --> 00:27:11,744
Essentially regular eyes

646
00:27:12,000 --> 00:27:13,536
Into a form

647
00:27:13,792 --> 00:27:16,352
That would allow it to translate in English

648
00:27:16,864 --> 00:27:18,656
And that intermediate form

649
00:27:18,912 --> 00:27:19,424
Which is

650
00:27:19,936 --> 00:27:23,008
Somewhere in the middle of this rather large neural network

651
00:27:23,520 --> 00:27:26,592
You know happens to have properties that looked

652
00:27:26,848 --> 00:27:28,128
The same across multiple language

653
00:27:28,384 --> 00:27:31,200
Is meeting that it's a fact effectively like the shared

654
00:27:31,456 --> 00:27:32,224
Semantics

655
00:27:32,736 --> 00:27:33,248
Different language

656
00:27:34,016 --> 00:27:34,528
Yeah

657
00:27:34,784 --> 00:27:35,296
Fascinating

658
00:27:35,808 --> 00:27:36,576
Well I think so

659
00:27:36,832 --> 00:27:38,112
Sharon that sounds like

660
00:27:40,160 --> 00:27:41,440
Dykema fictional universe

661
00:27:41,952 --> 00:27:43,232
Translator to something that we might

662
00:27:43,488 --> 00:27:44,768
Actually all of us be able to use

663
00:27:45,024 --> 00:27:50,656
Hope all is well with all 7.4 billion of us on the planet might be able to talk to one another that's right in the thousands of languages that we speak

664
00:27:51,424 --> 00:27:53,728
So wait we have covered a lot of

665
00:27:53,984 --> 00:27:57,568
Fascinating ground here and I just want to thank you

666
00:27:57,824 --> 00:27:58,336
For this

667
00:27:59,360 --> 00:28:00,128
Teaching conversation

668
00:28:00,384 --> 00:28:01,152
Well thank you Ivan

669
00:28:01,664 --> 00:28:02,176
Straight talk any

670
00:28:02,688 --> 00:28:04,736
And thanks listeners for sharing this time with us

671
00:28:05,504 --> 00:28:07,296
I hope you join us again for the next

672
00:28:07,808 --> 00:28:08,832
Voices from DARPA

673
00:28:12,928 --> 00:28:14,208
For more information that way.

674
00:28:14,464 --> 00:28:16,000
His program than the other brake

675
00:28:16,512 --> 00:28:17,792
Technologies DARPA is working on

676
00:28:18,304 --> 00:28:19,584
Visit DARPA. Mil

677
00:28:23,168 --> 00:28:25,216
And four links that enable you to download this

678
00:28:25,728 --> 00:28:28,800
Podcast go to the Voices from DARPA page on Darkness
