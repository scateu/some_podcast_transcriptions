1
00:00:11,780 --> 00:00:13,760
Stuff technology , the internet. 

2
00:00:13,880 --> 00:00:16,841
GPS in the palm of your hand are tonight . 

3
00:00:16,841 --> 00:00:30,850
Operation technology is a driver of our times since its founding a nineteen fifty eight , in the midst of the cold war , the defense advanced research projects agency has been a driver of technology . 

4
00:00:31,170 --> 00:00:42,710
Welcome to a Voices from dark , a window on the dark as core of program managers , their job to redefine what is my name is iphone motto , one of your dark host today . 

5
00:00:42,710 --> 00:00:47,650
I am pleased to be talking with doctor matter , a program manager since twenty eighteen . 

6
00:00:47,650 --> 00:00:58,656
And the agencies , information innovation office , we are recording our conversation from our respective homes as we do our part to slow the spread of copyright nine team , because we are not in recording studio . 

7
00:00:58,656 --> 00:01:01,230
You might be your ambient sounds like trucks and birds . 

8
00:01:01,230 --> 00:01:08,410
And today , even secretaries , microwaves to doubt his long time interest in computer vision , machine learning , artificial intelligence . 

9
00:01:08,410 --> 00:01:17,791
In many ways , this can be applied in society , important ways , ranging from media limited to industrial inspection to intelligence gathering for national security . 

10
00:01:17,791 --> 00:01:31,720
After collecting bachelor's and masters degrees and electrical engineering met on the PHTin computer science , from one sillier politician institute in chronic york along his professional pathway , met partner with colleagues to secure fourteen . 

11
00:01:31,720 --> 00:01:39,071
All of the necessary was making machines better able to see the world and to help people see more with the assistance of machines matter . 

12
00:01:39,071 --> 00:01:41,780
Thanks for joining me for a conversation tonight . 

13
00:01:41,780 --> 00:01:56,090
Hi , it's great to be here when I look at your portfolio programs that they dive deeply into some of the most challenging issues underlying both the promise in the parallel of artificial intelligence as it becomes more president of our lives . 

14
00:01:56,220 --> 00:02:12,170
But before we talk about those programs , i'd like here about some of the info convinces in your life that account for your educational choices of electrical engineering and computer science , and but that also might help explain your deep interest in computer vision and artificial intelligence. 

15
00:02:13,350 --> 00:02:23,470
I grew up as the child of two teachers actually , so my father was a university professor , and my mother was a high school teacher . 

16
00:02:23,470 --> 00:02:38,230
And there were a lot of science teachers , so I sort of naturally grew up with having that scientific respective , I guess in green than me , and I think along the way , i've just been lucky to work with some really interesting and compelling people . 

17
00:02:38,410 --> 00:02:51,180
So one of my first jobs I caught at general electric power systems and connected in new york , and was lucky enough to share an office with a researcher from the GE research . 

18
00:02:51,410 --> 00:02:56,100
And he took me over one day to see what the je research center was all about . 

19
00:02:56,180 --> 00:03:07,660
And I got to see a tour of the graphics and the computer visualization platform , which was very cool , particularly to someone who is in a technical major in collection . 

20
00:03:08,160 --> 00:03:17,610
And that was , I guess , my first introduction , technical areas involving things like computer graphic and computer vision and machine learning . 

21
00:03:18,230 --> 00:03:22,960
And that , really , it thinks , started to shape the trajectory of my career . 

22
00:03:23,110 --> 00:03:29,800
I was lucky enough years later to actually end up working in that same group at GEglobal research at the time . 

23
00:03:30,370 --> 00:03:32,100
That was really foundation for me . 

24
00:03:32,100 --> 00:03:47,620
I had the opportunity to work with some world class researchers in computer vision and graphics , and it gonna sort of set relatively early in my career and interesting and compelling trajectory , at least to me. 

25
00:03:47,950 --> 00:03:49,030
Thanks for sharing that . 

26
00:03:49,030 --> 00:04:00,780
I just always find a fascinating here about , you know , that one of those several transformative experiences that they often have some chance elements to them , but then they kind of , you know , said , you are on a , on a trajectory they can , that's for a lifetime . 

27
00:04:00,780 --> 00:04:02,270
So it's kind of very cool to hear that . 

28
00:04:02,860 --> 00:04:15,820
So one more thing before you talk about your programs , the threat of last decade find out that you work with teams on the research contracts for a number of programs they had to do with things like ultimated , object and threat recognition . 

29
00:04:15,820 --> 00:04:19,320
But I always like to hear that how I got to dark a story . 

30
00:04:19,440 --> 00:04:20,560
How did that actually happen? 

31
00:04:21,080 --> 00:04:34,616
So after I finished up my PHDApencil , I worked for about ten years at a open source software company kicked well , which is a small business located in the upstairs new york . 

32
00:04:34,616 --> 00:04:37,153
And they did a lot of work on the us . 

33
00:04:37,153 --> 00:04:41,720
Government programs for research lab , for dark for iowa and others . 

34
00:04:41,980 --> 00:04:50,030
And so that got me interested in the the problem , space , the source of problems that an organization like dark addresses . 

35
00:04:50,670 --> 00:05:07,470
And eventually I got to the point where I was interested in becoming a diaper program danger , and generally the process for that is , you know , either working off a contact you have with an existing program manager at darby , which is sort of how I got in the door . 

36
00:05:07,470 --> 00:05:20,020
I started talking with david domain , who was the program manager for me for the media , foreign explorer , and he was looking for someone to take over the program , and he was leaving , and he knew that I was interested in . 

37
00:05:20,160 --> 00:05:23,110
I had the computer vision background to be able to do it . 

38
00:05:23,520 --> 00:05:29,120
And so that sort of kick started the process for me for coming to double. 

39
00:05:29,820 --> 00:05:34,290
That's actually great invitation to separate into talking about your programs . 

40
00:05:34,290 --> 00:05:36,400
You're portfolio , you know , to me . 

41
00:05:36,400 --> 00:05:37,290
Can it could not be more . 

42
00:05:37,340 --> 00:05:49,870
Fortunately , one of the most precious commodities we can have as a society trust in media and other channels , and most communication seems to be evaporating so that two of your programs can desire on that . 

43
00:05:49,900 --> 00:05:53,730
Another program of yours gets a different kind of crucial trust . 

44
00:05:53,730 --> 00:06:01,604
This one human trust in AItools that are becoming embedded and influential , all of our everyday lives . 

45
00:06:01,604 --> 00:06:11,836
And and yet one more of your programs are hoping to catalyze research talent out there to build the all two human component of human intelligence into artificial intelligence . 

46
00:06:11,836 --> 00:06:13,974
And i'm talking here about common sense . 

47
00:06:13,974 --> 00:06:17,243
So let's start with media forensics or media . 

48
00:06:17,243 --> 00:06:30,450
Foreigners are same for the two programs I mentioned that addressed your wedding trust in the media and communication that you actually mention one of these as your entry into dark as program management . 

49
00:06:30,450 --> 00:06:31,520
So what thought about those two? 

50
00:06:32,040 --> 00:06:40,428
The media , francisco programmer metaphor kicked off in twenty sixteen in the summer , and is now starting to wrap up . 

51
00:06:40,428 --> 00:07:17,395
And the goal of that program is to build automated algorithms and automated tools that can look at an image or video and determine whether it's been manipulated or not so manipulated , in this case , might refer two things like being altered with photoshop , or it might refer to two techniques like generative administrator networks or guns that can generate a very realistic looking image of a human face or of a scene and do that with a centrally , no human input at so that's a large , dark research programs . 

52
00:07:17,395 --> 00:07:25,101
So typical of many darker researchers , programs were pulling on both the academic and industrial research community . 

53
00:07:25,101 --> 00:07:42,660
And we dark I have put in significant investment and the media francisco area over that four year period of the program , when the programme started in twenty sixteen , things like deep fakes and the word deep fakes didn't actually exist . 

54
00:07:42,750 --> 00:07:45,360
So certainly there was photoshop . 

55
00:07:45,710 --> 00:07:49,700
There was gamp , which is an open source image manipulation to . 

56
00:07:50,590 --> 00:08:07,560
But what's really changed in the last few years as a sort of the rise of these more automated manipulation capabilities that require what was scale and what was computer power to create a potentially compelling and manipulation . 

57
00:08:07,560 --> 00:08:18,090
And so one of the goals for the metaphor program is to try and raise the bar backup , make it harder , or for now , necessary to create those sorts of compelling media manipulation. 

58
00:08:18,950 --> 00:08:30,640
Right now , without going to do , can you give it just a sensor tool of the type specific features that you're looking for some in a media file that would be a type? 

59
00:08:31,580 --> 00:08:41,920
The media francisco program has framed the problem of assessing the integrity of a visual outset , so an image of video in a really interesting way . 

60
00:08:42,240 --> 00:08:50,360
So we look at three levels of information in order to determine whether a visual media outset has integrity . 

61
00:08:50,660 --> 00:08:52,910
So first we look at digital integrity . 

62
00:08:52,910 --> 00:08:59,930
So essentially , that's looking at low level information might be statistics in the pixel . 

63
00:09:00,030 --> 00:09:07,070
It might be meditated that comes along with a image or a video file , and look for inconsistencies and notes . 

64
00:09:07,530 --> 00:09:17,973
And it turns out that those approaches work really well for detecting some of the latest and greatest manipulation generation techniques like generative adversarial networks are guns . 

65
00:09:17,973 --> 00:09:22,563
But there are also fragile to an adversary who has skills innovating detections . 

66
00:09:22,563 --> 00:09:27,570
So there are things that you can do to try and hide those statistical fingerprints . 

67
00:09:27,650 --> 00:09:30,863
So we also look at other levels of information . 

68
00:09:30,863 --> 00:09:48,680
So we look at physical integrity and synthetic integrity so physically integrated in this context looks for a clues that the laws of physics may have been violated , so that sounds complicated , but it really simplifies the things like are lighting and shadows consistent . 

69
00:09:48,830 --> 00:10:00,880
So , for instance , if you have a number of faces in the scene is the lighting on all those faces consistent or consistent with the lighting sources that we know about in the scene , or is the geometry have an image . 

70
00:10:00,880 --> 00:10:09,650
So when you take an image of a three day scene of a three day real world with a camera that imposes a certain geometry on the scene . 

71
00:10:09,650 --> 00:10:12,270
So , for instance , parallel lines tend to . 

72
00:10:12,530 --> 00:10:21,140
And so those are the type of clothes that we can look at to see if , essentially the physics around the image acquisition process are correct or not . 

73
00:10:21,140 --> 00:10:26,639
So that's physical integrity , and unfortunately , integrity in the context of the media . 

74
00:10:26,639 --> 00:10:36,340
Francisco program , that's where we look to bring other information that we know is true to bear and characterising the integrity of a media outset . 

75
00:10:36,340 --> 00:10:49,750
So , for instance , if you have an image that was taken outside , and it comes with a time stamp in a jail position , you can look at the SUN angle on the shadows and see if those are consistent or inconsistent . 

76
00:10:49,750 --> 00:10:55,097
And so we actually built techniques that can look at those sorts of property . 

77
00:10:55,097 --> 00:11:08,010
So for instance , the weather is another property that if you have an outdoor for image or video and allocation in time that you can assess and see whether that's correct or not , whether it's been manipulated. 

78
00:11:08,650 --> 00:11:19,800
I want a drilling just one level deeper there , and then move on to synthetic forensics , because I could talk to you about an hour of you to one of these , what called me just then was the idea that there might be some meditators . 

79
00:11:19,800 --> 00:11:25,860
They had time stamped on an image and a funeral that was that you could have some idea of the angle of the sound would be . 

80
00:11:25,860 --> 00:11:40,600
And then you could look for shadows , other features to see if that's consistent in order to actually do that , then work , do these tools and have to go out and into the world and gather the appropriate data sets in order to make those kinds of assessments. 

81
00:11:40,860 --> 00:11:49,450
Well , so for things like some angle and shadows that information can be sort of computed around hindle the location of the time of day . 

82
00:11:49,450 --> 00:11:59,120
And you can compute songs , or from that , perhaps more interestingly , for things like whether you can go and look that information up in an online database . 

83
00:11:59,200 --> 00:12:14,670
So for instance , do you know where , and when a photo was taken , you can go to a historical weather database , looked at information up and compared with what you see in image now , a human can do that relatively easily . 

84
00:12:14,670 --> 00:12:37,710
We actually have a university , team , university , maryland , that built a deep neural network to automatically look at outdoor image and estimate things like the amount of cloud cover the temperature , those sorts of features that you might compared to the online weather database , so that automates the analysis piece when you are looking at an image. 

85
00:12:38,600 --> 00:12:49,880
Not just as we were talking about metaphor , you did begin to bring in the synthetic category for assessing weather and image , whether a kind of media file has integrity in . 

86
00:12:50,070 --> 00:12:52,710
But that is the whole program called domestic efforts . 

87
00:12:52,710 --> 00:12:53,460
So tell us. 

88
00:12:54,450 --> 00:13:02,694
Sure , so that domestic francisco program is , as you already to went to the media forensics program . 

89
00:13:02,694 --> 00:13:07,543
So here were using the term semantic a little bit differently . 

90
00:13:07,543 --> 00:13:14,010
One of the primary focuses of the subsequent program is really to build the fundamental . 

91
00:13:14,040 --> 00:13:26,877
This is against what we think is coming , and so we think that multi model assets , so things like a news story that have invited photos and video , and the video may have audio . 

92
00:13:26,877 --> 00:13:33,640
We think that some point in the future , there will be the ability to generate that from whole class . 

93
00:13:33,640 --> 00:13:44,830
So what we've focused on from a defensive standpoint is the fact that it is very difficult for those sorts of techniques that are generating maliciously falsified media . 

94
00:13:44,830 --> 00:13:48,700
It is very difficult for them to get all the semantics correct . 

95
00:13:48,830 --> 00:13:58,300
So in this case , it means things like , you know , consistency across what's in the text , or what's in the images or consistency within the image itself . 

96
00:13:58,300 --> 00:14:07,360
So for the proposal thursday for that program , we highlighted some examples of failure mode for typical generation albertas now. 

97
00:14:07,360 --> 00:14:10,547
And let me just introduct there for listening to , don't know . 

98
00:14:10,547 --> 00:14:19,226
So in , in a life cycle of a program , once kind of an announcement of the program comes out , the programmed others invite those who think they might want to get involved . 

99
00:14:19,226 --> 00:14:27,000
That is to say the proposals to come and share their ideas how they might go about solving a problem with stated in the programs kind of particulates . 

100
00:14:27,000 --> 00:14:28,926
And that's called the proposals day . 

101
00:14:28,926 --> 00:14:29,890
Okay , so mad , continue. 

102
00:14:30,490 --> 00:14:41,590
So at the proposal day , we highlighted a couple examples of where current techniques for generating media , for creating synthetic media break down . 

103
00:14:41,680 --> 00:14:50,797
So there was an example of one of these synthetically generated faces of a woman , and our inconsistencies in the earrings that she is wearing . 

104
00:14:50,797 --> 00:14:54,299
Now that's possible in the real world , but it's unlikely . 

105
00:14:54,299 --> 00:15:06,150
And so that sort of as a specialist clue in a perhaps more complex telling example , we showed fully synthetic LBNBad where they were just closed in the text that something was wrong . 

106
00:15:06,150 --> 00:15:16,050
And these are clues that are relatively obvious to human , but are difficult still for AItechniques to get right on the generation inside and also to detect . 

107
00:15:16,050 --> 00:15:32,140
So with things like the LBNBhad twenty four seven carpeting , and all that are freezed that we would never use twenty four , seven and ten and carpeting really together as humans , and looking at that , add as humans , we find them humorous because of those semantic inconsistencies . 

108
00:15:32,570 --> 00:15:37,450
And so that became some of the inspiration for the domestic forensic program . 

109
00:15:37,820 --> 00:15:53,140
Well , we're really looking to exploit those sorts of inconsistencies in the media generation process , and it also ties to one of the another part of my portfolio , which perhaps will talk about later , is common sense . 

110
00:15:53,320 --> 00:16:00,860
So some of those aspects , like twenty four seven carpeting will add just violates common sense of reasoning . 

111
00:16:01,110 --> 00:16:22,120
And so you know , there is another opportunity to really communicate from a semantic understanding of the content of the media , and look for those are inconsistencies and on the program , we're in particularly going to try and walk across combinations of different model is like text and images or video and text. 

112
00:16:22,880 --> 00:16:28,360
Okay , actually , we will move to the common sense program in just a minute makes sense to move to that . 

113
00:16:28,540 --> 00:16:41,930
But what would be cool if you could just as rifle , as you can take a threw a sequences of what , say , an image , video or some kind of model media product is put out there . 

114
00:16:41,930 --> 00:16:47,890
How would that then go through some kind of analytic packages like the emerges from the domestic friends explosion? 

115
00:16:48,380 --> 00:16:54,110
Imagine a hypothetical news article , and maybe that news article is on a web page . 

116
00:16:54,110 --> 00:16:55,910
It's got embedded images . 

117
00:16:55,910 --> 00:16:58,720
It's got video with a social IDL. 

118
00:16:59,800 --> 00:17:09,810
And maybe the news article talks about a protest on social security , and it places at a particular location near the UScapital as an example . 

119
00:17:10,460 --> 00:17:27,590
So you can imagine the types of of capabilities that will develop on automatic francisco program might be able to automatically go and analyze the text and images in the , on the audio for semantic inconsistencies . 

120
00:17:27,800 --> 00:17:36,609
So , for instance , the text might say that the protesters located near the UScapital , but in the images , it doesn't show the UScapital . 

121
00:17:36,609 --> 00:17:42,213
It doesn show any of the buildings that are near the us capitals , so that seems inconsistent . 

122
00:17:42,213 --> 00:17:50,270
Maybe the text talks about the mood of the crowds , so , for instance , may be characterizes them as a violent and a large crowd . 

123
00:17:50,640 --> 00:17:59,500
And you can look at the , at the images in the article and characteristics like the behavior in the video that might be associated with it . 

124
00:17:59,620 --> 00:18:12,300
So like a violent crowd , those sorts of activities might be easily differentiated from a peaceful protest , or the topic that the news article calls out something like social security . 

125
00:18:12,590 --> 00:18:19,410
Maybe there is no evidence in the image of video that the people that are shanna actually protesting social security . 

126
00:18:19,880 --> 00:18:30,960
So those are the source of inconsistencies that we might work at on the synthetic program and develop automated algorithms to carry out that sort of assessment. 

127
00:18:31,360 --> 00:18:43,406
Okay , so now before we move to your machine , common sense program , which you mention yourself just before just wanted other questions about these tools in a four identifying defects and processing the integrity of our media . 

128
00:18:43,406 --> 00:18:45,576
It is the question here of time , right ? 

129
00:18:45,576 --> 00:19:02,754
And I remember in a term in the past , I don't have a steel car , but the sort of the CNN , the fact that it is a society that if news gets out , kind of an innovation in a real time way , but it's fake , and it leads the various actions , you know , on the governments , right , the correction is too late . 

130
00:19:02,754 --> 00:19:10,170
Someone's always too late , because you can't undo actions that are taken unbelief of something that was unforced and presented . 

131
00:19:10,330 --> 00:19:19,280
So are you also trying to design these tools , both in metaphor and samsung forever to work fast enough so that actually. 

132
00:19:19,590 --> 00:19:26,400
Yeah , that's a great question about the speed which you need the coroners , something like a disinformation attack . 

133
00:19:26,510 --> 00:19:35,610
So the focus of the tools that were building is really to enable doing things like filtering and prioritizing of media at scale at scale . 

134
00:19:35,980 --> 00:19:46,220
So ultimately , the output from these tools may still need human review , but it's not possible to scale up human review to the size of the internet . 

135
00:19:46,390 --> 00:19:55,370
If you think about the volume of media , foreign students , that's going through an internet platform , or even that you get exposed to as an individual every day . 

136
00:19:55,770 --> 00:20:01,111
So it's really important that we have automated tools that can help us assist with prioritization . 

137
00:20:01,111 --> 00:20:04,002
I often compared that to spain filtering . 

138
00:20:04,002 --> 00:20:11,341
So , for instance , you could do spam filtering yourself , but most of us find it very helpful to have automated spam photos . 

139
00:20:11,341 --> 00:20:15,500
Essentially , that's a process for private advertising your emails . 

140
00:20:15,610 --> 00:20:23,220
It's deprive , advising the spanish and trying to leave you with the core communication that you want to receive . 

141
00:20:23,430 --> 00:20:25,180
That's part of the answer . 

142
00:20:25,380 --> 00:20:40,420
Another party , the answer is that even though I think technical tools are required , they're not a silver bullet , so there's other things that we need to look forward to sort of spread of missing this information . 

143
00:20:40,710 --> 00:20:47,350
And some of those start to get into how we communicate that an image of video has been manipulated . 

144
00:20:47,630 --> 00:20:54,450
So , for instance , just presenting that to a user might not be convincing , there are ways essentially to do that . 

145
00:20:54,450 --> 00:21:03,924
That might be more engaging to a user to get them to look at the media that the same they're seeing , that they're interesting a little bit more carefully . 

146
00:21:03,924 --> 00:21:16,674
So those are things that are actually outside the scope of what we're media , friendships and unauthentic friendship program , but they're actually really important piece of the overall societal picture . 

147
00:21:16,674 --> 00:21:27,207
Certainly , the automated tools will help with addressing the speed issue that you raised and being able to attribute prioritize media , yeah , at scale , and do it quickly . 

148
00:21:27,207 --> 00:21:34,150
But even with those technologies , there's going to be other pieces that were going to need to have a comprehensive solution. 

149
00:21:34,150 --> 00:21:45,500
I was just imagining that these tools working at the speed of the internet , and what might come through image might come on a tweet , for example , but it might say this is what gone down through some kind of integrity tool . 

150
00:21:45,500 --> 00:21:48,960
And there are some education it may have been manipulated . 

151
00:21:48,960 --> 00:21:56,900
I'm destroying that it could be some kind of little warning of that sort that would go along with potentially manipulated media files. 

152
00:21:57,100 --> 00:22:12,606
That may be possible someday , and perhaps even presenting some additional context to whom ever is consuming the media that , you know , here are some of the inconsistencies in the snooze story , or in this video club for other elements . 

153
00:22:12,606 --> 00:22:22,870
And so being able to provide that context to an end user could be really important for sort of slowing the consumption and spread of the same information. 

154
00:22:22,870 --> 00:22:25,754
Coastal really happy working on these programs . 

155
00:22:25,754 --> 00:22:31,935
I'm not so happy when I think about how often they're probably going to be applicable in the future . 

156
00:22:31,935 --> 00:22:35,025
So let's now move to your machine , common sense program . 

157
00:22:35,025 --> 00:22:36,880
I find this one equally fascinating . 

158
00:22:36,890 --> 00:22:54,340
I think somewhere I found you described this program as driven by the fact that there's an absence of what we , michael artificial , common sense in our AI is critical , significant barrier between the narrowly focus applications we were today in the mood , general human , like AIsystems . 

159
00:22:54,340 --> 00:22:56,300
We would like to build in the future . 

160
00:22:56,300 --> 00:22:59,930
So talk me about that the dark machine come on. 

161
00:23:00,000 --> 00:23:10,480
Program is focused on trying to create new techniques to build essentially common sense , knowledge and reasoning into artificial intelligence . 

162
00:23:10,720 --> 00:23:19,480
As you mentioned , one of the challenges with sort of state of the artificial intelligence or machine learning , is that it tends to be very narrow . 

163
00:23:19,480 --> 00:23:24,500
So it's focused on a particular task , and it doesn't generalized very well . 

164
00:23:24,500 --> 00:23:34,380
So generalize means moving to another task that similar , but maybe uses a different type of data or has a slightly different problem formulation . 

165
00:23:34,560 --> 00:23:39,106
So current AIin machine learning tends to be very brittle . 

166
00:23:39,106 --> 00:24:03,030
And that way that it doesn't generalize , well , and so in a one of the motivations behind the common sense program is to try and build those brought are based repositories of knowledge , and then reasoning techniques are allowed to handle new situations to adapt to a different problem formation to a different problem . 

167
00:24:03,030 --> 00:24:03,480
domain . 

168
00:24:04,060 --> 00:24:09,760
Do that adaptation and ways that are similar to how humans do that . 

169
00:24:09,830 --> 00:24:13,450
So right now , humans are much better at generalizing across . 

170
00:24:13,650 --> 00:24:18,150
Problem remains on taking a new tasks and adapting them . 

171
00:24:18,420 --> 00:24:22,960
Humans are much better at that than current artificial intelligence in machine learning. 

172
00:24:23,580 --> 00:24:30,160
Gave me one handle that you're going after or hanging on to try to bring that common sense into an AI context. 

173
00:24:30,190 --> 00:24:40,030
So in order to build common sense into artificial intelligence , we're looking at sort of two general approaches on the program . 

174
00:24:40,410 --> 00:24:47,690
So roughly half the program is trying to build the common sense that inspired by infants . 

175
00:24:48,010 --> 00:24:54,550
So children age zero to eighteen months are probably some of the best learners in the world . 

176
00:24:54,550 --> 00:25:03,083
In fact , in some ways , they learn better than adults they explore , and in some ways , to take more risks than adults . 

177
00:25:03,083 --> 00:25:26,350
So we have researchers on the program boat from artificial intelligence and from child developmental psychology that are working together to try and build new artificial intelligence algorithms that have some of those properties of infants , so that they have a better , more general understanding of objects . 

178
00:25:26,350 --> 00:25:33,330
Agency , places is those elements of artificial intelligence or those elements that are needed. 

179
00:25:33,370 --> 00:25:34,240
Hey , I reasoning . 

180
00:25:34,540 --> 00:25:44,255
So I just love this because the metric of success you are then in your machine , common sense programmers , if you can get an AI to think and learn like a baby , you have just known it . 

181
00:25:44,255 --> 00:25:45,450
Yes , and actually the. 

182
00:25:45,480 --> 00:25:57,880
Trucks are based on child development milestones , the source of skills that they acquire around the objects , agents , places , social beings , how humans interact with each other . 

183
00:25:58,150 --> 00:26:12,720
So we actually drown inspiration and goals from the child developmental psychology , literature , and settles down as benchmarks that were going to try and assess ourselves for part of the machine , common science program. 

184
00:26:12,970 --> 00:26:16,300
Okay , and then I deflected you when you are better going to the second big component. 

185
00:26:16,360 --> 00:26:34,060
So the other half of the machine common sense program , it's really looking to build large arab positions of common sense knowledge and to build common sense reasoning capabilities to go along with build those from large knowledge bases . 

186
00:26:34,060 --> 00:26:44,744
So , for instance , using internet resources like we compete in our other large curator data sets and use those to build what we call large knowledge graphs . 

187
00:26:44,744 --> 00:26:54,280
So those might be facts about a particular object in how it relates to other things in the world to try and build those at scale . 

188
00:26:54,720 --> 00:27:17,500
And so that approach has been explored some over the history of , yeah , but now , with approaches like deep learning and convolution of narrow networks and betting spaces were taking sort of a new , a new slide on that approach to see if we can build large scale of positives of common sense knowledge. 

189
00:27:17,500 --> 00:27:19,195
Absolutely fascinating . 

190
00:27:19,195 --> 00:27:19,679
Okay map . 

191
00:27:19,679 --> 00:27:21,858
We've talked about metaphor . 

192
00:27:21,858 --> 00:27:24,037
We have talked about some of four . 

193
00:27:24,037 --> 00:27:26,700
We've about machine , common sense . 

194
00:27:26,740 --> 00:27:32,470
Now let's talk about your fourth program , and lesson will talk about here , which is explainable . 

195
00:27:32,470 --> 00:27:35,980
Artificial intelligence , XAIand short . 

196
00:27:36,440 --> 00:27:44,680
This one also really fascinates me , because , you know , for many of us who might not be so control technology , we were surrounded by black boxes . 

197
00:27:45,050 --> 00:27:48,320
Our computers are found everything that we love the way they work . 

198
00:27:48,320 --> 00:27:54,421
We don't really understand what's going on and out of them , and that's what that happening now is A, I, you know , comes into our lives . 

199
00:27:54,421 --> 00:27:56,274
So you know , this sounds fascinating . 

200
00:27:56,274 --> 00:27:57,386
The media I did that . 

201
00:27:57,386 --> 00:28:05,250
Maybe we can get the air to explain themselves to in ways we understand , tell me about the program and why that is important to dark into you. 

202
00:28:05,380 --> 00:28:14,010
The explainable AI or explainable artificial intelligence program is focused on opening up some of those black boxes that you mentioned . 

203
00:28:14,240 --> 00:28:27,020
So a lot of the state they are approaches to machine learning , for instance , relies on techniques that are really just a pig too , not just the end users , but i'll pick to the developers . 

204
00:28:27,180 --> 00:28:49,780
They represent knowledge and information in ways that are just not easy to the bug , so that explainable eye program is focused on building more explainable machine learning models , building new training processes that might lead to better explainable models , and importantly , to building explanation interfaces . 

205
00:28:49,780 --> 00:28:59,350
So a way to provide that explanation from a machine learning model to a human , so certainly opening up that black box is important . 

206
00:28:59,350 --> 00:29:02,964
You know , that machine learning black box is important . 

207
00:29:02,964 --> 00:29:18,710
We've seen that crop up on a number of areas around foreign standards and AImachine learning , but just as important as opening that black , it's been able to provide an explanation that is meaningful and useful to humans . 

208
00:29:18,710 --> 00:29:30,040
And so that explanation interface part is particularly key , and it's really challenging because it draws on research or needs to draw on research from multiple domains . 

209
00:29:30,040 --> 00:29:36,410
It's not just artificial intelligence , researchers or computer scientists contribute to that problem . 

210
00:29:36,860 --> 00:29:46,660
It also focus like experimental psychologists so that you can understand the utility that an explanation has for an end . 

211
00:29:47,000 --> 00:30:06,639
And so I think one of the places where darker is really unique and could apply very much here in that XAIspace is the ability to form these cross disciplinary research teams to try and to encourage the research community to work together in ways that either isn't currently happening . 

212
00:30:06,639 --> 00:30:09,721
Or maybe they didn't even invasion happening . 

213
00:30:09,721 --> 00:30:30,250
I think one really nice aspects of XAIas the program is trying to get more of that cross disciplinary research going across computer scientists and AIresearchers , and and folks that have a more user central perspective , like experimental psychologists or folks working in human. 

214
00:30:30,280 --> 00:30:35,176
Factors , the word trust keeps coming to mind when I think explainable AI . 

215
00:30:35,176 --> 00:30:48,790
And I think the issue of do we trust these AI systems that coming to our lives , and it was being hugely important and potentially , in a deal breaks for the weather , people end up accepting them and adopting them in the future. 

216
00:30:49,180 --> 00:31:01,880
Yeah , I mean developing AI systems that humans can trust and contrast appropriately , and it is really critical to getting the trajectory along which AIand getting that trajectory correct . 

217
00:31:02,160 --> 00:31:08,150
We're starting to automate with AIand machine learning decision making processes . 

218
00:31:08,150 --> 00:31:11,390
So this is just the department of defense , right ? 

219
00:31:11,390 --> 00:31:25,270
This is happening across society , and we're starting to realize what some of the challenges and what some of the implications are for allowing that automation to be embedded in our decision . 

220
00:31:25,640 --> 00:31:37,870
And so being able to explain decisions , provide transparency into them , provide an explanation to the user in a way that they can consume it easily that actually makes the task easier . 

221
00:31:37,870 --> 00:31:44,290
That provides more right into what say , the recommendation of a system that's really critical . 

222
00:31:44,290 --> 00:31:48,280
Obviously , it's really important for the department of defence . 

223
00:31:48,280 --> 00:32:05,831
We may get to a point in time where machine learning , artificial intelligence , albert storms are more tightly integrated into the decision making process for the do d and the source of decisions that those systems might make are probably going to be mission critical decisions . 

224
00:32:05,831 --> 00:32:20,290
There may be lives on the line , and so it is really important that we put some foundations in place in the AI community in order to build in this transparency and trustworthiness in AI systems. 

225
00:32:20,560 --> 00:32:21,980
Okay , well , thanks for sharing . 

226
00:32:21,980 --> 00:32:22,780
All of that . 

227
00:32:22,780 --> 00:32:24,420
We are getting towards the end here . 

228
00:32:24,420 --> 00:32:46,793
So I just wanna make sure that I ask question , that mind , really odd , that is , you might imagine taking your programs through is your imagining your colleagues who also have other AI programs moving their programs through emergency five hundred years from what excites you about kind of the AI coming into our lives more and more . 

229
00:32:46,793 --> 00:32:48,910
And what if you think of? 

230
00:32:49,300 --> 00:32:52,210
Yeah , I guess i'll focus on the post part . 

231
00:32:52,410 --> 00:33:02,335
So again , I think being able to establish that trust in AIsystem is going forward is going to really , really , really critical . 

232
00:33:02,335 --> 00:33:06,226
I got not just for the do d but for society at large . 

233
00:33:06,226 --> 00:33:15,847
We need to figure out how to build AIAmachine learning systems that fit into the society of framework works that we've developed . 

234
00:33:15,847 --> 00:33:29,620
So , for instance , think for a moment about self driving cars , right when a humans driving on the car and accident occurs , it's relatively easy , perhaps to understand who is that fault , or at least have a process for doing that . 

235
00:33:29,670 --> 00:33:34,550
We have a legal process for understanding and educated in that situation . 

236
00:33:34,830 --> 00:33:39,590
It's not necessarily clear how we do that for something like an artificial intelligence system . 

237
00:33:39,890 --> 00:33:49,060
So if you are going to actually utilize the outcome of AIsystems , they need to be able to explain themselves . 

238
00:33:49,060 --> 00:33:59,000
They need to be able to provide some transparency they need in the first place , support good decision making processes so that accidents don't happen in the first place . 

239
00:33:59,520 --> 00:34:04,050
So I , that's a really important area that certainly that we are dark are tackling . 

240
00:34:04,050 --> 00:34:08,480
But I think that society , religion , you know , we need to focus on that . 

241
00:34:08,770 --> 00:34:25,530
I think if we can come up with good solutions to that sort of challenge , then we're gonna be really well positioned to start reaping some of the benefits of we can better and more effectively scale up decision making processes . 

242
00:34:26,070 --> 00:34:54,635
We can do more exploration on the science side and apply artificial intelligence , how we advance our scientific technologies , and that we can credibly apply artificial intelligence across a wide variety of domains and have trust that the outcomes from cooperating AI and our decision making process that those are going to be an alliant with the source of outcomes that we want from a societal perspective . 

243
00:34:54,635 --> 00:35:03,300
So I think that's one of the core challenges for us is to figure out how to build the aisles , storms that support what we , as a society. 

244
00:35:03,700 --> 00:35:13,710
So , as we can wind down here , I just wanna ask you , if you are actually outraged to me for not asking a question that I simply should have , in that case , we , what's the question and answered? 

245
00:35:14,090 --> 00:35:15,890
Let me make a more general comment . 

246
00:35:15,980 --> 00:35:24,960
The information innovation office has had a warm history of funding and being involved in AIresearch . 

247
00:35:25,220 --> 00:35:32,010
And one of the early directors of the information organizations at dark AJC. 

248
00:35:32,010 --> 00:35:34,910
Look like a queen to the term of sympathies . 

249
00:35:35,180 --> 00:35:41,200
Basically , there's close and positive interaction between automated systems in humans . 

250
00:35:41,390 --> 00:35:48,110
I think that showed a lot of foresight , and again , I think that is still a key issue for us today . 

251
00:35:48,110 --> 00:35:54,260
And one certainly that multiple double programs , not just in my carefully , we are focused on. 

252
00:35:54,650 --> 00:36:07,500
I'm glad you will bring up that little bit of history with JCRliquor , because he really goes back to the nineteenth sixties , and he was really beginning to choose to define this whole idea of contemporary AI and human machine teaming . 

253
00:36:07,500 --> 00:36:12,730
And as you say , simply , others , and it just goes to show you what a hard problem this is . 

254
00:36:12,950 --> 00:36:17,360
And here we are , you know , fifty years later , and more are still really working on that. 

255
00:36:17,930 --> 00:36:26,720
I like in the current situation too , maybe where we were early on with the development of the internet , right ? 

256
00:36:26,720 --> 00:36:39,960
So if we knew , then what we know now , in terms of where we've landed the internet in some of the challenges of the rapid flow of information and how that can be used for good or for ale . 

257
00:36:40,290 --> 00:36:48,130
Maybe we do things differently , and I see AIas another one of these unable enough and accelerating technologies . 

258
00:36:48,130 --> 00:36:54,710
We're incorporating AIand machine learning in our decision making processes are going to make them go faster . 

259
00:36:55,000 --> 00:36:59,910
The open at a scale that is going to be difficult to control and control . 

260
00:37:00,000 --> 00:37:03,552
Plus , if we don't build in the correct capabilities early . 

261
00:37:03,552 --> 00:37:10,240
And so I think that's part of the reason why it's critical for doctor to be investing in these technologies . 

262
00:37:10,240 --> 00:37:26,610
It's good that we've been doing it over the history of artificial intelligence , but now we're getting the points where there is enough capability in machine learning an AI to make it commercially for real products to get out there for those to have impacts on our daily lives . 

263
00:37:26,800 --> 00:37:35,450
And so I think we must now address these sorts of core issues around transparency , around trust hands . 

264
00:37:35,830 --> 00:37:37,780
AIMmachine learning systems. 

265
00:37:38,480 --> 00:37:42,770
Okay , well , that was that traffic seminar on the air programs . 

266
00:37:42,770 --> 00:37:53,921
You're running a film gonna move forward into the error with some white nuckles of little , but happy to know that you're going to be working on programs that might make me lose in my group of illegal . 

267
00:37:53,921 --> 00:37:59,796
Relax , this discussion was absolutely simulating for every kind of intelligence somehow resides inside of my school . 

268
00:37:59,796 --> 00:38:02,530
And I want to thank you for spending this time with a man . 

269
00:38:03,070 --> 00:38:08,590
I really appreciate the opportunity to talk with you , and thanks listeners for sharing this time with us . 

270
00:38:08,880 --> 00:38:31,960
I hope you join us again for the next Voices from dark , thanks also to ban selection for his partnership in producing this program for more information about material , the programs he runs in the agency's information invasion office and the other work you technologies , dark is working on visit , dark milk and for links that enable you to download this podcast . 

