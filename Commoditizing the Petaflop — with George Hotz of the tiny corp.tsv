EDL	Record In	Record Out	Clipname	Subtitle
https://api.substack.com/feed/podcast/129414110/89b9293d799ec4592ce76d5e9afd346b.mp3

Commoditizing the Petaflop — with George Hotz of the tiny corp
2023-6-20 | 01:12:41 | Latent Space: The AI Engineer Podcast — CodeGen, Agents, Computer Vision, Data Science, AI UX and all things Software 3.0 |

EDL	00:00:00,000	00:00:20,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Hey everyone, welcome to the Latent Space podcast. This is Swyx, writer and editor of Latent Space. And Alessio is taking over with the intros, Alessio is Partner and CTO in residence at Decibel Partners. \NSwyx：大家好, 欢迎来到Latent Space播客. 我是Swyx, Latent Space的作家和编辑. 而Alessio正在接手介绍, Alessio是Decibel Partners的合伙人和常驻CTO. 
EDL	00:00:20,000	00:00:29,973	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: Hey everyone, today we have Geohot on the podcast, aka George Hotz. Everybody knows George, so I'm not going to do a big intro. A couple of things that people might have missed: \NAlessio：大家好, 今天我们的播客有Geohot, 也就是George Hotz. 大家都知道乔治, 所以我不打算做一个大的介绍. 有几件事大家可能已经错过了：
EDL	00:00:29,973	00:00:39,999	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	you traded the first ever unlocked iPhone for a Nissan 350Z and three new iPhones. You were then one of the first people to break into the PS3 to run arbitrary code. You got sued by Sony, \N你用第一部解锁的iPhone换了一辆日产350Z和三部新iPhone. 然后你是第一批闯入PS3运行任意代码的人之一. 你被索尼起诉了、
EDL	00:00:39,999	00:00:50,239	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	you wrote a rap song to fight against that, which is still live on YouTube, which we're going to have on the show notes. Did not go to Tesla to build vision, and instead you started Comma.ai, \N你写了一首说唱歌曲来对抗, 这首歌现在还在YouTube上直播, 我们将在节目笔记中介绍. 你没有去特斯拉建立愿景, 而是创办了Comma.ai、
EDL	00:00:50,239	00:01:00,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	which was an amazing engineering feat in itself until you got a cease and desist from the government to not put these things on the street and turned that into a research only project.\N这本身就是一个惊人的工程壮举, 直到你从政府那里得到了一个停止和禁止, 不把这些东西放在街上, 并把它变成一个研究项目. 
EDL	00:01:00,000	00:01:01,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: You know they're out there. \N乔治：你知道它们就在那里. 
EDL	00:01:01,000	00:01:03,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: Yeah, yeah. \N阿莱西奥：是的, 是的. 
EDL	00:01:03,000	00:01:04,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: They're out there. \NSwyx：它们就在那里. 
EDL	00:01:04,000	00:01:06,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: But like in a, you know, you market them as a research kind of like no warranty. \NAlessio：但是像在一个, 你知道, 你把它们作为研究的那种无担保的市场. 
EDL	00:01:06,000	00:01:15,541	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Because I use the word dev kit, that's not about the government, that's nothing to do with the government. We offer a great one-year warranty. The truth about that is it's gatekeeping. \N乔治：因为我用了dev kit这个词, 那不是关于政府的, 那和政府没有关系. 我们提供了一个很好的一年保修期. 这方面的真相是它在把关. 
EDL	00:01:15,541	00:01:28,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	What's the difference between a dev kit and not a dev kit? Nothing. Just the question of do you think it's for you? And if you think it's for you, buy it. It's a consumer product. We call it a dev kit. If you have a problem with that, it's not for you. \N开发套件和非开发套件之间有什么区别? 没有什么区别. 只是你认为它是否适合你的问题? 如果你认为它适合你, 就买它. 这是一个消费者产品. 我们称它为开发工具包. 如果你对这个有意见, 它就不适合你. 
EDL	00:01:28,000	00:01:30,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: That's great insight. \NSwyx：这是很好的洞察力. 
EDL	00:01:30,000	00:01:40,121	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: I was going through your blog posts to get ready. You've wrote this post about The Hero's Journey. And you linked this thing called the portal story, which is kind of the set of stories in movies and books \NAlessio：我正在翻阅你的博客文章以做好准备. 你写了这篇关于英雄之旅的文章. 你把这个叫做门户故事的东西联系起来, 这是电影和书籍中的一组故事
EDL	00:01:40,121	00:01:49,442	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	about people living this arbitrary life. And then the run to this magic portals kind of takes them into a new, very exciting life and dimension. When you wrote that post, you talked about TinyGrad, \N关于人们过这种任意的生活. 然后奔向这个神奇的门户, 那种把他们带入一个新的、非常令人兴奋的生活和维度. 当你写那篇文章时, 你谈到了TinyGrad、
EDL	00:01:49,442	00:01:58,904	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	which is one of the projects we're working on today. You mentioned this is more of a hobby, something that is not going to change the course of history. Obviously, you're now going full speed into it. \N这也是我们今天正在进行的项目之一. 你提到这更像是一种爱好, 是不会改变历史进程的东西. 很明显, 你现在正全速进入它. 
EDL	00:01:58,904	00:02:03,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	So we would love to learn more about what was the portal that you ran into to get here. \N因此, 我们很想了解更多关于你走到这里所遇到的门户是什么. 
EDL	00:02:03,000	00:02:13,340	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Well, what you realize is... You know what made me realize that I absolutely had to do the company? Seeing Sam Altman go in front of Congress. Why? What are the odds they nationalize NVIDIA? \N乔治：嗯, 你意识到的是......你知道是什么让我意识到我绝对要做这个公司吗? 看到萨姆-阿特曼在国会面前的表现. 为什么? 他们将英伟达国有化的可能性有多大? 
EDL	00:02:13,340	00:02:23,992	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	What are the odds that large organizations in the government, but of course I repeat myself, decide to try to clamp down on accessibility of ML compute? I want to make sure that can't happen structurally. \N政府中的大型组织, 当然, 我再重复一遍, 决定试图钳制ML计算的可及性, 这种几率有多大? 我想确保这在结构上不可能发生. 
EDL	00:02:23,992	00:02:34,592	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	So that's why I realized that it's really important that I do this. And actually, from a more practical perspective, I'm working with NVIDIA and Qualcomm to buy chips. NVIDIA has the best training chips. \N所以这就是为什么我意识到, 我做这个真的很重要. 而实际上, 从更实际的角度来看, 我正在与英伟达和高通公司合作, 购买芯片. 英伟达有最好的训练芯片. 
EDL	00:02:34,592	00:02:48,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Qualcomm has the best inference chips. Working with these companies is really difficult. So I'd like to start another organization that eventually in the limit, either works with people to make chips or makes chips itself and makes them available to anybody. \N高通公司有最好的推理芯片. 与这些公司合作真的很困难. 所以我想成立另一个组织, 最终在限度内, 要么与人合作制造芯片, 要么自己制造芯片, 并向任何人提供. 
EDL	00:02:48,000	00:02:58,994	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: Can you share three core pieces to TinyCorp? Maybe we can dive into each of them. So XLA, PrimTorch, those are the complex instruction system. TinyGrad is the restricted instruction system. \N阿莱西奥：你能分享一下TinyCorp的三个核心部分吗? 也许我们可以深入了解每一个部分. 所以XLA、PrimTorch, 这些是复杂的指令系统. TinyGrad是限制性指令系统. 
EDL	00:02:58,994	00:03:08,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	So you're kind of focused on, again, TinyGrad being small, not being overcomplicated and trying to get as close to the DSP as possible in a way where it's at more. \N因此, 你的重点是, TinyGrad要小, 不要太复杂, 并试图以一种尽可能接近DSP的方式, 让它处于更多的位置. 
EDL	00:03:08,000	00:03:20,183	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Well, it's a very clear analogy from how processes are developed. So a lot of processes back in the day were CISC, complex instruction set, system 360, and then x86. This isn't how things stayed. \N乔治：嗯, 这是一个非常清晰的类比, 从如何开发流程. 所以很多工艺在过去是CISC, 复杂指令集, 系统360, 然后是X86. 事情不是这样保持的. 
EDL	00:03:20,183	00:03:32,247	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	They went to now the most common processor is ARM, and people are excited about RISC-V. No one's excited about it. RISC-V is even less complex than ARM. No one is excited about CISC processors anymore. \N他们走到了现在, 最常见的处理器是ARM, 人们对RISC-V感到兴奋. 没有人对它感到兴奋. RISC-V比ARM更不复杂. 没有人再对CISC处理器感到兴奋. 
EDL	00:03:32,247	00:03:47,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	They're excited about reduced instruction set processors. So TinyGrad is, we are going to make a RISC offset for all ML models. And yeah, it can run all ML models with basically 25 instead of the 250 of XLA or PrimeTorch. So about 10x less complex.\N他们对减少指令集的处理器感到兴奋. 所以TinyGrad是, 我们要为所有的ML模型做一个RISC抵消. 是的, 它可以运行所有的ML模型, 基本上是25而不是XLA或PrimeTorch的250. 因此, 大约减少了10倍的复杂性. 
EDL	00:03:47,000	00:03:48,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Yep. \NSwyx：是的. 
EDL	00:03:48,000	00:03:59,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: You talk a lot about existing AI chips. You said if you can’t write a fast ML framework for GPUs, you just cannot write one for your own chip. So that's another one of your core insights. I don't know if you want to expand on that. \NAlessio：你谈了很多关于现有的AI芯片. 你说如果你不能为GPU写一个快速的ML框架, 你就不能为自己的芯片写一个. 所以这是你的另一个核心见解. 我不知道你是否想就此展开. 
EDL	00:03:59,000	00:04:08,573	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Yeah. I mean, your chip is worse, right? There's no way the chip that you're going to tape out, especially on the first try, is going to be easier to use than an AMD GPU, right? \N乔治：是的, 我的意思是, 你的芯片更糟糕, 对吗? 你的芯片不可能比AMD的GPU更容易使用, 尤其是在第一次尝试时, 对吗? 
EDL	00:04:08,573	00:04:20,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And yet there's no good stack for AMD GPUs. So why do you think you can make one for your chip? You can't, right? There's one other company, aside from NVIDIA, who's succeeded at all at making training chips. What company? \N而AMD GPU却没有好的堆栈. 那么, 为什么你认为你可以为你的芯片做一个? 你不能, 对吗? 除了英伟达, 还有一家公司在制作培训芯片方面取得了完全的成功. 什么公司? 
EDL	00:04:20,000	00:04:22,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: AMD? Intel? \NSwyx：AMD? 英特尔? 
EDL	00:04:22,000	00:04:26,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: No, no, no. I've never trained. Who's trained a model on AMD or Intel? Cerebras. \N乔治：不, 不, 不. 我从来没有训练过. 谁在AMD或英特尔上训练过模型? 脑白金. 
EDL	00:04:26,000	00:04:27,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Cerebras! \NSwyx: Cerebras!
EDL	00:04:27,000	00:04:31,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: I'm talking about, you might know some startups who trained models on these chips. \N乔治：我说的是, 你可能知道一些创业公司在这些芯片上训练过模型. 
EDL	00:04:31,000	00:04:32,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: Oh, TPU. \N阿莱西奥：哦, TPU. 
EDL	00:04:32,000	00:04:41,503	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Exactly. Right? So Midjourney is trained on TPU, right? Like a lot of startups do actually train on TPUs. And they're the only other successful training chip, aside from NVIDIA. \N乔治：没错. 对吗? 所以Midjourney是在TPU上训练的, 对吗? 就像很多初创公司确实在TPU上训练. 而且除了英伟达之外, 它们是唯一一个成功的训练芯片. 
EDL	00:04:41,503	00:04:53,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	But what's unique about Google is that they also wrote their own ML framework, right? And if you can't write your own ML framework that is performant on NVIDIA, there's no way you're going to make it performant on your stuff. \N但谷歌的独特之处在于, 他们也写了自己的ML框架, 对吗? 如果你不能写出你自己的ML框架在英伟达上的表现, 你就没有办法让它在你的东西上表现出来. 
EDL	00:04:53,000	00:04:56,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: And they started from TensorFlow and then they made the chip after. \N阿莱西奥：他们从TensorFlow开始, 然后他们做了芯片之后. 
EDL	00:04:56,000	00:04:58,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Yeah, exactly. Exactly. \NSwyx：是的, 没错. 正是如此. 
EDL	00:04:58,000	00:05:07,369	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: And you have to do it in that direction. Otherwise, you're going to end up, you know, Cerebras, one of those things, a million... Has anyone ever seen a Cerebras? No one's ever like, oh, \N乔治：而且你必须朝着这个方向做. 否则, 你将最终, 你知道, Cerebras, 那些东西之一, 一百万... ...有谁见过Cerebras? 没有人喜欢过, 哦、
EDL	00:05:07,369	00:05:14,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	I trained my model on a Cerebras. Most people are like, I trained my model on GPUs. Some people, 20%, are like, I trained my model on TPUs.\N我在Cerebras上训练我的模型. 大多数人都是这样, 我在GPU上训练我的模型. 有些人, 20%, 会说, 我在TPU上训练了我的模型. 
EDL	00:05:14,000	00:05:25,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: And then the third one, which is the one that surprised me the most, is Turing completeness is harmful. It should be avoided. It made sense once I read it, but maybe tell us a bit more about how you got there. \N阿莱西奥：然后第三条, 也是最让我吃惊的一条, 就是图灵完备性是有害的. 它应该被避免. 我一读就明白了, 但也许可以告诉我们更多关于你是如何做到的. 
EDL	00:05:25,000	00:05:35,303	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Okay. So CPUs devote tons of their silicon and power to things like reorder buffers and speculative execution and branch predictors. And the reason that you need all these things is because \N乔治：好的, CPU将大量的硅和功率用于重排缓冲器、投机执行和分支预测器等方面. 你需要所有这些东西的原因是
EDL	00:05:35,303	00:05:45,606	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	at compile time, you can't understand how the code's going to run. This is Rice’s theorem. This is the halting problem and its limit. And this is not like, oh, the halting problem is theoretical. \N在编译时, 你无法理解代码将如何运行. 这就是莱斯定理. 这是停止问题和它的极限. 这并不是说, 哦, 停顿问题是理论上的. 
EDL	00:05:45,606	00:05:55,597	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	No, no, no, no. It's actually very real. Does this branch get taken or not? Well, it depends on X. Where does X come from? Yeah, forget it, right? But no branches depend on X in a neural net. \N不, 不, 不, 不. 它实际上是非常真实的. 这个分支到底能不能被采纳? 嗯, 这取决于X. X从哪里来? 是的, 算了吧, 对吗? 但在神经网络中, 没有任何分支依赖于X. 
EDL	00:05:55,597	00:06:05,328	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Every branch is a static loop. Like if you're doing a matrix multiply, it's a static loop over the inner dimension. And neural networks are even better. No loads even depend on X, right? \N每个分支都是一个静态循环. 就像你在做一个矩阵乘法, 它是一个内维的静态循环. 而神经网络甚至更好. 负载甚至不依赖于X, 对吗? 
EDL	00:06:05,328	00:06:14,278	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	So with a GPU shader, right, your load might depend on which texture you're actually loading into RAM. But with a neural network, your load is, well, I load that way. Why? \N因此, 对于GPU着色器来说, 你的负载可能取决于你实际加载到RAM中的纹理. 但对于神经网络, 你的负载是, 好吧, 我是这样加载的. 为什么? 
EDL	00:06:14,278	00:06:23,072	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Well, because I load that way the other million times I ran the same net. Every single time you run the net, you do the exact same set of loads, stores, and arithmetic. \N嗯, 因为我在运行同一个网络的一百万次中也是这样加载的. 每一次你运行网络, 你做的都是完全相同的加载、存储和算术. 
EDL	00:06:23,072	00:06:32,699	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	The only thing that changes is the data. And this gives you a very powerful ability to optimize that you can't do with CPU-style things, which have branches, and even GPU-style things, \N唯一改变的是数据. 这给了你一个非常强大的优化能力, 这是你在CPU风格的东西（有分支）, 甚至是GPU风格的东西所不能做到的、
EDL	00:06:32,699	00:06:41,545	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	which have loads and stores. Well, GPUs, if you want GPU-style stuff, you have like load based on X, you now need a cache hierarchy, and not an explicit cache hierarchy, \N有加载和存储. 那么, GPU, 如果你想要GPU风格的东西, 你有像基于X的负载, 你现在需要一个缓存层次, 而不是一个显式缓存层次、
EDL	00:06:41,545	00:06:50,860	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	an implicit cache hierarchy with eviction policies that are hard-coded into the CPU. You start doing all this stuff, and you're never going to get theoretically good performance. \N一个隐性的缓存层次结构, 其驱逐策略是硬编码在CPU中的. 你开始做所有这些事情, 你永远不会得到理论上的好性能. 
EDL	00:06:50,860	00:06:59,655	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Again, I don't think there's 100X. Some startups will talk about 100X, and they'll talk about absolutely ridiculous things like clockless computing or analog computing. \N同样, 我不认为会有100倍. 一些创业公司会谈论100倍, 他们会谈论绝对荒谬的事情, 如无时钟计算或模拟计算. 
EDL	00:06:59,655	00:07:09,751	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Okay, here, analog computing just won't work. And clockless computing, sure, it might work in theory, but your EDA tools are... Maybe AIs will be able to design clockless chips, but not humans. \N好吧, 在这里, 模拟计算是行不通的. 而无时钟计算, 当然, 它可能在理论上可行, 但你的EDA工具是...也许人工智能将能够设计无时钟芯片, 但不是人类. 
EDL	00:07:09,751	00:07:21,513	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	But what actually is practical is changing cache hierarchies and removing branch predictors and removing warp schedulers, right? GPUs spend tons of power on warp scheduling because we have to hide the latency from the memory. \N但实际上实用的是改变高速缓存的层次结构, 去除分支预测器和去除翘曲调度器, 对吗? GPU在翘曲调度上花费了大量的电力, 因为我们必须从内存中隐藏延迟. 
EDL	00:07:21,513	00:07:25,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	We'll have to hide the latency if everything's statically scheduled.\N如果所有的东西都是静态调度的话, 我们就必须要隐藏延迟. 
EDL	00:07:25,000	00:07:27,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: Why do you think people are still hanging on to Turing completeness? \N阿莱西奥：你认为为什么人们还在坚持图灵完备性? 
EDL	00:07:27,000	00:07:29,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Well, because it's really easy. \NSwyx：嗯, 因为它真的很容易. 
EDL	00:07:29,000	00:07:41,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Turing Complete is just really easy to just, oh, you know, it would just be so nice if I could do like an if statement here and actually branch the code, right? So it requires a lot more thought to do it without Turing Completeness. \N乔治：图灵完备性只是真的很容易, 哦, 你知道, 如果我可以在这里做一个if语句, 并真正地将代码分支, 那就太好了, 对吗? 所以, 如果没有图灵完备性, 就需要花更多的心思来做这件事. 
EDL	00:07:41,000	00:07:44,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: And would this be qualitatively different than TPUs? \NSwyx：这和TPU有什么本质上的区别吗? 
EDL	00:07:44,000	00:07:55,390	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: So TPUs are a lot closer. Yeah. TPUs are a lot closer to what I'm talking about than like CUDA. Okay, so what is CUDA? Well, CUDA is a C-like language, which compiles to an LLVM-like IR, which compiles to PTX, \N乔治：所以TPU要近得多. 是的. TPU比CUDA更接近我所说的东西. 好的, 那么什么是CUDA? 嗯, CUDA是一种类似于C的语言, 可以编译成类似于LLVM的IR, 可以编译成PTX、
EDL	00:07:55,390	00:08:06,885	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	which compiles to SAS, which are all Turing Complete. TPUs are much more like this. Yeah. Their memory is pretty statically managed. They have a V—I did some reverse engineering on the TPU. It's published in TinyGrad. \N它可以编译成SAS, 这些都是图灵完全语言. TPU则更像这样. 是的. 他们的内存是非常静态管理的. 他们有一个V-I对TPU做了一些反向工程. 它发表在TinyGrad上. 
EDL	00:08:06,885	00:08:20,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	It has like a VLIW instruction, and it runs them. So it's similar. I think the TPUs have a few problems. I think systolic arrays are the wrong choice. I think they have systolic arrays because that was the guy's PhD, and then of course Amazon makes— \N它有一个类似于VLIW的指令, 并运行它们. 所以它是类似的. 我认为TPU有一些问题. 我认为收缩式阵列是错误的选择. 我认为他们有收缩阵列, 因为那是那家伙的博士学位, 然后当然亚马逊使...
EDL	00:08:20,000	00:08:21,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Could you summarize systolic arrays for us? \NSwyx：你能为我们总结一下收缩型阵列吗? 
EDL	00:08:21,000	00:08:33,301	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Systolic arrays are just—okay, so basically you have like—it's a way to do matrix multiplication. Think of a grid of mollax, and then the grid can multiply, and then shift, multiply, then shift, multiply, then shift. \N乔治：收缩阵列就是--好的, 所以基本上你有--这是一种做矩阵乘法的方法. 想想看, 一个莫拉克斯的网格, 然后这个网格可以进行乘法, 然后移动, 乘法, 然后移动, 乘法, 然后移动. 
EDL	00:08:33,301	00:08:47,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And they are very power efficient, but it becomes hard to schedule a lot of stuff on them if you're not doing like perfectly sized dense matrix multiplies, which you can argue, well, design your models to use perfectly sized dense matrix multiplies, sure. \N它们非常省电, 但如果你不做完美大小的密集矩阵乘法, 就很难在上面安排很多东西, 你可以争辩说, 好吧, 设计你的模型来使用完美大小的密集矩阵乘法, 当然. 
EDL	00:08:47,000	00:08:56,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Thanks for indulging on these explanations. I think we need to keep our audience along with us by pausing every now and then to explain key terms. \NSwyx：谢谢你对这些解释的纵容. 我认为我们需要让我们的听众和我们一起, 时不时地暂停一下, 解释一下关键术语. 
EDL	00:08:56,000	00:09:04,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: When I say explain a systolic array, I just immediately get a picture in my head of like tilting a matrix and shifting it. It's hard to kind of explain. Yeah. \N乔治：当我说解释收缩阵列时, 我脑子里马上就会出现一幅画面, 就像倾斜的矩阵和移动它. 这很难解释. 是的. 
EDL	00:09:04,000	00:09:08,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Yeah. We'll do something. We'll do something. We'll have show notes. \NSwyx: 是的. 我们会做一些事情. 我们会做一些事情. 我们会有节目笔记. 
EDL	00:09:08,000	00:09:18,931	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: And we edit in visuals. Yeah, yeah, yeah. There's some great graphics that just show you, oh, so that's what a systolic array is. But it's a mollax shift machine that looks kind of different from the typical ALU sort of machine. \N乔治：我们在视觉上进行编辑. 对, 对, 对. 有一些伟大的图形, 只是告诉你, 哦, 所以这就是收缩阵列. 但它是一个莫拉克斯移位机, 看起来与典型的ALU类机器有点不同. 
EDL	00:09:18,931	00:09:29,955	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	I think the right answer is something that looks more like queues that feed into ALUs, and then you can prefetch the loads from the memory, put in a bunch of queues, and then the queue is just like, and feeds into another queue over here. \N我认为正确的答案是, 看起来更像是送入ALU的队列, 然后你可以从内存中预取负载, 放入一堆队列, 然后队列就像, 并送入这边的另一个队列. 
EDL	00:09:29,955	00:09:41,025	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	But yeah, but that's not even the main problem with TPUs. The main problem with TPUs is that they're closed source. Not only is the chip closed source, but all of XLA is open source. But the XLA to TPU compiler is a 32 megabyte binary blob \N但是, 是的, 但这甚至不是TPU的主要问题. TPU的主要问题是它们是闭源的. 不仅芯片是闭源的, 而且所有的XLA都是开源的. 但是XLA到TPU的编译器是一个32兆字节的二进制blob
EDL	00:09:41,025	00:09:52,187	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	called libTPU on Google's cloud instances. It's all closed source. It's all hidden stuff. And you know, well, there's a reason Google made it closed source. Amazon made a clone of the TPU. It's called Inferentia. Or they have some other name \N被称为libTPU的谷歌云实例. 这都是闭源的. 这都是隐藏的东西. 你知道的, 好吧, 谷歌让它闭源是有原因的. 亚马逊做了一个TPU的克隆. 它被称为Inferentia. 或者他们有一些其他的名字
EDL	00:09:52,187	00:09:58,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	for it, a training. Tranium. Yeah, yeah, yeah. And look, it's a clone of the TPU. But Google's software at least kind of works.\N训练. Tranium. 对, 对, 对. 而且你看, 它是TPU的一个克隆. 但谷歌的软件至少有点作用. 
EDL	00:09:58,000	00:10:07,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: So those are kind of like the three core pieces. The first thing you're working on, that you've been working on, is TinyGrad. And one of your Twitch streams, you said, is the best thing you've ever written. \N阿莱西奥：因此, 这些是类似于三个核心部分. 你正在做的第一件事是TinyGrad, 你一直在努力. 而你的一个Twitch流, 你说, 是你写过的最好的东西. 
EDL	00:10:07,000	00:10:08,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Yeah. \NSwyx：是的. 
EDL	00:10:08,000	00:10:10,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: Tell us a bit more about that creation. \N阿莱西奥：告诉我们更多关于这个创作的情况. 
EDL	00:10:10,000	00:10:23,678	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: For a long time, TinyGrad had a hard limit at a thousand lines of code. And what this would force you to do is really make sure you were not wasting lines. I got rid of the restriction because it became a little code golfy at the end. \N乔治：很长时间以来, TinyGrad有一个硬性的限制, 就是一千行的代码. 而这将迫使你做的是真正确保你不浪费行数. 我摆脱了这个限制, 因为它在最后变成了一个小的代码高尔夫. 
EDL	00:10:23,678	00:10:36,850	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	But once like the core framework of TinyGrad was there in those thousand lines, but like the core framework, the ideas are expressed with no boilerplate. If you go read PyTorch, you know, PyTorch I think is actually pretty good code. \N但有一次, TinyGrad的核心框架就在这一千多行中, 但就像核心框架一样, 这些想法的表达没有任何模板. 如果你去读PyTorch, 你知道, PyTorch我认为实际上是相当好的代码. 
EDL	00:10:36,850	00:10:44,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	I think Facebook's pretty good, but there's so much boilerplate. Go in PyTorch and try to track down how an LGU actually works. \N我认为Facebook也很不错, 但有很多模板. 在PyTorch中, 试着追踪LGU的实际工作方式. 
EDL	00:10:44,000	00:10:45,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Just a lot of instructions. \NSwyx：只是有很多说明. 
EDL	00:10:45,000	00:10:55,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Oh, you're going to be diving down a long stack from Python to C to custom libraries to dispatchers to, and then I don't even know how to read TensorFlow. I don't even know where's an LU in TensorFlow. \N乔治：哦, 你要从Python到C到自定义库到调度器的漫长堆栈中潜入, 然后我甚至不知道如何阅读TensorFlow. 我甚至不知道TensorFlow中的LU在哪里. 
EDL	00:10:55,000	00:10:56,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Nobody knows. \NSwyx：没人知道. 
EDL	00:10:56,000	00:11:02,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Someone at Google knows maybe. Google as an organism knows. I don't know if anyone individual at Google knows. \N乔治：谷歌的某人也许知道. 谷歌作为一个有机体知道. 我不知道谷歌是否有个人知道. 
EDL	00:11:02,000	00:11:07,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: What are like the important ergonomics like for a developer as you think about designing the TinyGrad API? \NAlessio：当你考虑设计TinyGrad的API时, 对开发者来说, 重要的人体工程学是什么? 
EDL	00:11:07,000	00:11:16,988	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: So the TinyGrad front end looks very similar to PyTorch. There's an even higher level front end you can use for TinyGrad, which is just ONNX. We have better support for ONNX than Core ML does. And we're going to have, \NGeorge：TinyGrad的前端看起来和PyTorch非常相似. 还有一个更高级别的前端, 你可以用在TinyGrad上, 这就是ONNX. 我们对ONNX的支持比Core ML要好. 而且我们会有、
EDL	00:11:16,988	00:11:23,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	I think we're going to pass ONNX Runtime soon, too. People think ONNX Runtime, that's the gold standard for ONNX. No, you can do better. \N我想我们很快也会通过ONNX Runtime. 人们认为ONNX Runtime是ONNX的黄金标准. 不, 你可以做得更好. 
EDL	00:11:23,000	00:11:26,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Pass them in what, specifically? Test compliance tests. \NSwyx：具体在什么方面通过? 测试符合性测试. 
EDL	00:11:26,000	00:11:38,357	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: So ONNX has a big set of compliance tests that you can check out. And we have them running in TinyGrad, and there's some failures. We're below ONNX Runtime, but we're beyond Core ML. So that's where we are in ONNX support now. \N乔治：所以ONNX有一大套合规性测试, 你可以查看一下. 而且我们在TinyGrad中运行了这些测试, 有一些失败的情况. 我们低于ONNX Runtime, 但我们超过了Core ML. 所以这就是我们现在对ONNX的支持. 
EDL	00:11:38,357	00:11:51,450	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	But we will pass ONNX Runtime soon because it becomes very easy to add ops because you don't need to do anything at the lower levels. You just do it at this very high level, and TinyGrad compiles it to something that's fast using these minimal ops. \N但我们很快就会通过ONNX Runtime, 因为它变得非常容易添加操作, 因为你不需要在较低的级别做任何事情. 你只需在这个非常高的层次上做, TinyGrad就会用这些最小的操作将其编译成快速的东西. 
EDL	00:11:51,450	00:12:05,438	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	You can write, most concretely, what TinyGrad can do that PyTorch can't really do, is if you have something like A times B plus C. If you write that in NaivePyTorch, what it's going to do on the GPU is read A, read B in a kernel, and then store A times B in memory, \N如果你用NaivePyTorch写, 它在GPU上要做的就是读取A, 在内核中读取B, 然后在内存中存储A乘以B、
EDL	00:12:05,438	00:12:19,689	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	and then launch another kernel to do A times B plus C. Okay, got to do those loads from memory. It's a whole extra round trip to memory that I just didn't have to do. And you're like, yeah, but you can use the Torch JIT, and it corrects this. Yeah, for that one example, \N然后启动另一个内核来做A乘以B再加上C. 好的, 必须从内存中做这些加载. 这是一个额外的往返于内存的过程, 我没有必要这样做. 你会说, 是的, 但是你可以使用Torch JIT, 它可以纠正这个问题. 是的, 就这一个例子而言、
EDL	00:12:19,689	00:12:26,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	for that one example of MUL/ACC, but, oh, now you did three multiplies? Six multiplies? It won't compile arbitrary code. \N对于MUL/ACC的那个例子, 但是, 哦, 现在你做了三次乘法? 六个乘法? 它不会编译任意的代码. 
EDL	00:12:26,000	00:12:32,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: And have you looked into the other approaches like PyTorch Lightning to accelerate PyTorch itself? \NSwyx：那你有没有研究过其他的方法, 比如PyTorch Lightning来加速PyTorch本身? 
EDL	00:12:32,000	00:12:46,228	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Well, PyTorch Lightning, my understanding is, it's mostly a framework around PyTorch, right? PyTorch Lightning is not going to fix this fundamental problem of I multiply six tensors together. It's not going to fix it going to memory any more than a single read \N乔治：嗯, PyTorch Lightning, 我的理解是, 它主要是围绕PyTorch的一个框架, 对吗? PyTorch Lightning并不打算解决我把六个张量相乘的根本问题. 它不可能解决它进入内存的问题, 就像一个单一的读取
EDL	00:12:46,228	00:13:02,255	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	from each and a single write to the output. There are lower level things in PyTorch that are, I'm not exactly sure what Dynamo does, but I know they're generating some Triton stuff, which is going to generate the kernels on the fly. But, you know, PyTorch Lightning is at a higher level of abstraction. \N和写入输出的问题. PyTorch中有一些较低层次的东西, 我不太清楚Dynamo是做什么的, 但我知道他们正在生成一些Triton的东西, 这将会在飞行中生成内核. 但是, 你知道, PyTorch Lightning是在一个更高的抽象层次上. 
EDL	00:13:02,255	00:13:17,965	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	So TinyGrad's front-end stuff looks like PyTorch. I made a few tweaks. There's a few things I don't like about PyTorch. Why is Relu a class? Really, what's the state? You make a class, and there's a state. Everything should just be Torch functional and then Relu, but just dot Relu on the tensor. \N所以TinyGrad的前端东西看起来像PyTorch. 我做了一些调整. PyTorch有几处我不喜欢的地方. 为什么Relu是一个类? 真的, 是什么状态? 你做了一个类, 就会有一个状态. 一切都应该只是Torch的功能, 然后是Relu, 但只是在张量上点Relu. 
EDL	00:13:17,965	00:13:34,944	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	There's things in Torch where you have to do tensor dot and not a tensor dot. It just shows an API that's not perfectly refined. But when you're doing stuff TinyGrad style where you don't have lines, well, it has to work this way. Because even the lines to express the, well, you can't use the where operator in PyTorch. \N在Torch中, 有些事情你必须做张量点, 而不是张量点. 这只是显示了一个并不完善的API. 但是当你在做TinyGrad风格的东西时, 你没有线, 那么, 它必须这样工作. 因为即使是用线来表达, 嗯, 你也不能在PyTorch中使用where操作符. 
EDL	00:13:34,944	00:13:46,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Why is it true case, condition, false case? Ugh, that's how Python expresses ifs. It's disgusting. Turner operators are much nicer. It should be, I can do my like a less than zero dot where a comma one, right? \N为什么是真情况, 条件, 假情况? 唉, 这就是Python表达if的方式. 真让人恶心. Turner运算符要好得多. 它应该是, 我可以做我喜欢的小于零的点, 其中有一个逗号一, 对吗? 
EDL	00:13:46,000	00:13:50,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: The very pandas-like API? \NSwyx: 非常像pandas的API? 
EDL	00:13:50,000	00:14:00,649	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: It looks like Torch, NumPy, pandas. They're all very similar. I tried to take the cleanest subset of them and express them. But like I said, you can also interact with it using ONNX. I have a rewrite of StableDiffusion, I have a rewrite of Llama, I have a rewrite of Whisper. \N乔治：它看起来像Torch、NumPy、pandas. 它们都非常相似. 我试图从它们中抽取最干净的子集来表达它们. 但就像我说的, 你也可以用ONNX与它互动. 我有一个重写的StableDiffusion, 我有一个重写的Llama, 我有一个重写的Whisper. 
EDL	00:14:00,649	00:14:05,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	You can look at them. They're shorter than the Torch versions, and I think they're cleaner. And you stream them all? \N你可以看一下它们. 它们比Torch的版本短, 而且我认为它们更干净. 你把它们都串起来了? 
EDL	00:14:05,000	00:14:07,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Yeah. Very nice. \NSwyx：是的. 非常好. 
EDL	00:14:07,000	00:14:11,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: So what's the other important concept that you're leveraging to do operation fusing? \N阿莱西奥：那么, 你利用的另一个重要概念是什么, 来做操作融合? 
EDL	00:14:11,000	00:14:25,119	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Yeah, you have basically like a few different like models for the simplest one is eager is as soon as the interpreter sees A times B, it actually dispatches A times B, right? Then you have graph like TensorFlow, which will put A times B into a graph, and then \N乔治：是的, 你基本上有几个不同的模型, 最简单的一个是eager, 就是只要解释器看到A乘以B, 它就会实际分配A乘以B, 对吗? 然后你有像TensorFlow这样的图, 它会把A乘以B放到一个图里, 然后
EDL	00:14:25,119	00:14:39,238	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	we'll do absolutely nothing until you actually compile the graph at the end. I like this third choice, which is somewhere in the middle, laziness. Laziness is you don't know when the ops are going to dispatch, and don't worry about that. You don't have to worry about \N我们完全不做任何事情, 直到你最后实际编译图. 我喜欢这个第三种选择, 这是在中间的某个地方, 懒惰. 懒惰是指你不知道什么时候操作会被派遣, 不用担心这个问题. 你不必担心
EDL	00:14:39,238	00:14:53,936	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	this as a programmer, you just write out all your stuff. And then when you actually type `.numpy`, it'll be ready by the time you copy the thing back to CPU. Or you can do `.realize`, and it will actually like force that tensor to be allocated in RAM. And if you think about it, \N作为一个程序员, 你不必担心这个问题, 你只需写出你所有的东西. 然后当你真正输入`.numpy`时, 当你把东西复制回CPU时, 它就已经准备好了. 或者你可以输入`.realize`, 它实际上会强制将张量分配到RAM中. 如果你考虑一下、
EDL	00:14:53,936	00:15:08,634	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	PyTorch is kind of lazy in a way, but they didn't extend the paradigm far enough, right? When I do A times B in PyTorch, it's going to launch a CUDA kernel to do A times B. But it's not going to wait for that CUDA kernel to complete. So you're getting the worst possible worlds. \NPyTorch在某种程度上是一种懒惰, 但他们没有把范式扩展到足够远, 对吗? 当我在PyTorch中做A乘以B时, 它会启动一个CUDA内核来做A乘以B, 但它不会等待这个CUDA内核完成. 所以你会得到最坏的结果. 
EDL	00:15:08,634	00:15:23,438	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	You're getting the same laziness, but you also can't get fusion, because PyTorch doesn't know that I'm then going to do plus C. There's no way for it to be like, whoa, whoa, whoa, don't launch that CUDA kernel. Whoa, just do this one too. Right? Again, PyTorch is working on this, \N你会得到同样的懒惰, 但你也不能得到融合, 因为PyTorch不知道我接下来要做的是加C, 它没有办法说, 哇, 哇, 哇, 不要启动那个CUDA内核. 哇, 把这个也做了吧. 对吗? 同样, PyTorch也在做这个工作、
EDL	00:15:23,438	00:15:38,190	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	and it's a little bit harder. In Kama, I felt like I was competing against a lot of idiots. Here, I'm competing against smart, very smart people who've made some, I think, different trade-offs. Whereas, if you're trying to build something that is just straight up good on NVIDIA, \N而且这有点难. 在Kama, 我觉得我是在和很多白痴竞争. 在这里, 我的对手是聪明的、非常聪明的人, 他们已经做了一些, 我想, 不同的权衡. 而如果你想在英伟达上建立一些直接的好东西、
EDL	00:15:38,190	00:15:53,521	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	and we have a lot of people and complexity to throw at it, yeah, PyTorch made a lot of the right choices. I'm trying to build something that manages complexity. You can always make your software do more. The magic is when you can make your software do more without adding complexity, right? \N而我们有大量的人员和复杂性可以投入其中, 是的, PyTorch做出了很多正确的选择. 我正试图建立一个可以管理复杂性的东西. 你总是可以让你的软件做得更多. 神奇之处在于, 你可以在不增加复杂性的情况下让你的软件做得更多, 对吗? 
EDL	00:15:53,521	00:15:58,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Because complex things eventually collapse under their own weight, so it's kind of... \N因为复杂的东西最终会在自己的重量下崩溃, 所以这是一种...
EDL	00:15:58,000	00:16:00,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: How does fusing actually work? \NAlessio: 融合实际上是如何工作的? 
EDL	00:16:00,000	00:16:14,480	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: There's this thing called lazy.py, and when you do A times B, that's... It's put into a graph, but it's a very local graph. There's no global graph optimizations. And even this can change, right? Again, the programming model for TinyGrad does not preclude eagerness, right? \N乔治：有一个叫lazy.py的东西, 当你做A乘以B的时候, 那是....... 它被放到一个图中, 但这是一个非常局部的图. 没有全局图的优化. 甚至这也可以改变, 对吗? 同样, TinyGrad的编程模型并不排除急于求成, 对吗? 
EDL	00:16:14,480	00:16:28,292	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Laziness is not guaranteed laziness. It's just going to try its best. So you put in A times B, and that's a binary op, right? And then you put in A times B, that's a node in the graph. It's a virtual node because it's not realized yet, plus C. Okay, here's a new node, \N懒惰并不能保证懒惰. 它只是要尽力而为. 所以你放进A乘以B, 这是一个二进制运算, 对吗? 然后你放进A乘以B, 那就是图中的一个节点. 这是一个虚拟节点, 因为它还没有实现, 加上C、
EDL	00:16:28,292	00:16:41,796	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	which takes the C tensor in here and takes the output of A times B. It's like, whoa, there's two binary ops. Okay, we'll just fuse those together. Okay, here I have a kernel. This kernel has A, B, and C as inputs. It does A times B plus C in the local registers, \N这就像, 哇, 有两个二进制操作. 好的, 我们就把这些融合在一起. 好的, 这里我有一个内核. 这个内核有A、B和C作为输入. 它在本地寄存器中进行A乘以B加C的运算、
EDL	00:16:41,796	00:16:55,763	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	and then outputs that to memory. And you can graph.one in TinyGrad. Another amazing thing that TinyGrad has that I've not seen in any other framework is two things. Graph equals one, which is an environment variable. It will output a complete graph of all the operations. \N然后将其输出到内存. 你可以在TinyGrad中绘制一个图形. TinyGrad的另一个神奇之处在于, 我在其他框架中没有看到过的两件事. Graph equals one, 它是一个环境变量. 它将输出所有操作的完整图形. 
EDL	00:16:55,763	00:17:11,681	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Other people are like, oh, you can use PyTorch, export it to ONNX, and use Netron. Yeah, you can. Like, what? That's not what's real. Graph equals one will show you the actual kernels that were dispatched to the GPU. You can also type debug equals two, which will print those kernels out in your command line, \N其他的人就像, 哦, 你可以用PyTorch, 把它导出到ONNX, 然后用Netron. 是的, 你可以. 就像, 什么? 那不是真正的东西. Graph equals one会显示实际派发到GPU上的内核. 你也可以输入debug equals two, 这将在你的命令行中打印出这些内核、
EDL	00:17:11,681	00:17:26,059	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	and it will tell you the exact number of flops and the exact number of memory accesses in each kernel. So you can immediately see, wait a second, okay, this kernel used this many flops. This was the gigaflops. This is how many bytes it read, and this was the gigabyte per second. \N它将告诉你每个内核中确切的跳动数和确切的内存访问数. 所以你可以立即看到, 等一下, 好的, 这个内核用了这么多flops. 这是千兆位数. 这是它读取的字节数, 这是每秒千兆字节的数量. 
EDL	00:17:26,059	00:17:40,334	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And then you can profile without having to like, okay, I mean, in theory, in PyTorch, Sure, use the NVIDIA Insight Profiler. No one does that. No one does, of course, because it's so difficult, right? Like, actually, NVIDIA used to, I think CUDA 9 was the last one that had it. \N然后你就可以进行剖析, 而不必像, 好吧, 我的意思是, 在理论上, 在PyTorch, 当然, 使用NVIDIA Insight Profiler. 没有人这样做. 当然, 没有人这么做, 因为这太难了, 对吧? 实际上, 英伟达曾经有, 我想CUDA 9是最后一个有这个功能的. 
EDL	00:17:40,334	00:17:58,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	They had a command line one, but now it's like, okay, I'm going to generate this blob, use this NVIDIA GUI tool to convert it into a Chrome trace, and then load it. Yeah, no one does that, right? Just type debug equals two in any TinyGrad model, and it will show you all the kernels that it launches and the efficiency of each kernel, basically.\N他们有一个命令行, 但现在就像, 好吧, 我将生成这个blob, 使用这个英伟达GUI工具将其转换为Chrome的跟踪, 然后加载它. 是的, 没有人这样做, 对吗? 只要在任何TinyGrad模型中输入debug equals two, 它就会显示它启动的所有内核以及每个内核的效率, 基本上是这样. 
EDL	00:17:58,000	00:18:12,430	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Yeah, this is something that John Carmack has often commented about, is that when you code, you need to build in your instrumentation or observability right into that. I wonder if whatever John is working on, he's adopting this style, and maybe we can sort of encourage it by, \NSwyx：是的, 这也是John Carmack经常评论的, 就是当你写代码的时候, 你需要把你的工具或可观察性直接建立在其中. 我在想, 不管约翰在做什么, 他都在采用这种风格, 也许我们可以通过以下方式来鼓励他、
EDL	00:18:12,430	00:18:16,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	I don't know, naming it and coining a certain kind of debugging style? \N我不知道, 给它起个名字, 并创造一种特定的调试风格? 
EDL	00:18:16,000	00:18:19,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: If he would like to start contributing to TinyGrad, I'd be so happy. \N乔治：如果他愿意开始为TinyGrad做贡献, 我会很高兴. 
EDL	00:18:19,000	00:18:22,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: You should hook up with them. \NSwyx: 你应该和他们联系一下. 
EDL	00:18:22,000	00:18:36,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: I've chatted with them a few times. I'm not really sure what his company's doing, but no, I mean, hopefully we get TinyGrad to a point where people actually want to start using it. So TinyGrad right now is uncompetitive on NVIDIA, and it's uncompetitive on x86.\N乔治：我已经和他们聊过几次了. 我不太清楚他的公司在做什么, 但我的意思是, 希望我们能让TinyGrad达到人们真正想要开始使用它的程度. 所以TinyGrad现在在NVIDIA上是没有竞争力的, 在X86上也是没有竞争力的. 
EDL	00:18:36,000	00:18:39,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: And specifically, what do you care about when you say uncompetitive? Speed. \NSwyx: 具体来说, 当你说没有竞争力的时候, 你关心的是什么? 速度. 
EDL	00:18:39,000	00:18:51,859	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Share of speed. It's correct. The correctness is there. The correctness for both forwards and backwards passes is there. But on NVIDIA, it's about 5x slower than PyTorch right now. Like 5x, wow, this is unsurmountable. No, there's reasons it's 5x slower, \N乔治：速度的份额. 这是正确的. 正确性是存在的. 前进和后退的正确性都在那里. 但是在NVIDIA上, 它现在比PyTorch慢了5倍左右. 就像5倍, 哇, 这是不可逾越的. 不, 它慢了5倍是有原因的、
EDL	00:18:51,859	00:19:04,376	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	and I can go through how we're going to make it faster. It could be 100x slower, so we're making progress. But there's one place where it actually is competitive, and that's Qualcomm GPUs. So TinyGrad is used to run the model in OpenPilot. Like right now, \N我可以说说我们要如何让它更快. 它可能会慢100倍, 所以我们正在取得进展. 但有一个地方, 它实际上是有竞争力的, 那就是高通GPU. 所以TinyGrad被用来运行OpenPilot中的模型. 就像现在、
EDL	00:19:04,376	00:19:10,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	it's been live in production now for six months. And TinyGrad is about 2x faster on the GPU than Qualcomm's library.\N它已经在生产中运行了6个月. TinyGrad在GPU上比高通公司的库快2倍. 
EDL	00:19:10,000	00:19:12,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: What about Qualcomm architecture? \NSwyx：那高通架构呢? 
EDL	00:19:12,000	00:19:25,714	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: What makes it doable? Well, because the world has spent how many millions of man hours to make NVIDIA fast? And Qualcomm has a team of 10 Qualcomm engineers? Okay, well, who can I beat here? What I propose with TinyGrad is that developer efficiency is much higher. \N乔治：是什么让它变得可行? 嗯, 因为世界上有多少人花了几百万个工时来使英伟达的速度变快? 而高通公司有一个由10名高通工程师组成的团队? 好吧, 那我能在这里打败谁? 我对TinyGrad的建议是, 开发人员的效率要高得多. 
EDL	00:19:25,714	00:19:40,082	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	But even if I have 10x higher developer efficiency, I still lose on NVIDIA, right? You know, okay, I didn't put 100,000 man hours into it, right? If they put a million, like, that's what I'm saying. But that's what I'm saying we can get. And we are going to close this speed gap a lot. \N但是, 即使我有10倍的开发者效率, 我还是输给了英伟达, 对吗? 你知道, 好吧, 我并没有投入10万个工时, 对吗? 如果他们投入了一百万, 比如, 这就是我说的. 但这是我说的, 我们可以得到的. 而且我们要把这个速度差距缩小很多. 
EDL	00:19:40,082	00:19:54,852	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Like I don't support TensorCourse yet. That's a big one that's just going to, okay, massively close the gap. And then AMD. I don't even have a benchmark for AMD because I couldn't get it compiled. Oh, and I tried. Oh, I tried. I spent a day. Like, I spent actually a day trying to get PyTorch. \N像我还不支持TensorCourse. 这是一个很大的问题, 它将会, 好吧, 大规模地缩小差距. 然后是AMD. 我甚至没有AMD的基准测试, 因为我无法将其编译. 哦, 我试过了. 哦, 我试过了. 我花了一天时间. 比如, 我花了一天的时间试图得到PyTorch. 
EDL	00:19:54,852	00:20:09,622	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And I got it built. I got it kind of working, then I tried to run a model, like, there's all kinds of weird errors and the rabbit holes are so deep on this. I'm like, you know, you can compare the speed. Right now, you can run LLAMA, you can run anything you want on AMD. It already all works. \N我建立了它. 我得到了它的工作, 然后我试图运行一个模型, 就像, 有各种奇怪的错误和兔子洞是如此之深. 我想, 你知道, 你可以比较一下速度. 现在, 你可以运行LLAMA, 你可以在AMD上运行任何你想要的东西. 它已经全部工作了. 
EDL	00:20:09,622	00:20:26,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Any OpenCL backend works, and it's not terribly slow. I mean, it's a lot faster than crashing. So it's infinitely times faster than PyTorch on AMD. But pretty soon, we're going to start getting close to theoretical maximums on AMD. That's really where I'm pushing. And I want to get AMD on MLPerf in a couple months, hopefully.\N任何OpenCL后端都可以使用, 而且速度并不慢. 我的意思是, 这比崩溃要快得多. 所以它比AMD上的PyTorch快了无限倍. 但很快, 我们就要开始接近AMD上的理论最大值了. 这就是我真正在推动的地方. 我想在几个月内让AMD在MLPerf上运行, 希望如此. 
EDL	00:20:26,000	00:20:27,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Now that you bring up AMD. \NSwyx：既然你提到了AMD. 
EDL	00:20:27,000	00:20:43,412	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: Yeah, let's dive into that. Because when you announced the Semicore fundraise, you mentioned one of your first goals is like build the framework, runtime and driver for AMD. And then on June 3rd on Twitch, you weren't as excited about AMD anymore. Maybe let's talk a bit about that. \NAlessio：是的, 让我们深入探讨一下. 因为当你宣布Semicore筹款时, 你提到你的首要目标之一是为AMD建立框架、运行时间和驱动程序. 然后在6月3日的Twitch上, 你对AMD不再那么兴奋了. 也许让我们来谈一谈这个问题. 
EDL	00:20:43,412	00:20:51,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	You compared the quality of commit messages from the AMD kernel to the Intel work that people are doing there. What's important to know?\N你比较了AMD内核的提交信息的质量和人们在那里做的英特尔工作. 有什么需要了解的吗? 
EDL	00:20:51,000	00:21:08,553	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: When I said I want to write a framework, I never intended on writing a kernel driver. I mean, I flirted with that idea briefly, but realistically, there's three parts to it, right? There's the ML framework, there's the driver, and then there's the user space runtime. I was even down to rewrite the user space runtime. \N乔治：当我说我想写一个框架的时候, 我从来没有想过要写一个内核驱动. 我的意思是, 我曾短暂地考虑过这个想法, 但现实中, 它有三个部分, 对吗? 有ML框架, 有驱动, 然后是用户空间的运行时间. 我甚至还在重写用户空间的运行时间. 
EDL	00:21:08,553	00:21:26,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	I have a GitHub repo called CUDA IOControlSniffer. It's terribly called. But you can actually launch a CUDA kernel without CUDA. So you don't need CUDA installed. Just the NVIDIA open source driver and this open source repo can launch a CUDA kernel. So rewriting the user space runtime is doable. Rewriting the kernel driver? \N我有一个GitHub repo, 叫做CUDA IOControlSniffer. 它的名字很吓人. 但是你实际上可以在没有CUDA的情况下启动一个CUDA内核. 所以你不需要安装CUDA. 只要有NVIDIA的开源驱动和这个开源版本就可以启动CUDA内核. 所以重写用户空间的运行时间是可以做到的. 重写内核驱动? 
EDL	00:21:26,000	00:21:27,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: I don't even have docs. \NSwyx: 我甚至没有文档. 
EDL	00:21:27,000	00:21:39,071	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: I don't have any docs for the GPU. Like it would just be a massive reverse engineering project. I wasn't complaining about it being slow. I wasn't complaining about PyTorch not compiling. I was complaining about the thing crashing my entire computer. It panics my kernel. \NGeorge: 我没有任何关于GPU的文档. 就像这将是一个巨大的逆向工程项目. 我不是在抱怨它太慢. 我不是在抱怨PyTorch不能编译. 我抱怨的是这个东西让我的整个电脑崩溃. 它让我的内核恐慌. 
EDL	00:21:39,071	00:21:51,531	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And I have to wait five minutes while it reboots because it's a server motherboard and they take five minutes to reboot. So I was like, look, if you guys do not care enough to get me a decent kernel driver, there's no way I'm wasting my time on this, especially when I can use Intel GPUs. \N我不得不在它重新启动时等待五分钟, 因为这是一块服务器主板, 它们需要五分钟才能重新启动. 所以我想, 如果你们不关心给我一个像样的内核驱动, 我就不可能在这上面浪费时间, 特别是当我可以使用英特尔GPU时. 
EDL	00:21:51,531	00:22:03,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Intel GPUs have a stable kernel driver and they have all their hardware documented. You can go and you can find all the register docs on Intel GPUs. So I'm like, why don't I just use these? Now, there's a downside to them. Their GPU is $350. You're like, what a deal.\N英特尔GPU有一个稳定的内核驱动, 他们有所有的硬件记录. 你可以去看看, 你可以找到所有关于英特尔GPU的注册文档. 所以我想, 为什么我不直接使用这些呢? 现在, 他们有一个缺点. 他们的GPU是350美元. 你会觉得, 这太划算了. 
EDL	00:22:03,000	00:22:04,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: It's $350.\NSwyx：是350美元. 
EDL	00:22:04,000	00:22:19,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: You know, you get about $350 worth of performance. And if you're paying about $400 for the PCIe slot to put it in, right, like between the power and all the other stuff, you're like, okay, nevermind. You got to use NVIDIA or AMD from that perspective. But I sent an email to Lisa Su. She responded.\N乔治：你知道, 你得到的是价值350美元的性能. 如果你为PCIe插槽支付400美元来安装它, 那么, 在电源和所有其他东西之间, 你就会觉得, 好吧, 算了吧. 从这个角度来看, 你必须使用NVIDIA或AMD. 但我给Lisa Su发了一封电子邮件. 她回复了. 
EDL	00:22:19,000	00:22:20,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Oh. \NSwyx：哦. 
EDL	00:22:20,000	00:22:34,148	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: And I've had a few calls since. And like, what I tried to do, first off, like, thank you for responding. It shows me that like, if you don't care about your kernel panicking, I can't, like, this is just a huge waste of my time, right? I'll find someone who will care. \N乔治：之后我接到了几个电话. 而且, 我想做的是, 首先, 感谢你的回应. 它告诉我, 就像, 如果你不关心你的内核恐慌, 我不能, 就像, 这只是一个巨大的浪费我的时间, 对吗? 我会找到一个会关心的人. 
EDL	00:22:34,148	00:22:48,962	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	I'm not asking for your seven by seven Winograd convolution when transposed to be fast. Like, I'm not asking for that. I'm asking literally for- The basics of getting it running. Oh, and this isn't TinyGrad. This is your demo apps. I ran their demo apps in loops, and I got kernel panics. \N我并不要求你的七乘七的Winograd卷积在转置时要快. 就像, 我不是在要求那个. 我要求的是字面上的--让它运行的基础知识. 哦, 这不是TinyGrad. 这是你的演示应用程序. 我在循环中运行他们的演示应用程序, 我得到了内核恐慌. 
EDL	00:22:48,962	00:23:03,520	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	I'm like, no, okay. No, Lisa Su reached out, connected with a whole bunch of different people. They sent me a pre-release version of RockM 5.6. They told me you can't release it, which I'm like, guys, why do you care? But they say they're going to release it by the end of the month, \N我想, 不, 好吧. 不, Lisa Su联系了, 与一大堆不同的人联系. 他们给我寄来了RockM 5.6的预发布版本. 他们告诉我, 你不能发布它, 我想, 伙计们, 你为什么要关心? 但他们说他们将在月底前发布、
EDL	00:23:03,520	00:23:18,078	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	and it fixed the kernel panic. The guy managed to reproduce it with the two GPUs and the computer, and yeah, sent me a driver, and it works. I had that experience, and then I had another experience where I had two calls with, like, AMD's, like, communication people. I was just like, \N而且它修复了内核恐慌问题. 那个人设法用两个GPU和电脑重现了这个问题, 是的, 给我寄来了一个驱动, 而且还能用. 我有这样的经历, 然后我有另一个经历, 我和AMD的沟通人员打了两次电话. 我当时就想、
EDL	00:23:18,078	00:23:33,867	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	I tried to explain to these people, like, open source culture. Like, it's not open source if you dump the source code on a GitHub repo and then forget about it until the next release. It's not open source if all your issues are from 2022. Like, it's just no one's going to contribute to that project, right? \N我试图向这些人解释, 比如, 开源文化. 就像, 如果你把源代码扔在GitHub repo上, 然后在下一个版本之前忘记它, 这就不是开源了. 如果你所有的问题都来自2022年, 那就不是开源了. 就像, 没有人会为这个项目做出贡献, 对吗? 
EDL	00:23:33,867	00:23:49,861	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Sure, it's open source in a very, like, technical sense. To be fair, it's better than nothing. It's better than nothing, but I fixed a bug in Nickel that I fixed. There's a fun fact, by the way. If you have a consumer AMD GPU, they don't support peer-to-peer, and their all-reduce bandwidth is horrendously slow \N当然, 在非常, 比如, 技术意义上, 它是开源的. 公平地说, 这总比没有好. 它比什么都好, 但我在Nickel中修复了一个错误, 我修复了. 顺便说一句, 有一个有趣的事实. 如果你有一个消费级的AMD GPU, 它们不支持点对点, 而且它们的全还原带宽慢得吓人
EDL	00:23:49,861	00:24:04,984	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	because it's using CUDA kernels to do the copy between the GPUs, and it's putting so many transactions on the PCIe bus that it's really slow. But you can use CUDA memcpy, and there's a flag to use CUDA memcpy, but that flag had a bug. I posted the issue on Nickel. I expected nothing to happen. \N因为它使用CUDA内核在GPU之间进行复制, 而且它在PCIe总线上放了这么多事务, 所以速度非常慢. 但你可以使用CUDA memcpy, 而且有一个标志可以使用CUDA memcpy, 但这个标志有一个错误. 我在Nickel上发布了这个问题. 我以为不会发生什么. 
EDL	00:24:04,984	00:24:18,723	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	The NVIDIA guy replied to me within an hour. He's like, try this other flag. I'm like, okay, I tried the other flag. It still doesn't work, but here's a clean repro. And I spent, like, three hours writing a very clean repro. I ended up tracking the issue down myself, \N英伟达的人在一个小时内就给我回复了. 他说, 试试这个其他的标志. 我想, 好吧, 我试了另一个标志. 它还是不行, 但这是一个干净的再现. 我花了大概三个小时写了一个非常干净的重现. 最后我自己追踪到了这个问题、
EDL	00:24:18,723	00:24:36,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	but just the fact that somebody responded to me within an hour and cared about fixing the issue? Okay, you've shown that it's worth my time, and I will put my time in because, like, let's make this better. Like, I'm here to help. But if you show me that, you know, you're like, you're the kernel panics. That's just, like, expected. Okay.\N但事实上, 有人在一小时内就回复了我, 并关心解决这个问题? 好吧, 你已经表明它值得我花时间, 我将投入我的时间, 因为, 比如, 让我们把它变得更好. 就像, 我是来帮忙的. 但是, 如果你向我展示, 你知道, 你喜欢, 你是内核恐慌. 这只是, 像, 预期. 好的. 
EDL	00:24:36,000	00:24:38,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Well, it sounds like AMD is getting the message. \NSwyx: 好吧, 听起来AMD已经得到了这个消息. 
EDL	00:24:38,000	00:24:53,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: They are. And I just, I don't really think they've had someone explain to them, like, like, I was like, you can, like, build in public. And they're like, what's an example of building in public? I'm like, go look at PyTorch. Go look at PyTorch. I have two minor things merged into PyTorch because it's very responsive, you know? \N乔治：他们是. 我只是, 我不认为他们真的有人向他们解释过, 比如, 我就像, 你可以, 比如, 在公共场合建立. 他们想, 什么是公共建筑的例子? 我就说, 去看看PyTorch. 去看看PyTorch吧. 我有两件小事被并入PyTorch, 因为它的响应速度非常快, 你知道吗? 
EDL	00:24:53,000	00:25:06,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: So that's kind of like the lowest level of the stack. And then at a slightly higher level, obviously, there's TinyGrad, there's Mojo, there's ggml. How are you thinking about breadth versus, like, depth? Like, where you decided to focus early on? \N阿莱西奥：所以这有点像最底层的堆栈. 然后在稍高的层次, 显然, 有TinyGrad, 有Mojo, 有ggml. 你是如何考虑广度与深度的关系的? 比如, 你在早期就决定把重点放在哪里? 
EDL	00:25:06,000	00:25:18,151	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: So ggml is very much like a, okay, everyone has M1s, right? Actually, I was thinking, in the beginning, I was thinking of something more like ggml, focused on the M1s. But ggml showed up and was just like, we're actually just focusing on the M1s. \N乔治：所以ggml非常像一个, 好吧, 每个人都有M1, 对吗? 事实上, 我在想, 在一开始, 我想的是更像ggml的东西, 专注于M1. 但是ggml出现了, 就像, 我们实际上只是专注于M1s. 
EDL	00:25:18,151	00:25:30,540	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And actually, M1 PyTorch is considerably better than AMD PyTorch. M1 PyTorch works, it only gives wrong answers sometimes, and it only crashes sometimes. But, like, some models kind of run. When I was writing the metal backend, I was comparing to MPS PyTorch, \N实际上, M1 PyTorch比AMD PyTorch要好得多. M1 PyTorch可以工作, 它只是有时给出错误的答案, 而且它只是有时崩溃. 但是, 比如说, 有些模型是可以运行的. 当我在写金属后端时, 我与MPS PyTorch进行了比较、
EDL	00:25:30,540	00:25:42,834	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	and I had, like, a discrepancy. TinyGrad checks all its outputs compared to Torch, and I had one where it didn't match. I'm like, I checked the matrix by hand, it matches TinyGrad, I don't understand. And then I switched PyTorch back to CPU, and it matched. \N而我有, 比如, 一个差异. TinyGrad检查它的所有输出与Torch的比较, 我有一个不匹配的地方. 我想, 我用手检查了矩阵, 它与TinyGrad相符, 我不明白. 然后我把PyTorch换回CPU, 它就匹配了. 
EDL	00:25:42,834	00:25:54,270	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	I'm like, oh. Well, there's, like, bugs, like, if you, like, transpose the matrix, because, like, I think it has to do with, like, multi-views in PyTorch, and, like, weird under-the-hood stuff that's not exposed to you, like, there's bugs. \N我想, 哦. 好吧, 有, 比如, bug, 比如, 如果你, 比如, 转置矩阵, 因为, 比如, 我认为这与, 比如, PyTorch的多视图有关, 还有, 比如, 奇怪的不为人知的内在东西, 比如, 有bug. 
EDL	00:25:54,270	00:26:04,515	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And maybe they fixed them, but, like, you know, it seems like there was a lot of momentum. Again, because you're getting how many engineers care about making PyTorch work on M1, right? Thousands, tens of thousands. \N也许他们修复了它们, 但是, 就像, 你知道, 似乎有很多的动力. 同样, 因为你得到多少工程师关心使PyTorch在M1上工作, 对吗? 成千上万, 数以万计. 
EDL	00:26:04,515	00:26:15,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And you have an open development process, and guess what? It's going to be good. How many engineers care about AMD working, PyTorch AMD working? Well, you got 10 guys that work for AMD, and then, like, a couple hobbyists.\N而且你有一个开放的开发过程, 你猜怎么着? 它将会是好的. 有多少工程师关心AMD的工作, PyTorch AMD的工作? 嗯, 你有10个为AMD工作的人, 然后, 比如, 几个业余爱好者. 
EDL	00:26:15,000	00:26:20,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: You revealed an interesting detail about how you debug. You hand-check the matrix math? No, I don't hand-check it. \NSwyx：你透露了一个关于你如何调试的有趣细节. 你手工检查矩阵的数学运算? 不, 我没有手工检查. 
EDL	00:26:20,000	00:26:34,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: One of the best tests in TinyGrad is a file called testops.py. And it's just a hundred small examples written in TinyGrad and PyTorch, and it checks both the forwards and backwards to make sure they match. \N乔治：TinyGrad中最好的测试之一是一个叫testops.py的文件. 它只是用TinyGrad和PyTorch写的一百个小例子, 它同时检查正向和反向, 以确保它们匹配. 
EDL	00:26:34,000	00:26:35,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Good test suite. Yeah. Very important. \NSwyx: 好的测试套件. 是的. 非常重要. 
EDL	00:26:35,000	00:26:43,869	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: That's, I mean, that's one of them where, like, I really, I put a lot of effort into CI for TinyGrad. I think CI is super important. Like, I want that green check to mean I can merge this, right? \N乔治：那是, 我的意思是, 那是其中的一个, 比如, 我真的, 我在TinyGrad的CI上花了很多精力. 我认为CI是超级重要的. 就像, 我希望绿色检查意味着我可以合并这个, 对吗? 
EDL	00:26:43,869	00:26:51,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Like, I don't want my tests to, and if the green check, if you somehow manage to introduce a bug and get the green check, okay, we're fixing the test, top priority. \N我不希望我的测试, 如果绿色检查, 如果你以某种方式设法引入一个错误并得到绿色检查, 好的, 我们正在修复测试, 最优先的. 
EDL	00:26:51,000	00:26:52,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Mojo? \NSwyx: Mojo?
EDL	00:26:52,000	00:27:00,406	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: It's closed source. No, I'm not that interested. Do you know what I mean? Like, look, I like Chris Lattner. I think he's going to do great things, and I understand the, like, \N乔治：它是闭源的. 不, 我不是那么感兴趣. 你知道我的意思吗? 比如, 听着, 我喜欢克里斯-拉特纳. 我认为他将会做伟大的事情, 而且我理解, 比如、
EDL	00:27:00,406	00:27:05,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	kind of the wisdom, even, in keeping it closed source. But, you know, I'm interested when it's open. \N我理解那种保持闭源的智慧, 甚至. 但是, 你知道, 当它是开放的时候, 我很感兴趣. 
EDL	00:27:05,000	00:27:14,543	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Yeah. You have an interesting design deviation from him, because he's decided to be a, well, promised to be a superset of Python, and you have decided to break with PyTorch APIs. \NSwyx: 是的. 你的设计与他有一个有趣的偏差, 因为他决定成为一个, 嗯, 承诺成为一个Python的超集, 而你决定打破PyTorch的API. 
EDL	00:27:14,543	00:27:18,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And I think that affects learnability and transportability of code. \N我认为这影响了代码的可学习性和可运输性. 
EDL	00:27:18,000	00:27:30,877	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: You know, if the PyTorch thing ends up being, like, a stumbling block, I could write a perfect PyTorch instead of import PyTorch. Instead of, like, yeah, import torch, you type import tinytorchestorch. \N乔治：你知道, 如果PyTorch的事情最终成为, 比如, 一个绊脚石, 我可以写一个完美的PyTorch而不是导入PyTorch. 而不是像, 是的, 导入Torch, 你输入import tinytorchestorch. 
EDL	00:27:30,877	00:27:44,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And if that really becomes the stumbling block, I will do that. No, Chris Lattner went much further than PyTorch. Replicating the PyTorch API is something I can do with a couple, you know, like an engineer monitor. \N如果这真的成了绊脚石, 我就会这么做. 不, Chris Lattner比PyTorch走得更远. 复制PyTorch的API是我可以用几个人做的, 你知道, 就像一个工程师显示器. 
EDL	00:27:44,000	00:27:44,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: A shim. \NSwyx：一个垫片. 
EDL	00:27:44,000	00:27:47,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Right, like a shim, yeah. Replicating Python? \N乔治：对, 就像一个垫片, 是的. 复制Python? 
EDL	00:27:47,000	00:27:48,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Hoo-hoo-hoo! \NSwyx: Hoo-hoo-hoo!
EDL	00:27:48,000	00:27:57,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: There's a big graveyard of those projects. How's Piston going? How's Jython? \N乔治：这些项目有一个很大的坟场. Piston怎么样了? Jython怎么样了? 
EDL	00:27:57,000	00:27:59,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: PyPy? Oh, you can go way back. \NSwyx: PyPy? 哦, 你可以追溯到很久以前. 
EDL	00:27:59,000	00:28:11,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: So your core mission is commoditizing the petaflop. And then your business goal is to sell computers for more than the cost to make, which seems super reasonable. And you're going to have three tiny boxes? \NAlessio：所以, 你的核心任务是使petaflop商品化. 然后你的商业目标是以超过制造成本的价格出售计算机, 这似乎超级合理. 你将会有三个小盒子? 
EDL	00:28:11,000	00:28:13,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Red, green, blue? No, no, no, no, no, no, no. \NSwyx：红、绿、蓝? 不, 不, 不, 不, 不, 不, 不. 
EDL	00:28:13,000	00:28:21,669	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: That was my... Look, you know, a lot of people, like, I love, you know, leaning into, like, saying I'm giving up, right? It's great to give up, right? Giving up is this wonderful thing. It's so liberating. \N乔治：那是我的...听着, 你知道, 很多人, 比如, 我喜欢, 你知道, 靠在一起, 比如, 说我放弃了, 对吗? 放弃很好, 对吗? 放弃是件美妙的事情. 它是如此解放. 
EDL	00:28:21,669	00:28:32,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And then, like, you can decide afterward if you really give up or not. There's very little harm in saying you give up, except, like, you know, great, Twitter haters have something to talk about, and all press is good press, kids, so... Just red, only red. \N然后, 比如, 你可以在事后决定是否真的放弃. 说你放弃没有什么坏处, 除了, 比如, 你知道, 很好, 推特上的仇恨者有东西可以谈论, 所有的媒体都是好的媒体, 孩子们, 所以... ...只有红色, 只有红色. 
EDL	00:28:32,000	00:28:34,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Tiny box, red. Tiny box, red. \NSwyx：小盒子, 红色. 小小的盒子, 红色的. 
EDL	00:28:34,000	00:28:41,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Unless AMD, you know, upsets me again, and then we're back to other colors. We have other colors to choose from. \N乔治：除非AMD公司, 你知道, 再次让我不高兴, 然后我们就回到其他颜色. 我们有其他颜色可以选择. 
EDL	00:28:41,000	00:28:52,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: When you think about hardware design, what are some of the numbers you look for? So, teraflops per second is one, but, like, memory bandwidth is another big limiter. Like, how do you make those trade-offs? \N阿莱西奥：当你考虑硬件设计时, 你看中的是哪些数字? 所以, 每秒兆位数是一个, 但是, 比如, 内存带宽是另一个大的限制因素. 比如, 你是如何进行这些权衡的? 
EDL	00:28:52,000	00:29:00,277	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Well, I mean, fundamentally, I'm limited to what GPUs I can buy. But, yeah, for something that I think a lot of people are going to want to reasonably do, with, um... \N乔治：好吧, 我的意思是, 从根本上说, 我的GPU是有限的, 我可以购买. 但是, 是的, 对于我认为很多人都想合理地做的事情来说, 用, 嗯......
EDL	00:29:00,277	00:29:13,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	A coworker of mine described them as luxury AI computers. Right? Like, luxury AI computers for people. And that's, like, what we're building. And I think a common thing people are going to want to do is run, like, Large Llama. Right? Or Large, like, Falcon or whatever. \N我的一个同事把它们描述为豪华的人工智能计算机. 对吗? 就像, 人们的豪华人工智能计算机. 而这正是我们正在建造的东西. 我认为人们想要做的一件普通的事情是运行, 比如, 大喇嘛. 对吗? 或者大型的, 比如, 猎鹰或其他什么. 
EDL	00:29:13,000	00:29:14,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: FB-16 Llama.\NSwyx: FB-16 Llama. 
EDL	00:29:14,000	00:29:23,851	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: FB-16, exactly. Exactly. Um, you know, Int8, I think, can work. I think that, like, what GGML is doing to go to, like, N4. Like, this doesn't work. Like, have you done... I mean, maybe they have. \N乔治：FB-16, 没错. 没错. 嗯, 你知道, Int8, 我认为, 可以工作. 我认为, 像, GGML正在做的事, 去, 像, N4. 像, 这不起作用. 像, 你有没有做...我的意思是, 也许他们有. 
EDL	00:29:23,851	00:29:33,170	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	But, like, I read what it was, and I was like, this isn't from any paper. This is just some... Squeezing as much as possible. Yeah, you made up some quantization standards to make it run fast. \N但是, 就像, 我读了它是什么, 我就像, 这不是从任何文件. 这只是一些...尽可能多的挤压. 是的, 你编造了一些量化标准以使其快速运行. 
EDL	00:29:33,170	00:29:38,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And, like, maybe it works. But, okay, where's, like, the Hellaswag number? Right? Where's your, uh...\N而且, 像, 也许它的工作. 但是, 好吧, 哪来的, 比如, Hellaswag的数字? 对吗? 你的, 呃...
EDL	00:29:38,000	00:29:44,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: The thesis is right. That, like, if you have hundreds of billions of parameters, that the individual quantization doesn't actually matter that much. \NSwyx：论文是正确的. 如果你有几千亿个参数, 单个量化其实并不那么重要. 
EDL	00:29:44,000	00:29:53,035	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Well, the real way to look at all of that is to just say you want to compress the weights, right? It's a form of weight compression. Quantization is a form of weight compression, right? \N乔治：好吧, 看这些的真正方法只是说你想压缩权重, 对吗? 这是一种重量压缩的形式. 量化是重量压缩的一种形式, 对吗? 
EDL	00:29:53,035	00:30:02,396	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Now, this is obviously not lossless. It's not a lossless compressor, right? If it's a lossless compressor, and you can show that it's correct, then, okay, we don't have to have any other conversation. \N现在, 这显然不是无损的. 这不是一个无损的压缩器, 对吗? 如果它是一个无损压缩器, 而且你能证明它是正确的, 那么, 好吧, 我们没有必要进行任何其他对话. 
EDL	00:30:02,396	00:30:11,338	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	But it's a lossy compressor. And how do you know that your loss isn't actually losing the power of the model? Maybe int4 65B llama is actually the same as FB16 7B llama, right? We don't know. \N但这是一个有损的压缩器. 而你怎么知道你的损失实际上并没有损失模型的力量呢? 也许int4 65B llama实际上和FB16 7B llama是一样的, 对吗? 我们不知道. 
EDL	00:30:11,338	00:30:21,025	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Maybe someone has done this yet, but I looked for it when it, like, first came out and people were talking about it. And I'm like, it's not from a paper, right? The indate stuff is from a paper where they... \N也许有人已经做了这个, 但我找了一下, 当它, 比如, 刚出来的时候, 人们在谈论它. 而我想, 这不是来自一篇论文, 对吗? 那些不确定的东西是来自一篇论文, 他们...
EDL	00:30:21,025	00:30:31,457	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Like, some of the indate stuff is from a paper. There's one paper, I think it's, like, indate... LLM.indate, where they actually do all the tests. And they didn't go fully indate. They made, like, 90% of it indate and kept, \N就像, 一些不确定的东西是来自一篇论文. 有一篇论文, 我想它是, 像, indate...LLM.indate, 在那里他们实际上做了所有的测试. 他们并没有完全采用indate. 他们做了90%的试卷, 保留了10%的内容、
EDL	00:30:31,457	00:30:37,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	like, 10% of it in FB16 for what they called, like, the outliers or whatever. So I think that this is not quite so easy.\N他们把90%的内容做成独立的, 而把10%的内容保留在FB16中, 以备他们所谓的离群索居之类的. 所以我认为这并不那么容易. 
EDL	00:30:37,000	00:30:38,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: And I think being able... \NSwyx: 我认为能够...
EDL	00:30:38,000	00:30:47,590	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Well, so first off, if you're training, no one's gotten training to work with indate yet. There's a few papers that vaguely show it. But if you're training, you're going to need BF16 or float16. \N乔治：好吧, 首先, 如果你在训练, 还没有人得到训练来使用indate. 有几篇论文隐约显示了这一点. 但如果你在训练, 你将需要BF16或float16. 
EDL	00:30:47,590	00:30:58,645	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	So this is why I target that. Now, the thing that you're going to want to do is run these large language models out of the box on your hardware in FB16, and that's memory bandwidth. So you need large amounts of memory bandwidth, too. \N所以这就是为什么我的目标是这个. 现在, 你要做的事情是在你的硬件上用FB16运行这些大型语言模型, 这就是内存带宽. 所以你也需要大量的内存带宽. 
EDL	00:30:58,645	00:31:02,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	So ask how I trade off memory bandwidth in Flop, so what GPUs can I buy?\N所以问我如何在Flop中交换内存带宽, 那么我可以买什么GPU? 
EDL	00:31:02,000	00:31:14,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: So first of all, you have this hiring process, which is you've got to solve one of the bounties that are open on TinyGrad. There's no technical interview. One of them is indate support. Do you already have some things you want to test on? \N阿莱西奥：所以首先, 你有这个招聘过程, 就是你必须解决TinyGrad上公开的悬赏任务之一. 没有技术面试. 其中一个是独立的支持. 你已经有一些你想测试的东西了吗? 
EDL	00:31:14,000	00:31:16,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: We have indate support. What I'd like to see somebody do \NSwyx：我们有indate支持. 我想看到有人做的是
EDL	00:31:16,000	00:31:27,552	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: is just load the ggml indate llama into TinyGrad and then benchmark it against the FB16 one. Indate already works in TinyGrad. It doesn't actually do the math in indate. It does all the math still in FB32. \NGeorge: 就是把ggml indate llama加载到TinyGrad中, 然后用FB16的基准来测试. Indate已经在TinyGrad中工作了. 它实际上并不做indate中的数学运算. 它仍然在FB32中做所有的数学运算. 
EDL	00:31:27,552	00:31:39,590	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	So indate can mean you just have your weights in indate, or indate can mean you actually do your math in indate. And doing your math in indate, the big gain that people care about is actually having your weights in indate, \N所以, Indate可能意味着你只是在Indate中拥有你的权重, 或者Indate可能意味着你实际上在Indate中做你的数学运算. 而在indate中做数学运算, 人们关心的最大收获是在indate中实际拥有你的权重、
EDL	00:31:39,590	00:31:51,035	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	because weights in indate mean less memory and less memory bandwidth, whereas the math, keep it in FB32. With on M1s, it doesn't matter what data type you're doing in the GPU. I'm not even sure it can do indate, \N因为indate中的权重意味着更少的内存和内存带宽, 而数学则保留在FB32中. 在M1上, 你在GPU中做什么数据类型并不重要. 我甚至不确定它是否能做indate、
EDL	00:31:51,035	00:31:58,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	but FB16 and FB32 is the same tariff ops. So yeah, no, that's one of the bounties. One of the bounties is get indate llama running\N但FB16和FB32是相同的关税操作. 所以, 是的, 不, 那是赏金之一. 其中一项任务是让indate llama运行. 
EDL	00:31:58,000	00:32:00,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: with the indate weights. \NSwyx:用indate权重. 
EDL	00:32:00,000	00:32:10,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: And then actually, what you could even do, if you really want to test this, just take the FB16 weights, convert them to indate, then convert them back to FB16, then compare the unconverted and converted.\N乔治：然后实际上, 你甚至可以做的是, 如果你真的想测试这个, 就把FB16的权重, 转换成indate, 然后再转换成FB16, 然后比较未转换和转换的. 
EDL	00:32:10,000	00:32:17,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Oh, that's a nice hack. Oh, yeah. Right, like- This should be lossless in the other direction. Yeah, I think FB16,\NSwyx: 哦, 这是个不错的黑客. 哦, 是的. 对, 就像--这应该是另一个方向上的无损的. 是的, 我认为FB16、
EDL	00:32:17,000	00:32:25,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: it should be lossless in the other direction. I'm actually not 100% about that. Why not? Oh, because like, you ever try to like, like if you want to represent, if it was like int16, it's not lossless.\N乔治：它应该是另一个方向的无损的. 实际上, 我对这一点不是百分之百. 为什么不呢? 哦, 因为你曾经试图像, 像如果你想表示, 如果它像int16, 它不是无损的. 
EDL	00:32:25,000	00:32:26,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Sure. \NSwyx: 当然. 
EDL	00:32:26,000	00:32:29,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: All of indate can be represented in FB16, but I'm not 100% about that.\N乔治：所有的indate都可以用FB16来表示, 但我不是百分之百相信. 
EDL	00:32:29,000	00:32:32,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Just drop the bytes. We just have to do it, right? \NSwyx: 丢掉这些字节就可以了. 我们只是要这样做, 对吗? 
EDL	00:32:32,000	00:32:47,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Just literally do it. There's only 256 to check, like. But yeah, either way, or I mean, int4, definitely. So do your int4, convert it back, and now see, even with int4 weights and FB32 math, like, okay, how much has your performance degraded this model?\N乔治：就按字面意思做吧. 只有256个要检查, 比如. 但是, 无论如何, 或者我的意思是, int4, 肯定是. 所以, 做你的int4, 把它转换回来, 现在看看, 即使有int4的权重和FB32的数学, 比如, 好的, 你的性能在这个模型中下降了多少? 
EDL	00:32:47,000	00:32:59,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: I think like the, you're planning to release the first tiny box, ship them in like two to six, eight months, something like that. What's top of mind for you in terms of building a team? Who should, who are you calling for? \NAlessio：我想, 就像, 你计划发布第一个小盒子, 在两到六个月, 八个月内发货, 类似这样的事情. 在建立一个团队方面, 你最关心的是什么? 谁应该, 你在找谁? 
EDL	00:32:59,000	00:33:09,760	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: So as the GPU is picked out and you're like, well, I could make that computer with the GPUs. And my answer is, can you? Do you know how hard it is to put six GPUs in a computer? And people think it's really easy. \N乔治：因此, 当GPU被挑选出来时, 你就会想, 好吧, 我可以用GPU做那台电脑. 而我的回答是, 你能吗? 你知道在一台电脑里放六个GPU有多难吗? 而人们认为这很容易. 
EDL	00:33:09,760	00:33:20,082	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And it's really easy to put one GPU in a computer. It's really easy to put two GPUs in a computer, but now you want to put in eight. Okay, so I'll tell you a few things about these GPUs. They take up four slots. \N在一台电脑里放一个GPU真的很容易. 在一台电脑上放两个GPU真的很容易, 但现在你想放八个. 好吧, 我告诉你一些关于这些GPU的事情. 它们占用了四个插槽. 
EDL	00:33:20,082	00:33:25,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	You can buy the nicest super micro. You can't put eight of those in there. You need two slot blowers. \N你可以买到最漂亮的超级微处理器. 你不能把八个这样的东西放在那里. 你需要两个插槽的吹风机. 
EDL	00:33:25,000	00:33:25,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: If you want to use one of those, \NSwyx：如果你想使用其中的一个、
EDL	00:33:25,000	00:33:31,666	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: those for you super micros, you need two slot blowers or water cooling, right? If you're trying to get the four slot cards in there, you're going to need some form of water cooling. \N乔治：那些为你的超级微机, 你需要两个插槽的吹风机或水冷, 对吗? 如果你想把四槽卡放进去, 你就需要某种形式的水冷. 
EDL	00:33:31,666	00:33:37,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	There are some like Chinese 40 nineties that are blowers, right? You have any blowers or water cooling if you're trying to get it in those things, right?\N有一些像中国的40个九十年代, 是吹风机, 对吗? 如果你想把它放在那些东西里, 你有任何鼓风机或水冷, 对吗? 
EDL	00:33:37,000	00:33:39,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: So are you doing water? \NSwyx：那么你在做水吗? 
EDL	00:33:39,000	00:33:50,572	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: No, I'm not using that chassis. Okay, so now you want to get six GPUs in a computer. So that's a big challenge. You're like, oh, I'll just use a PCIe extenders. I saw it online as tech tips. It works great. \N乔治：不, 我不使用那个底盘. 好吧, 那么现在你想在一台电脑里装上六个GPU. 所以这是一个很大的挑战. 你会想, 哦, 我就用一个PCIe扩展器吧. 我在网上看到了它的技术提示. 它的效果很好. 
EDL	00:33:50,572	00:34:01,499	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	No, it doesn't. Try PCIe extenders that work at PCIe 4.0 and interconnect bandwidth, super important. They don't work at 3.0. No PCIe extender I've tested, and I've bought 20 of them, works at PCIe 4.0. \N不, 不是这样的. 尝试PCIe扩展器, 在PCIe 4.0和互连带宽下工作, 超级重要. 他们不工作在3.0. 我测试过的PCIe扩展器, 我已经买了20个, 都不能在PCIe 4.0下工作. 
EDL	00:34:01,499	00:34:11,672	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	So you're going to need PCIe re-drivers. Now, okay, how much is that adding cost, right? Like these things all get really hard. And then tiny boxes, I've even had another constraint to it. \N因此, 你将需要PCIe重新驱动. 现在, 好吧, 这要增加多少成本, 对吗? 像这些东西都变得非常硬. 然后小盒子, 我甚至有另一个制约因素. 
EDL	00:34:11,672	00:34:24,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	I want this thing to be silent, not totally silent, but my limit is like 45, maybe 50 DB, but not super micro machine, 60 DB. We have a small, we have a compute cluster at comma. You gotta wear ear protection to go in there. Like-\N我希望这个东西是无声的, 不是完全无声的, 但是我的限制是像45, 也许50DB, 但不是超级微型机, 60DB. 我们有一个小的, 我们在逗号有一个计算集群. 你必须戴上护耳罩才能进去. 就像...
EDL	00:34:24,000	00:34:28,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Yeah, I've seen some videos where you give a tour. Oh yeah. It's noisy. It's super loud. \NSwyx: 是的, 我看过一些视频, 你在那里做了一个参观. 哦, 是的. 它很吵. 超级吵. 
EDL	00:34:28,000	00:34:38,385	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: You got all these machines just screaming. All those, like if you have a blower, what is that thing? 10,000 RPM, just screaming. Like I want to be able to use the normal big GPU fans \N乔治：你有所有这些机器只是尖叫. 所有这些, 比如你有一个鼓风机, 那是什么东西? 10,000转, 只是尖叫. 我希望能够使用普通的大GPU风扇
EDL	00:34:38,385	00:34:51,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	and make this thing so it can sit under your desk, plug into one outlet of power, right? Six GPUs, your GPUs are 350 Watts each. Can't plug that into a wall outlet. Okay, so how are you going to deal with that? Good questions, right?\N并使这个东西可以放在你的桌子下面, 插在一个电源插座上, 对吗? 六个GPU, 你的GPU每个是350瓦. 不能把它插入墙上的插座. 好吧, 那么你打算如何处理这个问题? 好问题, 对吗? 
EDL	00:34:51,000	00:34:52,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: And you're not sharing them. \NSwyx：而且你没有分享它们. 
EDL	00:34:52,000	00:35:00,286	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Well, that one, I mean, that one is pretty obvious. You have to limit the power on the GPUs, right? You have to limit the power on the GPUs. Now you can limit power on GPUs and still get, \N乔治：嗯, 那个, 我是说, 那个是很明显的. 你必须限制GPU的功率, 对吗? 你必须限制GPU上的功率. 现在你可以限制GPU的功率, 但仍然可以得到、
EDL	00:35:00,286	00:35:08,657	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	you can use like half the power and get 80% of the performance. This is a known fact about GPUs, but like that's one of my design constraints. So when you start to add all these design constraints, \N你可以使用一半的功率, 获得80%的性能. 这是一个关于GPU的已知事实, 但这是我的设计限制之一. 因此, 当你开始添加所有这些设计限制时, 你就会发现、
EDL	00:35:08,657	00:35:15,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	good luck building a tiny box yourself. Obviously it can be done, but you need something that has actually quite a bit of scale and resources to do it.\N祝你自己建造一个小盒子. 显然, 它可以做到, 但你需要一些实际上具有相当大的规模和资源的东西来做到这一点. 
EDL	00:35:15,000	00:35:21,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: And you see like the, under the desk, it's like one of the main use cases, kind of like individual developer use or. \N阿莱西奥：你看, 在桌子下面, 这就像是主要的使用案例之一, 有点像个人开发者的使用或. 
EDL	00:35:21,000	00:35:30,181	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Yeah, what I also see is more of a, like an AI hub for your home, right? As we start to get like home robotics kind of stuff, you don't want to put the inference on the robot, \N乔治：是的, 我还看到更多的是, 像你的家庭的人工智能中心, 对吗? 当我们开始得到像家庭机器人之类的东西时, 你不想把推理放在机器人上、
EDL	00:35:30,181	00:35:39,812	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	but you also don't want to put the inference on the cloud. Well, you don't want to put it on the robot because, okay, it's 1500 Watts, tiny box. You'll put batteries and charge them, bad idea. \N但你也不想把推理放在云端. 好吧, 你不想把它放在机器人上, 因为, 好吧, 它是1500瓦特, 小小的盒子. 你会放电池, 给它们充电, 坏主意. 
EDL	00:35:39,812	00:35:50,092	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Just wireless. Wireless is 0.5 milliseconds, right? This is super fast. You don't want to go to the cloud for two reasons. One, cloud's far away. Okay, it's not that far away. You can kind of address this. \N只是无线. 无线是0.5毫秒, 对吗? 这是超级快的. 你不想去云端, 有两个原因. 一, 云的距离很远. 好吧, 它不是那么远. 你可以在某种程度上解决这个问题. 
EDL	00:35:50,092	00:36:00,072	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	But two, cloud's also mad expensive. Like cloud GPUs are way more expensive than running that GPU at your house. At least any rates you're going to get, right? Maybe if you commit to buy, well, yeah, \N但是, 第二, 云计算的价格也很高. 就像云计算的GPU比在你家里运行GPU要贵得多. 至少你会得到任何费率, 对吗? 也许如果你承诺购买, 嗯, 是的、
EDL	00:36:00,072	00:36:12,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	I'm going to buy 10,000 GPUs for three years, then maybe the cloud will give you a good rate. But like, you want to buy one GPU in the cloud? I mean, okay, you can go to like vast, but like if you're going on Azure AWS, so that's expensive.\N我要买10000个GPU三年, 那么也许云计算会给你一个好的价格. 但是, 像你想在云端买一个GPU? 我的意思是, 好吧, 你可以去像广大, 但像如果你要在Azure AWS上, 所以这很昂贵. 
EDL	00:36:12,000	00:36:16,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: This is like a personal data center instead of a cloud data center. \NSwyx：这就像一个个人数据中心, 而不是一个云数据中心. 
EDL	00:36:16,000	00:36:20,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: We like the term compute cluster. So we can use NVIDIA GPUs. \N乔治：我们喜欢计算集群这个词. 所以我们可以使用NVIDIA的GPU. 
EDL	00:36:20,000	00:36:23,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Yeah, data centers may be a little bit dated. It's a compute cluster, \NSwyx：是的, 数据中心可能有点过时. 这是一个计算集群、
EDL	00:36:23,000	00:36:26,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: which is totally legal under the CUDA license agreement. \N乔治：这在CUDA许可协议下是完全合法的. 
EDL	00:36:26,000	00:36:32,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: You talk a lot about the PCIe connection. Do you think there's any fat there to trim? What do you mean? You're limited by bandwidth. \NSwyx: 你谈了很多关于PCIe连接的问题. 你认为那里有任何脂肪可以修剪吗? 你是什么意思? 你受到带宽的限制. 
EDL	00:36:32,000	00:36:41,616	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Okay, for some things, yes. So bandwidth is roughly 10x less than what you can get with NB-linked A100s, right? NB-linked A100s are going to have, and then you can even get like full fabric \N乔治：好的, 对于某些事情来说, 是的. 所以, 带宽大约比你用NB-linked A100s得到的少10倍, 对吗? NB-linked A100s会有, 然后你甚至可以得到像全结构的
EDL	00:36:41,616	00:36:51,183	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	and NVIDIA really pushes on that stuff, 600 gigabytes per second, right? And PCIe, four, you're going to get 60, right? So you're getting 10x less. That said, why do you need the bandwidth, right? \N英伟达在这方面做得很好, 每秒600千兆字节, 对吗? 而PCIe, 4个, 你将得到60个, 对吗? 所以你得到的是10倍以下. 这就是说, 你为什么需要带宽, 对吗? 
EDL	00:36:51,183	00:37:01,576	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And the answer is you need it for training huge models. If you're training on a tiny box, your limit's going to be about 7 billion. If you're training on big stuff, your limit's going to be like 70 billion, right? \N答案是你需要它来训练巨大的模型. 如果你在一个小盒子上训练, 你的极限是70亿. 如果你在大的东西上训练, 你的限制将是700亿, 对吗? 
EDL	00:37:01,576	00:37:13,912	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Okay, you can hack it to get a bit higher. You can hack it, like GPT hacked it to get a bit higher, but like that 65 billion in LLAMA, like there's a reason they chose 65 billion, right? And that's what can reasonably fit model parallel on a GPU, right? \N好吧, 你可以黑掉它, 让它变得更高一点. 你可以黑掉它, 就像GPT黑掉它以获得更高一点, 但就像LLAMA中的650亿一样, 他们选择650亿是有原因的, 对吗? 这就是在GPU上能够合理地适合模型并行的东西, 对吗? 
EDL	00:37:13,912	00:37:23,771	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	So yes, you are going to end up training models. The cap's going to be like 7 billion, but I actually heard this on your podcast. I don't think that the best chatbot models are going to be the big ones. \N所以, 是的, 你最终要去训练模型. 上限将是70亿, 但实际上我在你的播客中听到了这个. 我不认为最好的聊天机器人模型会是大型的. 
EDL	00:37:23,771	00:37:33,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	I think the best chatbot models are going to be the ones where you had a thousand training runs instead of one. And I don't think that the interconnect bandwidth is going to matter that much.\N我认为最好的聊天机器人模型将是那些你有一千次训练而不是一次训练的模型. 我认为互连带宽并不重要. 
EDL	00:37:33,000	00:37:41,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: So what are we optimizing for instead of compute optimal? What do you mean compute optimal? You're talking about this, the LLAMA style models where you train for like 200x. You train longer, yeah.\NSwyx：那么我们要优化什么, 而不是计算最优? 什么叫计算优化? 你说的是这个, LLAMA风格的模型, 你要训练200倍的时间. 你训练的时间更长, 是的. 
EDL	00:37:41,000	00:37:49,817	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Yeah, yeah, yeah. You can always make your model better by doing one of two things, right? And a comma, we just have a strict limit on it. You can always make your model better by training longer, \N乔治：是的, 是的, 是的. 你总是可以通过做两件事中的一件使你的模型变得更好, 对吗? 还有一个逗号, 我们只是对它有一个严格的限制. 你总是可以通过训练更长的时间使你的模型变得更好、
EDL	00:37:49,817	00:37:59,150	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	and you can always make your model better by making it bigger. But these aren't the interesting ones, right? Particularly the making it bigger because training it longer, fine. You're getting a better set of weights. \N和你总是可以通过使你的模型变得更大来使它变得更好. 但这些都不是有趣的, 对吗? 特别是让它变大, 因为训练时间更长, 很好. 你会得到一组更好的权重. 
EDL	00:37:59,150	00:38:08,655	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	The inference is the same. The inference is the same whether I trained it for a day or a week. Okay, if it's 1 billion versus 10 billion, well, I 10x my inference too, right? So I think that these big models are kind of, \N推理是一样的. 无论我训练一天还是一周, 推论都是一样的. 好吧, 如果是10亿对100亿, 好吧, 我的推断也是10倍, 对吗? 所以我认为这些大模型是一种、
EDL	00:38:08,655	00:38:13,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	sure, they're great if you're research labs and you're trying to like max out this hypothetical thing.\N当然, 如果你是研究实验室, 你想把这个假设的事情做到极致, 它们是很好的. 
EDL	00:38:13,000	00:38:15,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Which you can talk about later. Yeah, yeah, yeah. \NSwyx: 你可以稍后再谈这个问题. 对, 对, 对. 
EDL	00:38:15,000	00:38:22,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: But if you're like a startup or you're like an individual or you're trying to deploy this to the edge anywhere, you don't need that many weights. \N乔治：但是如果你是一个初创公司, 或者你是一个人, 或者你想把这个东西部署到任何地方的边缘, 你不需要那么多重量. 
EDL	00:38:22,000	00:38:29,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Yeah, yeah. You actually don't want that many weights. Optimizing for inference rather than capabilities doing benchmarks. Yes. \NSwyx：是的, 是的. 你实际上不需要那么多的权重. 优化推理而不是做基准的能力. 是的. 
EDL	00:38:29,000	00:38:37,435	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: And I think the inference thing, right? There's gonna be so much more. Right now, the ratio between like training and inference on clouds, I think it's only still, I think it's like two or three X, right? \N乔治：我认为推理的事情, 对吗? 会有这么多. 现在, 在云上的训练和推理之间的比例, 我认为它只是仍然, 我认为它是像2或3 X, 对吗? 
EDL	00:38:37,435	00:38:41,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	It's two or three X more inference, which doesn't make any sense. It's way more inference. \N这是两到三倍的推理, 这没有任何意义. 它是更多的推论. 
EDL	00:38:41,000	00:38:42,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Yeah. \NSwyx：是的. 
EDL	00:38:42,000	00:38:52,250	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: There should be 10 to 100 X more inference in the world than training. But then also like, what is training, right? You start to see these things like LoRa, like it's kind of blurring the lines between inference and training. \N乔治：世界上应该有比训练多10到100倍的推理. 但是, 也像, 什么是培训, 对吗? 你开始看到像LoRa这样的东西, 就像它有点模糊了推理和训练之间的界限. 
EDL	00:38:52,250	00:39:02,851	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And I think that that blurred line is actually really good. I'd like to see much more like on-device training or on-device fine tuning of the final layer. We're pushing toward this stuff at Comma, right? Like why am I shipping a fixed model? \N我认为, 这种模糊的界限实际上是非常好的. 我希望看到更多的像设备上的训练或最终层的设备上的微调. 我们在Comma正在推动这些东西, 对吗? 比如我为什么要运送一个固定的模型? 
EDL	00:39:02,851	00:39:11,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	I totally want this model to fine tune based on like how your left tire is flat, right? Every time you cut the same turn because your left tire is flat, well, it should learn that, right?\N我完全希望这个模型能够根据你的左轮胎是如何爆胎的来进行微调, 对吗? 每次你因为左轮胎没气而转弯时, 它就应该学会这个, 对吗? 
EDL	00:39:11,000	00:39:16,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: So would Comma pursue parameter efficient fine tuning? Yeah. \NSwyx：那么Comma会不会追求参数的高效微调? 是的. 
EDL	00:39:16,000	00:39:22,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: We're looking into stuff like that. I mean, Comma is already very parameter efficient because we have to like run this thing in a car and you have to like cool it and power it. \N乔治：我们正在研究这样的东西. 我的意思是, Comma已经是非常高效的参数了, 因为我们必须把这个东西放在车里运行, 你必须把它冷却, 给它供电. 
EDL	00:39:22,000	00:39:33,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: And so this kind of like intelligence cluster you have in your home, you see when the person is using third-party model, they load them locally and kind of do the final fine tuning. It kind of stays within the box. \N阿莱西奥：所以这种像你家里的智能集群, 你看到当人们使用第三方模型时, 他们在本地加载它们, 并做最后的微调. 它是在盒子里的. 
EDL	00:39:33,000	00:39:45,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: I think that that's one version of it for the privacy conscious. I also see a world where you can have your tiny box in its down cycles, mine flop coin, right? You know, it turns out not all crypto is a scam. \N乔治：我认为这是对隐私意识的一个版本. 我还看到一个世界, 你可以让你的小盒子在它的下降周期中, 我翻转硬币, 对吗? 你知道, 事实证明, 并非所有的加密货币都是骗局. 
EDL	00:39:45,000	00:39:46,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: There's one way to tell if crypto is a scam. \NSwyx：有一个方法可以判断加密货币是否是一个骗局. 
EDL	00:39:46,000	00:39:49,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: If they're selling the coin before they make the product, \N乔治：如果他们在制造产品之前就出售硬币、
EDL	00:39:49,000	00:39:49,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: it's a scam. \NSwyx：这就是一个骗局. 
EDL	00:39:49,000	00:39:58,260	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: If they have the product and then they sell the coin, it's maybe not a scam, right? So yeah, my thought is like each tiny box would let you, would have a private key on it. And you have to do it this way. \N乔治：如果他们有了产品, 然后再卖币, 也许就不是骗局了, 对吗? 所以, 我的想法是, 每个小盒子都会让你, 有一个私钥在上面. 而且你必须这样做. 
EDL	00:39:58,260	00:40:01,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	You can't just let anyone join because of Sybil attacks, right? \N你不能让任何人加入, 因为有Sybil攻击, 对吗? 
EDL	00:40:01,000	00:40:01,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: There's a real problem of like, \NSwyx：有一个真正的问题, 那就是像、
EDL	00:40:01,000	00:40:08,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: how do I ensure your data is correct? And the way that I ensure your data is correct on the tiny net is if you ever send wrong data, you're banned from the network for life. \N乔治：我怎样才能确保你的数据是正确的? 而我确保你的数据在小网上是正确的方法是, 如果你发送错误的数据, 你将被终身禁止进入网络. 
EDL	00:40:08,000	00:40:09,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Yeah. \NSwyx：是的. 
EDL	00:40:09,000	00:40:11,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Your $15,000 hardware box is banned.\N乔治：你的15,000美元的硬件盒子被禁止使用. 
EDL	00:40:11,000	00:40:11,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: So, you know, don't cheat. \NSwyx：所以, 你知道, 不要作弊. 
EDL	00:40:11,000	00:40:14,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Obviously if it messes up, we'll forgive you. \N乔治：显然, 如果它搞砸了, 我们会原谅你. 
EDL	00:40:14,000	00:40:17,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Somebody's going to try to jailbreak your devices. There's no jailbreak. \NSwyx：有人会试图对你的设备进行越狱. 没有越狱. 
EDL	00:40:17,000	00:40:18,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: There's no jailbreak. \N乔治：没有越狱. 
EDL	00:40:18,000	00:40:19,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: It's just a different network. \NSwyx：这只是一个不同的网络. 
EDL	00:40:19,000	00:40:23,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Well, there's just a private key on ea ch device, right? Like if you buy a tiny box from the tiny corp, \N乔治：嗯, 只是有一个私钥在ea ch设备上, 对吗? 就像你从小公司买了一个小盒子、
EDL	00:40:23,000	00:40:23,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: I give you a private key. \NSwyx：我给你一个私钥. 
EDL	00:40:23,000	00:40:29,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: It's in my backend server, right? You want to hack my server, that's illegal. Anything you want to do on the device, the device is yours. My server's mine, right? \N乔治：它在我的后台服务器里, 对吗? 你想入侵我的服务器, 那是非法的. 你想在设备上做什么, 设备就是你的. 我的服务器是我的, 对吗? 
EDL	00:40:29,000	00:40:33,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Yeah. Have you looked into like a federated training at all? \N你有没有研究过联盟式培训? 
EDL	00:40:33,000	00:40:37,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Okay. There's orders of magnitude of federated training. You mean like over the cloud and stuff? \N乔治：好的. 有数量级的联合培训. 你是说通过云计算之类的? 
EDL	00:40:37,000	00:40:41,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Over the internet? Yeah. Over the internet, but also distributed on a bunch of devices, right? \NSwyx: 在互联网上? 是的. 在互联网上, 但也分布在一堆设备上, 对吗? 
EDL	00:40:41,000	00:40:51,320	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Yeah, I'm very bearish on this stuff. Because your interconnect bandwidth, right? So, okay. At the high end, you have your interconnect bandwidth of NVLink, which is 600 gigabytes per second, right? \N乔治：是的, 我对这个东西非常看淡. 因为你的互连带宽, 对吗? 所以, 好吧. 在高端, 你有NVLink的互连带宽, 它是每秒600千兆字节, 对吗? 
EDL	00:40:51,320	00:41:01,491	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	The tiny box has 60 gigabytes per second. And then your internet has 125 megabytes per second, right? Not gigabits, 125 megabytes, right? So, okay. That's how many orders of magnitude we're talking here? \N这个小盒子有每秒60千兆字节. 然后你的互联网有每秒125兆字节, 对吗? 不是千兆字节, 是125兆字节, 对吗? 所以, 好吧. 这就是我们在这里谈论的多少个数量级的问题? 
EDL	00:41:01,491	00:41:12,958	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Like from 60 down to 125? Like, all right, that's over a hundred X. That's 400 X, right? So like, what you can do is inference, right? Like there's, for inference, you don't care, right? For inference, there's so little bandwidth \N比如从60到125? 就像, 好吧, 那是超过100X, 那是400X, 对吗? 所以, 你可以做的是推理, 对吗? 比如说, 对于推理, 你不在乎, 对吗? 对于推理, 有这么少的带宽
EDL	00:41:12,958	00:41:23,528	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	at the top and the bottom of the model that like, yeah, you can do federated inference, right? And that's kind of what I'm talking about. There's also interesting things to push into, like you're like, but okay, \N在模型的顶部和底部, 就像, 是的, 你可以做联合推理, 对吗? 这就是我所说的. 还有一些有趣的东西可以推入, 比如你喜欢, 但是好吧、
EDL	00:41:23,528	00:41:34,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	what if you want to run closed source models? This stuff gets kind of interesting, like using TPMs on the boxes and stuff. But then someone might jailbreak my device. So, you know, maybe we don't try to do that.\N如果你想运行闭源模型呢? 这东西变得有点有趣, 比如在盒子上使用TPM之类的东西. 但是, 有人可能会对我的设备进行越狱. 所以, 你知道, 也许我们不会尝试这样做. 
EDL	00:41:34,000	00:41:39,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: Yeah, what's like the enterprise use case? Do you see companies buying a bunch of these and like stacking them together? \N阿莱西奥：是的, 企业的使用情况是怎样的? 你是否看到公司买了一堆这样的东西并把它们堆在一起? 
EDL	00:41:39,000	00:41:49,005	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: The tiny box is like the first version of what we're building. But what I really want to do is be on the absolute edge of flops per dollar and flops per watt. These are the two numbers that matter. \N乔治：这个小盒子是我们正在建造的第一个版本. 但我真正想做的是在每美元的运算量和每瓦的运算量方面处于绝对优势. 这是两个重要的数字. 
EDL	00:41:49,005	00:41:56,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	So the enterprise use case is you want to train, like Kama, right? So Kama just built out a new compute cluster. It's about a person and a half. \N因此, 企业的用例是你想训练, 像Kama, 对吗? 所以Kama刚刚建立了一个新的计算集群. 这大约是一个半人. 
EDL	00:41:56,000	00:41:58,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: A person being 20 petaflops.\NSwyx：一个人是20 petaflops. 
EDL	00:41:58,000	00:42:08,750	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: A person is 20 petaflops. It's about 30 petaflops. We built out a little compute cluster and, you know, we paid double what you theoretically could per flop, right? You theoretically could pay half per flop \N乔治：一个人是20 petaflops. 这大约是30 petaflops. 我们建立了一个小的计算集群, 你知道, 我们支付的费用是理论上每跳的两倍, 对吗? 理论上, 如果你设计了一堆定制的东西, 你可以支付每一跳的一半费用
EDL	00:42:08,750	00:42:21,150	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	if you designed a bunch of custom stuff. And yeah, I mean, I could see that being, you know, a tiny corp. Kama's going to be the first customer. I'm going to build a box for Kama and then I'm going to show off the box I built for Kama and be like, \N如果你设计了一堆定制的东西. 是的, 我的意思是, 我可以看到, 你知道, 一个小公司. 卡玛将是第一个客户. 我将为卡玛建造一个盒子, 然后我将展示我为卡玛建造的盒子, 就像、
EDL	00:42:21,150	00:42:26,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	okay, like, do you want to build? I sell $250,000 training computers. Or how much is one H100 box?\N好的, 比如, 你想造吗? 我卖25万美元的培训电脑. 或者说一个H100盒子多少钱? 
EDL	00:42:26,000	00:42:27,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: It's 400 grand?\NSwyx：要40万? 
EDL	00:42:27,000	00:42:35,829	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Okay, I'll build you a 400 grand training computer and it'll be 10x better than that H100 box. Again, not for every use case. For some, you need the interconnect bandwidth. \N乔治：好吧, 我给你造一台40万的培训电脑, 它将比那台H100盒子好10倍. 同样, 并不是所有的使用情况都适用. 对于一些人来说, 你需要互连带宽. 
EDL	00:42:35,829	00:42:41,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	But for 90% of most companies' model training use cases, the tiny box will be 5x faster for the same price.\N但是对于大多数公司的90%的模型培训用例来说, 这个小盒子在同样的价格下会快5倍. 
EDL	00:42:41,000	00:42:47,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: You mentioned the person of compute. How do we build a human for $20 million?\N阿莱西奥：你提到了计算的人. 我们如何用2000万美元建造一个人呢? 
EDL	00:42:47,000	00:42:54,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Well, it's a lot cheaper now. So like I said, Kama spent about half a million on our person and a half, so. \N乔治：嗯, 现在便宜多了. 所以就像我说的, 卡玛在我们的人身上花了大约50万, 所以. 
EDL	00:42:54,000	00:43:03,832	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: What are some of the numbers people should think of when they compare compute to like people? So GPT-4 was 100 person years of training. That's more like on the timescale. \N阿莱西奥：当人们在比较计算和像人的时候, 应该想到一些什么数字? 所以GPT-4是100人年的培训. 这更像是在时间尺度上. 
EDL	00:43:03,832	00:43:16,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	20 petaflops is one person. I think you, right now the math was that for the price of the most expensive thing we build, which is the International Space Station, we could build one Tampa of. Yeah, yeah, one Tampa of compute.\N20 petaflops是一个人. 我想你, 现在的计算是, 对于我们建造的最昂贵的东西, 也就是国际空间站的价格, 我们可以建造一个坦帕的. 是的, 是的, 一个坦帕的计算量. 
EDL	00:43:16,000	00:43:20,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Yeah, which is the ultimate currency of measurement. \NSwyx：是的, 这是衡量的最终货币. 
EDL	00:43:20,000	00:43:28,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Yeah, yeah, we could build. So like the biggest training clusters today, I know less about how GPT-4 was trained. I know some rough numbers on the weights and stuff, but Lama-\N乔治：是的, 是的, 我们可以建立. 因此, 像今天最大的训练集群, 我对GPT-4是如何训练的了解较少. 我知道一些关于权重之类的粗略数字, 但是Lama-
EDL	00:43:28,000	00:43:30,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: A trillion parameters? \NSwyx：一万亿个参数? 
EDL	00:43:30,000	00:43:38,882	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Well, okay, so GPT-4 is 220 billion in each head, and then it's an eight-way mixture model. So mixture models are what you do when you're out of ideas. So, you know, it's a mixture model. \N乔治：嗯, 好的, 所以GPT-4每个头都是2200亿, 然后它是一个八路的混合模型. 所以混合模型是当你没有想法的时候才会做的. 所以, 你知道, 这是一个混合模型. 
EDL	00:43:38,882	00:43:45,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	They just train the same model eight times, and then they have some little trick. They actually do 16 inferences, but no, it's not like-\N他们只是训练同一个模型八次, 然后他们有一些小技巧. 
EDL	00:43:45,000	00:43:49,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: So the multimodality is just a vision model kind of glommed on? \NSwyx：所以多模态只是一种视觉模型, 是一种粘附在上面的? 
EDL	00:43:49,000	00:43:57,417	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: I mean, the multimodality is like obvious what it is too. You just put the vision model in the same token space as your language model. Oh, did people think it was something else? \N乔治：我的意思是, 多模态也是显而易见的, 它是什么. 你只是把视觉模型和你的语言模型放在同一个标记空间里. 哦, 人们是否认为这是别的东西? 
EDL	00:43:57,417	00:44:06,238	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	The mixture has nothing to do with the vision or language aspect of it. It just has to do with, well, okay, we can't really make models bigger than 220 billion parameters. We want it to be better. \N这种混合与视觉或语言方面无关. 它只是与, 好吧, 好吧, 我们不能真的使模型大于2200亿个参数. 我们想让它变得更好. 
EDL	00:44:06,238	00:44:13,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Well, how can we make it better? Well, we can train it longer, and okay, we've actually already maxed that out. We're getting diminishing returns there.\N那么, 我们怎样才能使它更好呢? 好吧, 我们可以训练它更长的时间, 好吧, 我们实际上已经达到了极限. 我们得到的回报越来越少了. 
EDL	00:44:13,000	00:44:14,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Okay. A mixture of experts. \NSwyx: 好的. 一个专家的混合物. 
EDL	00:44:14,000	00:44:16,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Yeah, a mixture of experts. We'll train eight of them, right? \N乔治：是的, 专家的混合物. 我们将培训八个人, 对吗? 
EDL	00:44:16,000	00:44:17,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: So, all right. \NSwyx：那么, 好吧. 
EDL	00:44:17,000	00:44:28,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: So, you know, the real truth is whenever a start, whenever a company is secretive, it's because they're hiding something that's not that cool. And people have this wrong idea over and over again that they think they're hiding it because it's really cool. \N乔治：所以, 你知道, 真正的事实是, 每当一个开始, 每当一个公司是秘密的, 那是因为他们隐藏了一些不那么酷的东西. 而人们一次又一次地有这样的错误想法, 他们认为他们隐藏它是因为它真的很酷. 
EDL	00:44:28,000	00:44:29,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: It must be amazing. \NSwyx：它一定很神奇. 
EDL	00:44:29,000	00:44:37,796	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: It's a trillion parameters. No, it's a little bigger than GPT-3, and they did an eight-way mixture of experts. Like, all right, dude, anyone can spend eight times the money and get that. \N乔治：这是一个万亿的参数. 不, 它比GPT-3大一点, 他们做了一个八方专家的混合. 就像, 好吧, 伙计, 任何人都可以花八倍的钱来得到这个. 
EDL	00:44:37,796	00:44:47,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Coming back to what I think is actually gonna happen is, yeah, people are gonna train smaller models for longer and fine-tune them and find all these tricks. OpenAI used to publish stuff on this, you know,\N回到我认为实际会发生的事情, 是的, 人们会对较小的模型进行更长时间的训练, 并对它们进行微调, 找到所有这些技巧. OpenAI曾经发表过这方面的东西, 你知道、
EDL	00:44:47,000	00:44:48,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: when they would publish stuff \NSwyx：当他们发表东西时
EDL	00:44:48,000	00:45:00,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: about how much better the training has gotten holding compute constant. It's gotten a lot better, right? Think, compare like BatchNorm to NoBatchNorm. \N乔治：关于在计算量不变的情况下, 训练的效果有多好. 它已经变得更好了, 对吗? 想一想, 就像BatchNorm和NoBatchNorm的比较. 
EDL	00:45:00,000	00:45:02,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Is you're finding algorithms like FlashAttention? \NSwyx: 你发现像FlashAttention这样的算法吗? 
EDL	00:45:02,000	00:45:11,054	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Yeah, well, FlashAttention, yeah. And FlashAttention is the same compute. FlashAttention is an interesting fact where it's actually the identical compute. It's just a more efficient way to do the compute. \N乔治：是的, 嗯, FlashAttention, 是的. 而FlashAttention也是同样的计算. FlashAttention是一个有趣的事实, 它实际上是相同的计算. 它只是用一种更有效的方式来做计算. 
EDL	00:45:11,054	00:45:19,684	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	But I'm even talking about like, look at the new embeddings people are using, right? They used to use these like boring old embeddings. Now, like, Lama uses that complex one, and now there's like Alibi. \N但我甚至在谈论像, 看看人们正在使用的新嵌入物, 对吗? 他们过去使用的是这些无聊的旧嵌入. 现在, 比如说, Lama用的是那个复杂的嵌入, 现在又有了Alibi. 
EDL	00:45:19,684	00:45:23,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	I'm not up-to-date on all the latest stuff, but those tricks give you so much. \N我并不了解所有最新的东西, 但这些技巧给了你很多. 
EDL	00:45:23,000	00:45:29,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: There's been a whole round trip with positional embeddings. I don't know if you've seen this discussion. I haven't followed exactly. \NSwyx: 有一个关于位置嵌入的完整旅程. 我不知道你是否看到过这个讨论. 我还没有完全跟上. 
EDL	00:45:29,000	00:45:38,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: I mean, you quickly run into the obvious problem with positional embeddings, which is you have to invalidate your KV cache if you run off the context. So that's why I think these new ones, \N乔治：我的意思是, 你很快就会遇到位置嵌入的明显问题, 那就是如果你脱离了上下文, 你就必须使你的KV缓存失效. 所以这就是为什么我认为这些新的、
EDL	00:45:38,000	00:45:38,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: they're playing with them, \NSwyx：他们在玩这些东西、
EDL	00:45:38,000	00:45:43,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: but I'm not an expert on like the latest up-to-date language model stuff. \N乔治：但我不是一个专家, 像最新的最新的语言模型的东西. 
EDL	00:45:43,000	00:45:53,259	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: What are some of the things, I mean, that people are getting wrong? So back to autonomous driving, there was like the whole like LiDAR versus vision thing. People don't get into accidents because they cannot see well. \N阿莱西奥：我的意思是, 有哪些事情是人们搞错了的? 所以回到自动驾驶, 有整个像LiDAR与视觉的事情. 人们发生事故并不是因为他们看不清楚. 
EDL	00:45:53,259	00:45:59,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	They get into accidents because they get distracted and all these things. Do you see similarities today on like the Pathway GI? \N他们发生事故是因为他们分心和所有这些事情. 你今天看到Pathway GI上的相似之处了吗? 
EDL	00:45:59,000	00:46:03,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Nothing I say about this is ever gonna compete with how Rich Sutton stated it. \N乔治：我所说的一切都无法与里奇-萨顿所说的竞争. 
EDL	00:46:03,000	00:46:04,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Rich Sutton, the writer of \NSwyx：里奇-萨顿, 《中国青年报》的作者. 
EDL	00:46:04,000	00:46:13,974	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Reinforcement Learning, The Bitter Lesson. Nothing I say is ever gonna compete with, The Bitter Lesson's way better than any way I'm going to phrase this. Just go read that, and then like, I'm sorry it's bitter, \N乔治：强化学习, 痛苦的一课. 我说什么都比不上《苦涩的一课》, 《苦涩的一课》比我的任何措辞都要好. 只要去读一读, 然后就像, 我很抱歉它是苦的、
EDL	00:46:13,974	00:46:22,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	but you actually just have to believe it. Like over and over again, people make this mistake. They're like, oh, we're gonna hand engineer this thing. No, like stop wasting time. \N但你实际上必须相信它. 就像一次又一次, 人们犯了这个错误. 他们想, 哦, 我们要用手来设计这个东西. 不, 不要再浪费时间了. 
EDL	00:46:22,000	00:46:27,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: I mean, OpenAI is not taking The Bitter Lesson. They were leaders in deep learning for a long, long, long time. \NSwyx：我的意思是, OpenAI没有接受《苦难的教训》. 他们在深度学习领域领先了很久、很久、很长一段时间. 
EDL	00:46:27,000	00:46:31,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Well, OpenAI was the absolute leader to the thesis that compute is all you need, right? \N乔治：好吧, OpenAI是 "计算是你所需要的一切 "这一论点的绝对领导者, 对吗? 
EDL	00:46:31,000	00:46:32,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: And there's a question of how long \NSwyx：而且有一个问题, 就是在多长时间内
EDL	00:46:32,000	00:46:44,261	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: this thesis is going to continue for. It's a cool thesis, and look, I think I would be lying along with everybody else. I was into language models like way back in the day for the Hutter Prize. I got into AI through the Hutter Prize. \N乔治：这个论题会持续多久. 这是一个很酷的论文, 听着, 我想我也会和其他人一样说谎. 我是为了胡特奖而进入语言模型的, 就像当年一样. 我是通过胡特奖进入人工智能的. 
EDL	00:46:44,261	00:46:55,762	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Like 2014, I'm trying to build compressive models of Wikipedia. And I'm like, okay, why is this so hard? What this is is a language model, right? And I'm playing with these Bayesian things, and I'm just like, oh, but I get it. \N就像2014年, 我正试图建立维基百科的压缩模型. 我想, 好吧, 为什么这这么难? 这就是一个语言模型, 对吗? 我在玩这些贝叶斯的东西, 我只是想, 哦, 但我明白了. 
EDL	00:46:55,762	00:47:07,364	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	I have two data points, and they're almost the same, but how do I measure that almost, right? I just wrapped my head around this, and this was around the time Karpathy released the first RNN that generated the Shakespeare stuff. \N我有两个数据点, 它们几乎是一样的, 但我如何衡量这个几乎, 对吗? 我只是把我的头绕了一圈, 这大约是Karpathy发布第一个生成莎士比亚的RNN的时候. 
EDL	00:47:07,364	00:47:18,156	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And I'm like, okay, I get it, right? It's neural networks that are compressors. Now, this isn't actually, you can't actually win the Hutter Prize with these things because the Hutter Prize is MDL. It's the model, \N我就想, 好吧, 我明白了, 对吗? 这是神经网络, 是压缩器. 现在, 这实际上不是, 你实际上不能用这些东西赢得哈特奖, 因为哈特奖是MDL. 它是模型、
EDL	00:47:18,156	00:47:29,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	size of the model plus the size of the encodings, embeddings. So yeah, you can't, I mean, probably now you can because it's gotten so good. But yeah, back in the day, you kind of couldn't. So I was like, okay, cool.\N模型的大小加上编码的大小, 嵌入的大小. 所以, 是的, 你不能, 我的意思是, 可能现在你可以, 因为它已经变得如此之好. 但是, 在过去, 你不能这样做. 所以我当时想, 好吧, 好吧. 
EDL	00:47:29,000	00:47:29,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: This is what it is. \NSwyx：这就是它. 
EDL	00:47:29,000	00:47:40,422	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: I kind of get it. I didn't expect that it would continue to work this well. I thought there'd be real limits to how good autocomplete could get. That's fancy autocomplete. But yeah, it works well. \N乔治：我有点明白了. 我没有想到它能继续这么好地工作. 我以为自动完成的效果会有很大的限制. 那是花哨的自动完成. 但是, 是的, 它工作得很好. 
EDL	00:47:40,422	00:47:48,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	So like, yeah, what is OpenAI getting wrong? Technically, not that much. I don't know. If I was a researcher, why would I go work there? \N那么, 是的, OpenAI有什么问题吗? 从技术上讲, 没有那么多. 我不知道. 如果我是一个研究人员, 我为什么要去那里工作? 
EDL	00:47:48,000	00:47:51,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Yes, so why is OpenAI like the Miami Heat? \NSwyx：是的, 那么为什么OpenAI像迈阿密热火队一样? 
EDL	00:47:51,000	00:48:01,734	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: No, look, this is my technical stuff. I don't really want to harp on this, but like, why go work at OpenAI when you could go work at Facebook as a researcher? OpenAI can keep ideologues who, you know, \N乔治：不, 听着, 这是我的技术东西. 我真的不想在这个问题上纠缠, 但就像, 如果你可以去Facebook做研究员, 为什么要去OpenAI工作? OpenAI可以留住那些意识形态的人, 你知道、
EDL	00:48:01,734	00:48:08,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	believe ideological stuff and Facebook can keep every researcher who's like, dude, I just want to build AI and publish it. \N而Facebook则可以留住所有的研究人员, 他们只是想建立人工智能并发表它. 
EDL	00:48:08,000	00:48:11,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: Yeah, any other thoughts, tiny corp, bounties? \NAlessio：是的, 还有其他想法吗, 小公司, 赏金? 
EDL	00:48:11,000	00:48:20,854	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: You know, I've been thinking a lot about like what it means to hire in today's world. Okay, look, I'm a believer that machines are going to replace everything in about 20 years. \N乔治：你知道, 我一直在想, 在今天的世界里, 雇佣意味着什么. 好吧, 听着, 我相信机器将在20年内取代一切. 
EDL	00:48:20,854	00:48:30,920	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	So, okay, what is that thing that people can still do that computers can't? And this is a narrowing list, but like, you know, back in the day, like imagine I was starting a company in 1960. \N那么, 好吧, 什么事情是人们仍然可以做而计算机不能做的? 这是一个缩小的清单, 但就像, 你知道, 在过去的日子里, 就像想象我在1960年创办一家公司. 
EDL	00:48:30,920	00:48:41,675	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Oh, and we're going to have to hire a whole bunch of calculators in the basement to do all the, you know, math to support the, dude, have you heard about computers? Why don't we just buy a few of those? \N哦, 我们将不得不在地下室雇用一大堆计算器来做所有的, 你知道, 数学来支持, 伙计, 你听说过计算机吗? 我们为什么不买几台呢? 
EDL	00:48:41,675	00:48:50,416	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Oh, wow, man, you're right. So like, I feel like that's kind of happening again. And I'm thinking about, I will post in my Discord, I'll be like, who wants to like, \N哦, 哇, 伙计, 你是对的. 所以, 我觉得这种情况又在发生. 而且我在想, 我会在我的Discord里发帖, 我会像, 谁愿意喜欢、
EDL	00:48:50,416	00:48:59,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	okay, I just changed my unary ops used to be log and exp in like E. I changed them to be log two and exp two because hardware has log two and exp two accelerators.\N好的, 我刚刚改变了我的单线操作, 以前是Log和Exp, 就像E, 我把它们改成了Log 2和Exp 2, 因为硬件有Log 2和Exp 2加速器. 
EDL	00:48:59,000	00:49:00,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Yeah, and of course you can just change your base. \NSwyx: 是的, 当然你也可以直接改变你的基础. 
EDL	00:49:00,000	00:49:08,250	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: It's one multiply to get it back to E. But like, I made the primitives log two and exp two, right? I just posted in the Discord. I'm like, could someone put this pull request up? \N乔治：这是让它回到E的一个乘法. 但就像, 我把基元变成了对数二和指数二, 对吗? 我刚刚在讨论区发了帖子. 我想, 谁能把这个拉动请求放上去? 
EDL	00:49:08,250	00:49:12,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And someone eventually did and I merged it. But I'm like, this is almost to the level \N最终有人做了, 我把它合并了. 但我想, 这几乎达到了以下水平
EDL	00:49:12,000	00:49:14,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: where models can do it. \NSwyx：模型可以做到这一点. 
EDL	00:49:14,000	00:49:17,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: We're almost to the point where I can say that to a model and the model can do it. \N乔治：我们几乎到了我可以对模型说, 而模型可以做的地步了. 
EDL	00:49:17,000	00:49:20,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Have you tried? Yeah, I don't know. \NSwyx：你试过吗? 是的, 我不知道. 
EDL	00:49:20,000	00:49:32,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: I think autocomplete went further than I thought it would, but I'm also relatively unimpressed with these chatbots. The problem is if your loss function is categorical cross entropy on the internet, your responses will always be mid. \N乔治：我认为自动完成比我想象的要更进一步, 但我对这些聊天机器人也相对没有印象. 问题是, 如果你的损失函数是互联网上的分类交叉熵, 那么你的回应将永远是中. 
EDL	00:49:32,000	00:49:35,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Yes, mode collapse is what I call it, I don't know. \NSwyx：是的, 模式崩溃是我所说的, 我不知道. 
EDL	00:49:35,000	00:49:45,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Maybe, I'm not even talking about mode collapse. You're actually trying to predict the, like, look, I rap. I'm a hobbyist rapper. When I try to get these things to write rap, the raps sound like the kind of raps you read in the YouTube comments. \N乔治：也许吧, 我根本不是在谈论模式崩溃. 你实际上是在试图预测, 比如, 看, 我说唱. 我是一个爱好说唱的人. 当我试图让这些东西写说唱时, 说唱听起来就像你在YouTube评论中看到的那种说唱. 
EDL	00:49:45,000	00:49:46,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Nursery school. \NSwyx：幼儿园. 
EDL	00:49:46,000	00:49:55,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Yeah, it's like, all right, great. You rhyme box with fox, sick rhyme, bro. You know, and Drake is rhyming give it up for me with napkins and cutlery, right? Like, all right, come on. \N乔治：是的, 这就像, 好吧, 太好了. 你把盒子和狐狸押韵, 变态的押韵, 兄弟. 你知道, 德雷克用餐巾纸和餐具为我押韵, 对吗? 就像, 好吧, 来吧. 
EDL	00:49:55,000	00:49:59,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: He's got like this thing about orange. Orange is famous so you can't rhyme it. Yeah, yeah, yeah, yeah, yeah. \NSwyx：他有关于橙色的事情. 橙色很有名, 所以你不能押韵. 是啊, 是啊, 是啊, 是啊, 是啊. 
EDL	00:49:59,000	00:50:07,547	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: But now, of course, you know, four-inch screws and orange juice is in GPT's training course. Yeah, so I think it went further than everyone kind of thought it would. \N乔治：但现在, 当然, 你知道, 四英寸的螺丝和橙汁是在GPT的培训课程. 是的, 所以我认为它比大家想象的要更进一步. 
EDL	00:50:07,547	00:50:16,635	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	But the thing that I really want to see is like somebody put 10 LLMs in a room and have them discuss the answer before they give it to me. Right, like, you can actually do this, right? \N但我真正想看到的是, 就像有人把10个法律硕士放在一个房间里, 让他们在给我答案之前讨论一下. 对, 比如, 你可以真正做到这一点, 对吗? 
EDL	00:50:16,635	00:50:25,527	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And I think the coding things have to be the same way. There is no coder alive, no matter how good you are, that sits down, well, I'm going to start at cell A1 and type my program, \N我认为编码的事情必须是同样的方式. 没有一个活着的编码员, 不管你有多好, 会坐下来, 好吧, 我要从A1单元格开始, 输入我的程序、
EDL	00:50:25,527	00:50:34,271	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	and then I'm going to press run and it's going to work. No one programs like that. So why do we expect the models to, right? So there's a lot that, like, still needs to be done. \N然后我就按下运行键, 它就会工作. 没有人像这样编程. 那么, 我们为什么期望模型能这样做呢, 对吗? 所以有很多事情, 比如, 仍然需要做. 
EDL	00:50:34,271	00:50:43,408	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	But, you know, at the tiny corp, I want to be on the cutting edge of this, too. I want to be, like, program generation. I mean, what is TinyGrad? It's a compiler, it generates programs. \N但是, 你知道, 在小公司, 我也想站在这一领域的前沿. 我想成为, 比如, 程序生成. 我是说, TinyGrad是什么? 它是一个编译器, 它生成程序. 
EDL	00:50:43,408	00:50:51,711	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Generate the fastest program that meets the spec, right? Why am I not just having ML do that? So, you know, it's kind of a, you have to exist fluidly with the machines. \N生成符合规格的最快程序, 对吗? 为什么我不直接让ML做这个? 所以, 你知道, 这是一种, 你必须与机器流畅地存在. 
EDL	00:50:51,711	00:50:58,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And I've come around on a lot of stuff. I'm like, wait, TinyGrad, TinyCorp should be a remote company. I can't do this in person.\N我在很多事情上都有想法. 我想, 等等, TinyGrad, TinyCorp应该是一个远程公司. 我不能亲自做这个. 
EDL	00:50:58,000	00:50:58,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Really? \NSwyx: 真的吗? 
EDL	00:50:58,000	00:51:04,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Yeah, like, comma makes sense to be in person. Like, comma, sure. Yeah, we're getting off in San Diego. \N乔治：是的, 就像, 逗号有意义的是要亲自去. 像, 逗号, 当然. 是的, 我们要在圣地亚哥下车. 
EDL	00:51:04,000	00:51:05,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: But that was a six-year-old company, right? \NSwyx: 但那是一个六年的公司, 对吗? 
EDL	00:51:05,000	00:51:08,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: And it works, and it works for a certain type of people \N乔治：而且它很有效, 对某类人很有效
EDL	00:51:08,000	00:51:08,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: and a certain type of culture. \NSwyx：和某种类型的文化. 
EDL	00:51:08,000	00:51:16,217	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: But what's going to be different this time? Okay, remote, but now it's remote. And now I'm getting these, like, people who apply, and I'm like, I literally have a thousand applications. \N乔治：但这次会有什么不同呢? 好吧, 远程, 但现在是远程. 现在我收到这些, 比如, 申请的人, 我就说, 我真的有一千份申请. 
EDL	00:51:16,217	00:51:24,476	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	I'm not calling you to do a technical screen. I can't really tell anything from a technical screen. What am I going to do? Make a code on a whiteboard? Like, bring up a shared notebook document, \N我不会打电话给你做一个技术筛选. 我真的无法从技术筛选中看出什么. 那我要做什么? 在白板上做一个代码? 比如, 调出一个共享笔记本文档、
EDL	00:51:24,476	00:51:31,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	so we could, oh, like, that's not going to work. Okay, so then I'm moved to the next thing. We do this at Comma with good success, programming challenges. \N所以我们可以, 哦, 比如, 那是行不通的. 好吧, 那么我就被转移到下一件事. 我们在Comma这样做, 取得了良好的效果, 编程挑战. 
EDL	00:51:31,000	00:51:32,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: I've also found them to be, like, \NSwyx：我也发现它们是, 比如、
EDL	00:51:32,000	00:51:38,770	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: completely non-predictive. I found one thing to actually be predictive, and it's, wait a second, just write code in TinyGrad. It's open source, right? \N乔治：完全没有预测性. 我发现有一件事实际上是可以预测的, 那就是, 等一下, 只要在TinyGrad中写代码. 它是开源的, 对吗? 
EDL	00:51:38,770	00:51:46,179	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And yeah, so, you know, I'm talking to a few people who've been contributing, and, like, contribute, or, you know, the job's not for you. But you can do it remote, and it's, \N是的, 所以, 你知道, 我正在和一些人交谈, 他们一直在贡献, 而且, 比如, 贡献, 或者, 你知道, 这个工作不适合你. 但你可以做远程, 它是、
EDL	00:51:46,179	00:51:54,057	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	look, it's a chill job. Like, you're not, you're like, oh, yeah, well, I work for the tiny corp. Like, well, you're writing MIT-licensed software. Like, you see what it's doing, right? \N你看, 这是一个寒冷的工作. 就像, 你不是, 你就像, 哦, 是的, 好吧, 我为小公司工作. 就像, 好吧, 你在写MIT许可的软件. 就像, 你看到它在做什么, 对吗? 
EDL	00:51:54,057	00:52:01,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Like, we'll just, I think, think of it as maybe more of, like, a stipend than a salary. And then also some equity. Like, if, you know, I get rich, we all get rich. \N就像, 我们只是, 我想, 把它当作也许更多的, 像, 津贴而不是工资. 然后还有一些股权. 就像, 如果, 你知道, 我发财了, 我们都发财了. 
EDL	00:52:01,000	00:52:09,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: How do you think about agents and kind of, like, thinking of them as people versus, like, job to be done? Sean built this thing called Small Developer. \N阿莱西奥：你如何看待代理人, 以及把他们当作人, 而不是当作工作来做? 肖恩建立了这个叫做 "小开发者 "的东西. 
EDL	00:52:09,000	00:52:17,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: It's in the same vein. Or, like, the human in the loop with the language model and just iterating while you write code. I think that's absolutely where it goes. \NSwyx：这是同样的思路. 或者说, 人类在语言模型的循环中, 只是在你写代码时进行迭代. 我认为这绝对是它的方向. 
EDL	00:52:17,000	00:52:24,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: And there's, like, a, it's not, like, one thing. It's, like, there's Small Interpreter. There's, like, Small Debugger. It's kind of, like, all these different jobs to be done. \N阿莱西奥：还有, 比如, 它不是, 比如, 一件事. 它是, 比如, 有小型解释器. 还有, 比如, 小型调试器. 这是一种, 比如, 所有这些不同的工作要做. 
EDL	00:52:24,000	00:52:25,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: It's a small world. \NSwyx：这是个小世界. 
EDL	00:52:25,000	00:52:29,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: Yeah, it's a, I know, this is, like, the small box is, like, small AI meets tiny corp. \NAlessio: 是的, 这是一个, 我知道, 这是, 比如, 小盒子是, 比如, 小人工智能与小公司的结合. 
EDL	00:52:29,000	00:52:30,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: So we're all in the same wavelength. \NSwyx：所以我们都在同一个波长上. 
EDL	00:52:30,000	00:52:41,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: How do you think about that? Do you think people will have a human-like interaction where it's, like, oh, this is, like, the AI developer, or, like, is it I'm the human being supercharged by the AI tools? \N阿莱西奥：你是怎么想的? 你认为人们会有一个类似人类的互动, 比如, 哦, 这是, 比如, 人工智能开发者, 或者, 比如, 我是被人工智能工具强化的人类? 
EDL	00:52:41,000	00:52:48,407	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Oh, I think it's, yeah, much more like I'm the human supercharged by the AI tools. I think that, like, coding is tool-complete. Like, driving's not tool-complete. \N乔治：哦, 我认为这是, 是的, 更像是我是被人工智能工具增压的人类. 我认为, 比如说, 编码是完整的工具. 就像, 驾驶不是完整的工具. 
EDL	00:52:48,407	00:52:53,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	We hire people to drive who are, like, below the API line. Right, there's an API line in the world, right? \N我们雇用那些低于API线的人去开车. 对, 世界上有一条API线, 对吗? 
EDL	00:52:53,000	00:52:53,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Love that. Yes. \NSwyx：喜欢这个说法. 是的. 
EDL	00:52:53,000	00:53:00,739	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Yeah, yeah, yeah, there's an API line in the world. And, like, you can think, like, Uber's a really clear example, right? There's the people below the API line and the people above the API line. \N乔治：是的, 是的, 是的, 世界上有一条API线. 而且, 你可以想, 比如, Uber就是一个非常明显的例子, 对吗? 有低于API线的人和高于API线的人. 
EDL	00:53:00,739	00:53:06,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And the way you can tell if you're below or above, by the way, is is your manager a computer, right? Who's the manager of the Uber driver? \N顺便说一下, 你可以知道你是在下面还是上面, 你的经理是一台电脑, 对吗? 谁是Uber司机的经理? 
EDL	00:53:06,000	00:53:09,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Well, a computer, right? Does the machine tell you what to do or do you tell machines what to do? Exactly, exactly. \NSwyx：嗯, 一台电脑, 对吗? 是机器告诉你要做什么, 还是你告诉机器要做什么? 正是如此, 正是如此. 
EDL	00:53:09,000	00:53:13,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: So, coding is tool-complete, right? \N乔治：所以, 编码是工具性的, 对吗? 
EDL	00:53:13,000	00:53:13,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Coding is tool-complete. \NSwyx: 编码是工具完整的. 
EDL	00:53:13,000	00:53:21,298	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Coding is above the API line. So it will always be tools supercharging your coding workflow. And it will never be you performing some, like, task. Like, \N乔治：编码是在API线上的. 因此, 它将永远是工具为你的编码工作流程增压. 而它永远不会是你在执行一些, 比如, 任务. 比如说、
EDL	00:53:21,298	00:53:29,958	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	okay, well, I can do everything except for actually starting a Docker container. Like, it just doesn't make any sense, right? Yeah, so it will always be sort of tools. \N好吧, 除了启动Docker容器, 我什么都能做. 就像, 它只是没有任何意义, 对吗? 是的, 所以它将永远是某种工具. 
EDL	00:53:29,958	00:53:38,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And, you know, look, we see the same stuff with all the, like, people are like, stable diffusion's gonna replace artists or whatever. It's like, dude, like- \N而且, 你知道, 你看, 我们看到同样的东西, 所有的, 比如, 人们都喜欢, 稳定的扩散会取代艺术家或什么. 这就像, 伙计, 像...
EDL	00:53:38,000	00:53:39,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: It's gonna create new artists. \NSwyx：它将创造新的艺术家. 
EDL	00:53:39,000	00:53:41,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Did Photoshop replace artists? \N乔治：Photoshop取代了艺术家吗? 
EDL	00:53:41,000	00:53:42,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Like, what are you talking about, right? \NSwyx：就像, 你在说什么, 对吗? 
EDL	00:53:42,000	00:53:50,059	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Like, you know, a real artist's finger paint. They can't use brushes. Brushes are, you know, brushes are gonna replace all the, okay, like, I just can't. \N乔治：就像, 你知道, 一个真正的艺术家的手指画. 他们不能用刷子. 刷子是, 你知道, 刷子会取代所有的, 好吧, 就像, 我只是不能. 
EDL	00:53:50,059	00:53:57,273	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Like, it's all just tools and the tools are gonna get better and better and better. And then eventually, yes, the tools are going to replace us. \N就像, 这一切都只是工具, 而工具会变得越来越好, 越来越好. 然后最终, 是的, 这些工具将取代我们. 
EDL	00:53:57,273	00:54:02,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	But, you know, that's still 20 years away. So, you know, I got a company to run in the meantime.\N但是, 你知道, 那仍然是20年后的事. 所以, 你知道, 在这期间, 我有一个公司要经营. 
EDL	00:54:02,000	00:54:07,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: So I've written about the API line before and I think that's from Venkatesh. I don't know if you've got your directive to it. I don't know, I definitely took it from someone. \NSwyx：所以我以前写过关于API线的文章, 我想那是Venkatesh写的. 我不知道你是否已经有了你的指令. 我不知道, 我肯定是从别人那里拿的. 
EDL	00:54:07,000	00:54:08,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: It's definitely not mine. \N乔治：这绝对不是我的. 
EDL	00:54:08,000	00:54:16,242	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: It's VGR. But I also have a speculated, a higher line than that, which is the Kanban board. Like, who tells the programmers what to do, right? \NSwyx：是VGR. 但我也有一个推测, 比这更高的线, 那就是看板. 比如, 谁告诉程序员该怎么做, 对吗? 
EDL	00:54:16,242	00:54:21,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	So are you above or below the Kanban board? Has that evolved your management thinking? \N所以你是在看板之上还是之下? 这是否改变了你的管理思维? 
EDL	00:54:21,000	00:54:28,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Yeah, like, that's sort of what I mean. Like, it's like, I'm just gonna describe the pull request in two sentences and then like, yeah. \N乔治：是的, 就像, 这就是我的意思. 就像, 我只是要用两句话描述拉动请求, 然后就像, 是的. 
EDL	00:54:28,000	00:54:31,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: So you are running the Kanban board? Or the bounties, you know? \NSwyx: 所以你在运行看板? 或者赏金, 你知道吗? 
EDL	00:54:31,000	00:54:39,186	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Yes, the bounties are the Kanban board, exactly. And that is kind of the high level. And then like, yeah, we'll get AIs to fill in some and we'll get people to fill in others. \N乔治：是的, 赏金就是看板, 没错. 这是一种高层次的. 然后, 是的, 我们会让人工智能来填补一些, 我们会让人们来填补其他. 
EDL	00:54:39,186	00:54:47,595	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And that's also what it means to be like, full-time at TinyCorp, right? Would you start, and I wrote this up pretty concretely. I'm like, okay, step one is you do bounties for the company. \N这也是在TinyCorp全职工作的意思, 对吗? 你会不会开始, 我把这个写得很具体. 我想, 好的, 第一步是你为公司做赏金. 
EDL	00:54:47,595	00:54:52,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Step two is you propose bounties for the company, right? You don't obviously pay them, we pay them. \N第二步是你为公司提出赏金, 对吗? 你显然没有支付他们, 我们支付他们. 
EDL	00:54:52,000	00:54:52,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: But you propose them. \NSwyx：但是你提出来. 
EDL	00:54:52,000	00:55:01,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: And I'm like, yeah, that's a good bounty. That like, helps with the main workflow of the company. And step three is you get hired full-time, you get equity, we all, you know, maybe get rich. \N乔治：我想, 是的, 这是一个好的赏金. 这就像, 有助于公司的主要工作流程. 第三步是你被全职雇用, 你得到股权, 我们都, 你知道, 也许会变得富有. 
EDL	00:55:01,000	00:55:04,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: What else are you designing differently about the employee experience? \NSwyx：你在员工体验方面还有什么不同的设计? 
EDL	00:55:04,000	00:55:06,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: You know, some people really like to like, \N乔治：你知道, 有些人真的喜欢喜欢、
EDL	00:55:06,000	00:55:07,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: like keep a separation, right? \NSwyx：喜欢保持分离, 对吗? 
EDL	00:55:07,000	00:55:15,263	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Some people really like to keep a separation between like employees and management or customers and employees. Like a comma, you know, the reason I do the DevKit thing, it's like, \N乔治：有些人非常喜欢在员工和管理层或客户和员工之间保持一种分离. 像逗号, 你知道, 我之所以做DevKit的事情, 这就像、
EDL	00:55:15,263	00:55:23,131	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	dude, you buy a comma thing, you're an employee of the company. Like you're just part of the company. It's all the same thing. There's no like secrets, there's no dividing lines. \N老兄, 你买了一个逗号的东西, 你就是公司的雇员. 就像你只是公司的一部分. 这都是一样的东西. 没有什么秘密, 没有什么分界线. 
EDL	00:55:23,131	00:55:32,186	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	There's no like, it's all a spectrum for like, you know, down here at the spectrum, like you pay. And then up here at the spectrum, you get paid. You understand this is the same spectrum of college, right? \N没有像, 它是所有的光谱一样, 你知道, 在这里的光谱, 像你付出. 然后在这里的频谱上, 你得到报酬. 你明白这和大学的光谱是一样的, 对吗? 
EDL	00:55:32,186	00:55:39,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Like for undergrad, you pay, and then you get up here to like, you know, I'm doing a PhD program, you get paid. Okay, well, cool. Welcome to the, you know. \N就像本科生, 你付钱, 然后你到了这里, 就像, 你知道, 我在做一个博士项目, 你得到报酬. 好吧, 好吧, 酷. 欢迎来到这里, 你知道. 
EDL	00:55:39,000	00:55:47,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: What about comma bodies? You mentioned a lot of this stuff is clearly virtual, but then there's below the API line you actually need. \N阿莱西奥：逗号体怎么样? 你提到很多这些东西显然是虚拟的, 但在API线以下还有你实际需要的东西. 
EDL	00:55:47,000	00:55:51,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Wait, this is a thing that's been announced? Comma bodies? We sell them. You can buy them. \NSwyx: 等等, 这是一个已经公布的东西? 逗号体? 我们出售它们. 你可以买到它们. 
EDL	00:55:51,000	00:55:53,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: They're a thousand bucks on our website. \N乔治：他们在我们的网站上是一千块钱. 
EDL	00:55:53,000	00:55:58,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Oh, okay, no, no, no. I'm thinking about like the, what Tesla announced with like the humanoid robots. It's the same thing. \N斯威克斯：哦, 好吧, 不, 不, 不. 我想的是, 就像特斯拉宣布的仿人机器人一样. 这是同一件事. 
EDL	00:55:58,000	00:56:07,531	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Except of course, we made the comma version of it. Tesla uses 20 actuators. We use two, right? Like how do you build the simplest possible thing that can like \N乔治：当然, 除了我们做了它的逗号版本. 特斯拉使用20个执行器. 我们使用两个, 对吗? 就像你如何建立一个最简单的东西, 可以像
EDL	00:56:07,531	00:56:17,803	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	turn the robotics problem into entirely a software problem? So right now it is literally just a comma three on a pole with two wheels. It balances, keeps the comma three up there. \N把机器人问题完全变成一个软件问题? 因此, 现在它实际上只是一个有两个轮子的杆上的逗号三. 它能保持平衡, 使逗号三保持在上面. 
EDL	00:56:17,803	00:56:21,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And like, there's so much you could do with that already.\N而且, 你已经可以用它做很多事情了. 
EDL	00:56:21,000	00:56:22,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Right? \NSwyx: 对吗? 
EDL	00:56:22,000	00:56:29,657	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Like this should replace, how many security guards could this replace? Right? If this thing could just competently wander around a space and take pictures and, you know, \N乔治：就像这应该取代, 这可以取代多少个保安? 对吗? 如果这个东西可以在一个空间里游荡, 拍照, 你知道、
EDL	00:56:29,657	00:56:37,960	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	focus in on things, send you a text message when someone's trying to break into your building, you know, like, like this could already do so much, of course, but the software is not there yet. \N当有人试图闯入你的大楼时, 给你发一条短信, 你知道, 就像, 这已经可以做这么多了, 当然, 但软件还没有出现. 
EDL	00:56:37,960	00:56:46,048	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Right? So how do we turn robotics into a thing where it's very clearly a software problem? You know, that people don't accept that self-driving cars are a software problem. Like, I don't, \N对吗? 因此, 我们如何把机器人技术变成一个非常明显的软件问题的东西? 你知道, 人们不接受自动驾驶汽车是一个软件问题的说法. 就像, 我不知道、
EDL	00:56:46,048	00:56:55,771	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	I don't know what to tell you, man. Like literally just watch the video yourself and then drive with a joystick, right? Can you drive? And we've actually done this test. We've actually done this test where you've had someone, \N我不知道该怎么告诉你, 伙计. 就像从字面上看, 你自己看视频, 然后用操纵杆开车, 对吗? 你能开车吗? 而且我们实际上已经做了这个测试. 我们实际上已经做了这个测试, 你已经有一个人、
EDL	00:56:55,771	00:57:07,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	okay, you just watch this video and here's a joystick and you got to drive the car. And of course they can drive the car. It takes a little bit of practice to get used to the joystick, but the problem is all the model, right? So I can now make the model better. \N好吧, 你只是看这个视频, 这里有一个操纵杆, 你必须驾驶这辆车. 当然, 他们可以驾驶这辆车. 这需要一点点练习来适应操纵杆, 但问题是所有的模型, 对吗? 所以我现在可以把模型做得更好. 
EDL	00:57:07,000	00:57:17,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Our second most popular episode ever was about segment anything coming out of Facebook, which as far as I understand the state of the art in computer vision, what are you hoping for there that you need for Karma? \NSwyx：我们有史以来最受欢迎的第二集是关于从Facebook出来的segment anything, 据我了解, 这是计算机视觉的技术水平, 你在那里希望得到什么, 你需要Karma? 
EDL	00:57:17,000	00:57:24,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: I haven't used segment anything. Like they large, large YOLOs or not. I've used like large YOLOs and I'm super impressed by them. \N乔治：我还没有用过segment anything. 像他们大型的, 大型的YOLO或者不是. 我用过像大型的YOLO, 我对它们印象超级深刻. 
EDL	00:57:24,000	00:57:25,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Yeah. \NSwyx：是的. 
EDL	00:57:25,000	00:57:35,468	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: I got to check out segment anything. I don't think it's a distinct problem, right? Okay, here's something that I'm interested in. All right, we have great LLMs. We have great text to speech models and we have great speech to text models. \N乔治：我得去看看段子什么的. 我不认为这是一个明显的问题, 对吗? 好吧, 这里有我感兴趣的东西. 好吧, 我们有伟大的LLMs. 我们有很好的文本到语音模型, 我们有很好的语音到文本模型. 
EDL	00:57:35,468	00:57:39,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Okay, so why can I not talk to an LLM? Like I'd have a normal conversation with it. \N好吧, 那么为什么我不能和LLM交谈? 就像我可以和它进行正常的对话一样. 
EDL	00:57:39,000	00:57:42,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: You can with the latency of like two seconds every time. Right? \NSwyx：你可以, 每次都有两秒的延迟. 对吗? 
EDL	00:57:42,000	00:57:53,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: And then it feels so unnatural. It's this like staccato. Like I don't like the RLHF models. I don't like the tuned versions of them. You take on the personality of our customer support agent. Right? \N乔治：然后就感觉很不自然了. 它是这样的, 就像咯噔一下. 就像我不喜欢RLHF的模型. 我不喜欢它们的调谐版本. 你承担了我们的客户支持代理人的个性. 对吗? 
EDL	00:57:53,000	00:57:54,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Like, oh, come on. \NSwyx：像, 哦, 来吧. 
EDL	00:57:54,000	00:58:06,811	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: I like LLMA more than ChatGPT. ChatGPT's personality just graded on me. Whereas LLMA, like, cool. I read a little bit of pretext paragraph. I can put you in any scenario I want, right? Like, that's interesting to me. \N乔治：比起ChatGPT, 我更喜欢LLMA. ChatGPT的个性对我来说很重要. 而LLMA, 像, 很酷. 我读了一点借口的段落. 我可以把你放在我想要的任何场景中, 对吗? 像, 这对我来说很有趣. 
EDL	00:58:06,811	00:58:18,882	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	So yeah, I think there is really no like distinction between computer vision and language and any of this stuff. It's all eventually going to be fused into one massive. So to say computer vision is solved, well, \N所以, 是的, 我认为在计算机视觉和语言以及任何这些东西之间真的没有像区别. 这一切最终都会被融合成一个巨大的. 因此, 如果说计算机视觉已经解决了, 那么、
EDL	00:58:18,882	00:58:26,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	it doesn't make any sense because what's the output of a computer vision model? Segmentation? Like, what a weird task, right? \N它没有任何意义, 因为计算机视觉模型的输出是什么? 分割? 多么奇怪的任务啊, 对吗? 
EDL	00:58:26,000	00:58:28,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Who cares? OCR? \NSwyx：谁在乎呢? OCR? 
EDL	00:58:28,000	00:58:29,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Who cares? \N乔治：谁在乎呢? 
EDL	00:58:29,000	00:58:29,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: I don't care if you can segment \NSwyx：我不关心你是否能分段
EDL	00:58:29,000	00:58:32,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: which pixels make up that laptop. I care if you can pick it up. \N乔治：哪些像素组成了那个笔记本. 我关心的是你是否能把它捡起来. 
EDL	00:58:32,000	00:58:36,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: And you're going to have the local cluster. You're going to have the body. \NAlessio：而你将拥有本地的集群. 你将会拥有这个身体. 
EDL	00:58:36,000	00:58:37,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Yeah. \NSwyx：是的. 
EDL	00:58:37,000	00:58:39,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Yeah, I think that's kind of where that goes. \N乔治：是的, 我想这就是那种情况了. 
EDL	00:58:39,000	00:58:48,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Maybe we can paint the future of like, the year is 2050. You've achieved all you wanted at TinyCorp. What is the AI enabled future like?\NSwyx: 也许我们可以描绘一下未来, 比如说, 今年是2050年. 你在TinyCorp已经实现了你想要的一切. 人工智能的未来是什么样子的? 
EDL	00:58:48,000	00:58:59,530	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Well, TinyCorp's the second company. Comma was the first. Comma builds the hardware infrastructure. TinyCorp builds the software infrastructure. The third company is the first one that's going to build a real product. \N乔治：嗯, TinyCorp是第二家公司. Comma是第一家. Comma建立了硬件基础设施. TinyCorp建立了软件基础设施. 第三家公司是第一家将建立一个真正的产品的公司. 
EDL	00:58:59,530	00:59:08,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And that product is AI Girlfriend. No, like I'm dead serious, right? Like, this is the dream product. This is the absolute dream product. Girlfriend is just the like- \N而这个产品就是人工智能女友. 不, 我是认真的, 对吗? 就像, 这是梦想中的产品. 这是绝对的梦想产品. 女朋友就是这样...
EDL	00:59:08,000	00:59:09,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Stand-in. \NSwyx: 站着的. 
EDL	00:59:09,000	00:59:15,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Well, no, it's not a stand-in. No, no, no, no. I actually mean it, right? So I've been wanting to merge with a machine ever since I was like, mad little. \N乔治：嗯, 不, 这不是一个替身. 不, 不, 不, 不, 不. 我实际上是认真的, 对吗? 所以我一直想和机器合并, 因为我就像, 疯狂的小. 
EDL	00:59:15,000	00:59:16,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Like, you know, I was just like, \NSwyx: 就像, 你知道, 我只是想、
EDL	00:59:16,000	00:59:18,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: how do I merge with a machine, right? \N乔治：我怎样才能与机器融合, 对吗? 
EDL	00:59:18,000	00:59:19,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: And like, you can look at like, \NSwyx：而且, 你可以看看像、
EDL	00:59:19,000	00:59:30,578	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: maybe the Elon style way of thinking about it is Neuralink, right? I'm like, I don't think we need any of this, right? You ever, some of your friends maybe, they get into relationships and you start thinking of, \N乔治：也许伊隆式的思考方式是Neuralink, 对吗? 我想, 我不认为我们需要这些东西, 对吗? 你曾经, 你的一些朋友也许, 他们进入了关系, 你开始思考、
EDL	00:59:30,578	00:59:40,999	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	you know, them and their partner as the same person. You start thinking of them as like one person. I mean, they are kind of like merged, right? Like, humans can just kind of do this. It's so cool. \N你知道, 他们和他们的伴侣是同一个人. 你开始把他们想成一个人. 我的意思是, 他们有点像合并了, 对吗? 就像, 人类可以做到这一点. 这太酷了. 
EDL	00:59:40,999	00:59:50,683	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	It's this ability that we already have. Right, so I don't need to put, you know, electrodes in my brain to merge with a machine. I need an AI Girlfriend, right? So that's what I mean. \N这是我们已经拥有的能力. 对, 所以我不需要, 你知道, 在我的大脑里放电极来与机器融合. 我需要一个人工智能女友, 对吗? 所以这就是我的意思. 
EDL	00:59:50,683	01:00:03,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Like, this is the third product. This is the third company. And yeah, in 2050, I mean like, ah, it's so hard. I just like, maybe I can imagine like 2035. I don't even know 2050, but like, yeah, 2035. Like, yeah, that'd be really great.\N就像, 这是第三个产品. 这是第三家公司. 而且, 是的, 在2050年, 我的意思是像, 啊, 这太难了. 我只是喜欢, 也许我可以想象像2035年. 我甚至不知道2050年, 但像, 是的, 2035年. 就像, 是的, 那将是非常棒的. 
EDL	01:00:03,000	01:00:09,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: In terms of merging, like, isn't it, shouldn't you work on Brain Upload rather than AI Girlfriend? Brain Upload, right? \NSwyx：在合并方面, 就像, 是不是, 你不应该致力于《大脑上传》而不是《AI女友》? 大脑上传, 对吗? 
EDL	01:00:09,000	01:00:17,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: I don't need Brain Upload either. Like, there's thousands of hours of me on YouTube, right? Yes. How much of my brain's already uploaded? \N乔治：我也不需要大脑上传. 就像, YouTube上有几千个小时的我, 对吗? 是的. 我的大脑有多少已经上传了? 
EDL	01:00:17,000	01:00:20,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: That's only the stuff that you voice. Yeah, it's not that different. \NSwyx: 那只是你发声的东西. 是的, 这没有什么不同. 
EDL	01:00:20,000	01:00:29,382	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: It's not that different, right? You really think a model with, you know, an exaflop of compute couldn't extract everything that's really going on in my brain? I'm a pretty open person, right? \N乔治：没有什么不同, 对吗? 你真的认为一个拥有, 你知道的, exaflop计算能力的模型不能提取我大脑中真正发生的一切? 我是一个相当开放的人, 对吗? 
EDL	01:00:29,382	01:00:39,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Like, I'm not running a complex filter. Humans can't run that complex of a filter. Like, humans just can't. Like, this is actually a cool quirk of biology. It's like, well, humans like can't lie that well. \N比如, 我没有运行一个复杂的过滤器. 人类不可能运行那么复杂的过滤器. 就像, 人类就是不能. 就像, 这实际上是生物学的一个很酷的怪癖. 这就像, 好吧, 人类就像不能很好地撒谎. 
EDL	01:00:39,000	01:00:43,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: So is it good or bad to put all of your stream of consciousness out there? \N阿莱西奥：那么, 把你所有的意识流放在外面是好还是坏? 
EDL	01:00:43,000	01:00:45,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: I mean, I think it's good. \N乔治：我的意思是, 我认为这很好. 
EDL	01:00:45,000	01:00:54,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: I mean, he's streaming every day. I want to live forever. We said off mic that we may be the first immortals, right? Yeah, this is how you live forever. \NSwyx：我是说, 他每天都在流传. 我想永远活着. 我们在话筒外说, 我们可能是第一个不朽的人, 对吗? 是的, 这就是你永生的方式. 
EDL	01:00:54,000	01:01:02,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: It's a question of, okay, how many weights do I have? Right, okay, let's say I have a trillion weights, right? So talking about a terabyte, 100 terabytes here.\N乔治：这是一个问题, 好吧, 我有多少个砝码? 对, 好吧, 让我们说我有一万亿个砝码, 对吗? 所以在这里说的是一兆字节, 100兆字节. 
EDL	01:01:02,000	01:01:03,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Okay, but it's not really 100 terabytes, right?\NSwyx：好吧, 但它不是真的100兆字节, 对吗? 
EDL	01:01:03,000	01:01:12,978	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Because it's Kolmogorov complexity. How much redundancy is there in those weights? So, like, maximally compressed, how big is the weight file for my brain? Quantize it whatever you want. \N乔治：因为它是科尔莫戈罗夫复杂性. 在这些权重中, 有多少冗余度? 所以, 比如, 最大限度地压缩, 我的大脑的权重文件有多大? 随你怎么量化吧. 
EDL	01:01:12,978	01:01:27,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Quantization is a poor man's compression. I think we're only talking really here about, like, maybe a couple gigabytes, right? And then if you have, like, a couple gigabytes of true information of yourself up there, cool, man. Like, what does it mean for me to live forever? \N量化是一种穷人的压缩. 我想我们在这里真正谈论的只是, 比如, 也许几个千兆字节, 对吗? 然后, 如果你有, 比如, 几千兆字节的自己的真实信息在那里, 酷, 伙计. 比如, 对我来说, 长生不老意味着什么? 
EDL	01:01:27,000	01:01:29,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Like, that's me. No, I think that's good. \NSwyx: 就像, 这就是我. 不, 我认为这很好. 
EDL	01:01:29,000	01:01:36,430	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: And I think there's a bit of, like, a professionalization of social media, where, like, a lot of people only have what's, like, PC out there, you know? \N阿莱西奥：我认为有一点, 比如, 社交媒体的专业化, 其中, 比如, 很多人只有什么, 比如, PC在那里, 你知道? 
EDL	01:01:36,430	01:01:44,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And I feel like you're going to get, going back to the ChatGPT thing, right? You're going to train a model on, like, everything that's public about a lot of people. \N我觉得你会得到, 回到ChatGPT的事情上, 对吗? 你将会训练一个模型, 比如, 关于很多人的所有公开信息. 
EDL	01:01:44,000	01:01:45,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: And it's like- \NSwyx: 这就像...
EDL	01:01:45,000	01:01:49,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Then no one's going to run their model and they're going to die. Don't put PC on social media. \N乔治：那么就没有人去运行他们的模型, 他们就会死. 不要把PC放在社交媒体上. 
EDL	01:01:49,000	01:01:59,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: We're moving on to what would normally be called the lightning round, but just general tics, because you're a generally interesting person with many other interests. What does the goddess of everything else mean to you? \NSwyx：我们现在进入通常被称为闪电回合的话题, 但只是一般的抽搐, 因为你是一个普遍有趣的人, 有许多其他的兴趣. 其他事物的女神对你来说意味着什么? 
EDL	01:01:59,000	01:02:01,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Oh, it means that AI is not really going to kill us. \N乔治：哦, 这意味着人工智能不会真的杀死我们. 
EDL	01:02:01,000	01:02:01,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Really? \NSwyx：真的吗? 
EDL	01:02:01,000	01:02:02,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Of course. \N乔治：当然了. 
EDL	01:02:02,000	01:02:03,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Tell us more. \NSwyx: 告诉我们更多. 
EDL	01:02:03,000	01:02:11,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Lex asked me this, like, is AI going to kill us all? And I was quick to say yes, but I don't actually really believe it. I think there's a decent chance that AI kills 95% of us.\N乔治：莱克斯问我这个问题, 比如, 人工智能会杀死我们所有人吗? 我很快就说是的, 但我实际上并不真的相信它. 我认为有一个很好的机会, 人工智能会杀死我们95%的人. 
EDL	01:02:11,000	01:02:12,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Okay. \NSwyx：好的. 
EDL	01:02:12,000	01:02:16,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: But they saw on your Twitch streams that you're with them, so they're not going to- \NAlessio: 但是他们在你的Twitch流媒体上看到你和他们在一起, 所以他们不会......
EDL	01:02:16,000	01:02:18,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: No, I don't think, I actually, \NSwyx：不, 我不认为, 我实际上、
EDL	01:02:18,000	01:02:25,470	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: I don't also think it's AI. Like, I think the AI alignment problem is so misstated. I think it's actually not a question of whether the computer is aligned with the company who owns the computer. \N乔治：我也不认为这是人工智能. 就像, 我认为人工智能的对齐问题被错误地描述了. 我认为这实际上不是一个计算机是否与拥有该计算机的公司结盟的问题. 
EDL	01:02:25,470	01:02:31,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	It's a question of whether that company's aligned with you or that government's aligned with you. And the answer is no, and that's how you end up dead. \N这是一个该公司是否与你结盟或政府与你结盟的问题. 而答案是否定的, 这就是你如何最终死亡的原因. 
EDL	01:02:31,000	01:02:32,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: So what the goddess of everything else means to me \NSwyx：那么, 其他一切的女神对我来说意味着什么? 
EDL	01:02:32,000	01:02:37,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: is like, the complexity will continue. Paper clippers don't exist. \N乔治：就像, 复杂的事情会继续. 剪纸机并不存在. 
EDL	01:02:37,000	01:02:38,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: You know, there are forces. \NSwyx：你知道, 有一些力量. 
EDL	01:02:38,000	01:02:48,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: The paper clipper is cancer, right? The paper clipper is really just a perfect form of cancer. And the goddess of everything else says, yeah, but cancer doesn't win, you know? \N乔治：剪纸器是癌症, 对吗? 剪纸机真的只是癌症的一个完美形式. 而其他事物的女神说, 是的, 但癌症不会赢, 你知道吗? 
EDL	01:02:48,000	01:02:55,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Yeah, it's a beautiful story for those who haven't heard it. And you read it out and I listened to it. Yeah, what are you grateful for today? \NSwyx：是的, 对于那些没有听过的人来说, 这是个美丽的故事. 你把它读出来, 我也听了. 是的, 你今天对什么感到感激? 
EDL	01:02:55,000	01:03:04,472	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Oh man, I mean, it's all just like, I haven't, I haven't thinking about this stuff forever. Like, that it's actually like happening and it's happening in an accessible way too. \N乔治：哦, 伙计, 我的意思是, 这一切就像, 我没有, 我永远没有想过这些东西. 就像, 它实际上是在发生, 而且是以一种可接受的方式发生. 
EDL	01:03:04,472	01:03:12,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	I guess that's what I'm really grateful for. It's not like, AI is not some Manhattan project style. You don't know anything about it. Closed doors. \N我想这就是我真正感激的地方. 它不像, 人工智能不是什么曼哈顿项目式的. 你对它一无所知. 闭门造车. 
EDL	01:03:12,000	01:03:13,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Closed doors. \NSwyx：闭门造车. 
EDL	01:03:13,000	01:03:21,183	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: I'll fight really hard to keep it that way. I'm grateful for just how much is released out there and how much I can just learn and stay up to date. \N乔治：我将非常努力地争取保持这种状态. 我很感激有多少东西被发布出来, 有多少东西我可以学习并保持更新. 
EDL	01:03:21,183	01:03:31,360	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	And I guess I'm grateful to the true fabric of reality that, you know, I didn't need differential equations to understand it. Like, I don't need some like, there's a limit to my math abilities. \N我想我很感激现实的真正结构, 你知道, 我不需要微分方程来理解它. 就像, 我不需要一些像, 我的数学能力有一个限制. 
EDL	01:03:31,360	01:03:45,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	I can do most undergrad math, but I took some grad math classes and okay, now we're getting to the end of what I can do. And it's just the actual like, end of what I can do. Like, I'm limited by my brain, but you know, ML stuff, hey, you need high school math. \N我可以做大多数本科生的数学, 但我上了一些研究生数学课, 好吧, 现在我们已经到了我能做的极限. 而这只是实际的, 我所能做的极限. 就像, 我被我的大脑所限制, 但你知道, ML的东西, 嘿, 你需要高中数学. 
EDL	01:03:45,000	01:03:46,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: You know what I mean? \NSwyx: 你明白我的意思吗? 
EDL	01:03:46,000	01:03:48,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: When I learned to multiply a matrix, seventh grade, \N乔治：当我学会乘以一个矩阵时, 七年级、
EDL	01:03:48,000	01:03:52,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: like, it's all easy. You need more electrical engineering than you need high school math early. \NSwyx: 就像, 这一切都很容易. 你需要更多的电气工程, 而不是提前需要高中数学. 
EDL	01:03:52,000	01:03:59,447	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Yeah, well, you need electrical engineering to like, build the machines, but even that, like, these machines are simpler than the machines that have existed before. \N乔治：是的, 你需要电气工程来建造机器, 但即使如此, 这些机器也比以前存在的机器更简单. 
EDL	01:03:59,447	01:04:05,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	The compute stack looks really nice. So, you know, yeah, I just, I'm grateful that it's all happening and I get to understand it. \N计算堆栈看起来非常好. 所以, 你知道, 是的, 我只是, 我很感激这一切的发生, 我能够理解它. 
EDL	01:04:05,000	01:04:11,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: John Carmack mentioned there's about six insights we have left. Do you have an intuition for what some of the paths \N阿莱西奥：约翰-卡马克提到, 我们还剩下大约六个洞察力. 你对其中的一些路径有什么直觉吗? 
EDL	01:04:11,000	01:04:12,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: people should be taking? \NSwyx：人们应该走什么路? 
EDL	01:04:12,000	01:04:17,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: Obviously you're working on one. What are some of the other branches of the tree that people should go under? \N阿莱西奥：很明显, 你正在从事一项工作. 人们应该走的其他树枝有哪些? 
EDL	01:04:17,000	01:04:25,964	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: I don't think I'm working on one of the six insights. I don't think TinyGrid's any one of the six insights. Something I really like that Elon does, and I try to be inspired by it, \N乔治：我不认为我正在研究这六种见解中的一种. 我不认为TinyGrid是六种见解中的任何一种. 我非常喜欢埃隆所做的事情, 我也试图从它那里得到启发、
EDL	01:04:25,964	01:04:35,167	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	is look at the boring tunnel machine and ask how you can build a 10X cheaper one. All right, look at the rocket. How can I build a 10X cheaper one? All right, look at the electric car and say, \N就是看一下无聊的隧道机, 然后问你如何能建造一个便宜10倍的隧道机. 好吧, 看看火箭. 我怎么能建造一个便宜10倍的? 好吧, 看一下电动汽车, 然后说、
EDL	01:04:35,167	01:04:43,130	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	how can I build a 10X cheaper, like, cheaper or, you know, can go further or whatever, whatever, whatever, right? And you just do the straight up physics math, right? \N我怎么能造一个便宜10倍的, 比如, 更便宜, 或者, 你知道, 可以走得更远, 或者什么, 什么, 什么, 对吗? 而你只是做了直接的物理数学, 对吗? 
EDL	01:04:43,130	01:04:52,619	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	I'm trying to do the same thing with ML frameworks, right? And in doing so, making sure that this stuff remains accessible. You could imagine a world where if Google TPUs were actually the ultimate, \N我正试图用ML框架做同样的事情, 对吗? 在这样做的过程中, 要确保这些东西仍然是可获得的. 你可以想象一个世界, 如果谷歌TPU实际上是终极的、
EDL	01:04:52,619	01:05:04,255	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	if Google TPUs were actually the best training things, I mean, actually, you know, I'm kind of grateful for NVIDIA, right? Because if Google TPUs were the ultimate, now you have this huge closed source compiler in between XLA and the hardware, \N如果谷歌TPU实际上是最好的训练东西, 我的意思是, 实际上, 你知道, 我有点感谢NVIDIA, 对吗? 因为如果谷歌TPU是终极的, 那么现在你在XLA和硬件之间有一个巨大的封闭源代码编译器、
EDL	01:05:04,255	01:05:13,697	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	and yeah, that's just a really bad thing. So, I mean, something that is somewhat upsetting about the Tiny Core is that it is trying to prevent downside, but it's not all trying to prevent downside. \N是的, 这真的是一件坏事. 所以, 我的意思是, 关于Tiny Core的一些令人不安的事情是, 它正在努力防止降级, 但它并不全是为了防止降级. 
EDL	01:05:13,697	01:05:25,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Like, we're also building computers and we're gonna build some awesome, powerful, cheap computers along the way. So, no, I'm not really working directly on any of the six tricks. I also think the six tricks are kind of gonna be like luck.\N比如, 我们也在建造计算机, 而且我们会在这一过程中建造一些超棒的、强大的、廉价的计算机. 所以, 不, 我并没有真正直接从事这六招中的任何一招. 我也认为这六招有点像运气. 
EDL	01:05:25,000	01:05:26,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: I think it's just gonna be like, you know, \NSwyx：我认为这只是会像, 你知道、
EDL	01:05:26,000	01:05:37,044	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: please tell me more about what covariate shift is and how that inspired you to come up with batch normalization. Please tell me more about why it's a transformer and it has a query, a key, and a value, right? \N乔治：请告诉我更多关于什么是协变量转移, 以及它是如何启发你想出批量归一化的. 请告诉我更多关于为什么它是一个转化器, 它有一个查询, 一个键, 和一个值, 对吗? 
EDL	01:05:37,044	01:05:47,579	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Like Schmidt-Huber described it better in fast weights. I mean, my theory about why transformers work have nothing to do with this attention mechanism and just the fact that it's semi-weight sharing, right? \N像Schmidt-Huber在快速权重中描述得比较好. 我的意思是, 我关于变压器为什么工作的理论与这个注意机制无关, 只是它是半权重共享的事实, 对吗? 
EDL	01:05:47,579	01:05:57,910	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Because the weight matrix is being generated on the fly, you can compress the weight matrix, right? Like, this is what that, there's an operation in the transformer, which, and by the way, this is like, \N因为权重矩阵是在飞行中生成的, 你可以压缩权重矩阵, 对吗? 比如说, 这就是, 在变换器里有一个操作, 顺便说一下, 这就像、
EDL	01:05:57,910	01:06:07,784	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Qualcomm's SNPE can't run transformers for this reason. So, most matrix multipliers in neural networks are weight times values, right? Whereas when you get to the outer product in transformers, \N高通公司的SNPE不能运行变压器, 就是这个原因. 所以, 神经网络中的大多数矩阵乘法器是权重乘以数值, 对吗? 而当你到了变压器中的外积时、
EDL	01:06:07,784	01:06:20,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	well, it's weight times weight. It's values times values, right? So, SNPE doesn't even support that operation, right? So, it's like that operation that gives the transformer its power. It has nothing to do with the fact that it's attention, \N那么, 它是权重乘以权重. 它是数值乘以数值, 对吗? 所以, SNPE甚至不支持这种操作, 对吗? 所以, 就像那个操作给了变压器它的力量. 它与它的注意力没有关系、
EDL	01:06:20,000	01:06:21,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: right? \NSwyx：对吗? 
EDL	01:06:21,000	01:06:29,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: And this is a funny, like, but that is one of the six tricks, right? Batch, like these norms are a trick. Transformers are a trick. Okay, six more. \N乔治：这是一个有趣的, 像, 但这是六个技巧之一, 对吗? 批量, 像这些规范是一个技巧. 变形金刚是一个把戏. 好吧, 还有六个. 
EDL	01:06:29,000	01:06:33,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: So, you talk about attention as weight compression. \NSwyx: 所以, 你说到注意力是重量压缩. 
EDL	01:06:33,000	01:06:44,580	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Compression is not exactly the right word. What I mean is that the weight can change dynamically based on the context. So, there was this thing in PAC-8 in the Hutter Prize that I absolutely loved, and I've never seen it again in neural networks, \N乔治：压缩这个词不完全正确. 我的意思是, 权重可以根据上下文动态地变化. 所以, 在胡特奖的PAC-8中, 有这样一个东西, 我非常喜欢, 我在神经网络中再也没有看到过它、
EDL	01:06:44,580	01:06:55,161	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	and it's a really good trick. Okay, imagine you have 256 weight sets for a layer, right? And then you choose which of the weight sets you're loading in based on some context. And that context can come from another neural net, right? \N这是一个非常好的技巧. 好吧, 想象一下你有256个权重集的层, 对吗? 然后你根据一些背景选择你要加载的权重集. 而这种背景可以来自另一个神经网络, 对吗? 
EDL	01:06:55,161	01:07:06,514	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	So, I have another neural net, which projects 256 wide, one hot, do a softmax, predict it, and then I actually load the weights in. And I can do this operation at both test time and train time. I can do this operation at both training and inference, \N所以, 我有另一个神经网络, 它投射了256个宽, 一个热, 做一个softmax, 预测它, 然后我实际上加载了权重. 我可以在测试时间和训练时间都做这个操作. 我可以在训练和推理时都做这个操作、
EDL	01:07:06,514	01:07:16,778	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	and I load in the weights given the context. Like, that is what transformers do. But transformers, instead of having 256 discrete ones, it's actually just that, but continuous. Which is funny that that was in language models, \N我可以根据上下文加载权重. 就像, 这就是变换器的作用. 但是, 变压器, 而不是有256个离散的, 它实际上就是这样, 但是是连续的. 有趣的是, 那是在语言模型中、
EDL	01:07:16,778	01:07:23,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	and I just like, when I understood that about transformers, I'm like, oh, this is a real trick, and why are they using the word attention?\N我只是喜欢, 当我理解了变压器, 我想, 哦, 这是一个真正的技巧, 他们为什么要用注意力这个词? 
EDL	01:07:23,000	01:07:27,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: And today is actually the anniversary of attention is all you need. What? \N阿莱西奥：而今天实际上是注意力就是你所需要的周年纪念. 什么? 
EDL	01:07:27,000	01:07:28,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Oh, that's so cool. \NSwyx: 哦, 这太酷了. 
EDL	01:07:28,000	01:07:29,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: Today, six years ago. \N阿莱西奥：今天, 六年前. 
EDL	01:07:29,000	01:07:30,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Six years. \NSwyx：六年了. 
EDL	01:07:30,000	01:07:31,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Six years. \N乔治：六年了. 
EDL	01:07:31,000	01:07:32,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Changed the world. Wow. \NSwyx: 改变了世界. 哇. 
EDL	01:07:32,000	01:07:40,707	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Well, there's one of your envelope tricks, right? And you could easily write it on an envelope, think about how you write out that. How many times have you written that? Because it's not in any libraries, \N乔治：嗯, 这是你的一个信封技巧, 对吗? 而且你可以很容易地把它写在信封上, 想想你是怎么写出来的. 你写过多少次了? 因为它不在任何图书馆里、
EDL	01:07:40,707	01:07:45,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	because it's all used a little differently each time. Like, you just write out that exact same, you know. \N因为它每次的使用方式都有点不同. 就像, 你只是写出了那个完全相同的, 你知道. 
EDL	01:07:45,000	01:07:53,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: You've name checked Elon a few times. I think about both of you as systems thinkers. Input, output, thinking something in between. What's different about your style versus his? \NSwyx：你已经点了几次埃隆的名字. 我认为你们两个人都是系统思考者. 输入、输出, 在这两者之间思考问题. 你和他的风格有什么不同? 
EDL	01:07:53,000	01:07:58,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Elon's fundamental science for the world is physics, mine is information theory. But you do a lot of physics as well. \N乔治：埃隆对世界的基本科学是物理学, 我的是信息论. 但你也做了很多物理学方面的工作. 
EDL	01:07:58,000	01:07:59,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: I mean, like, you base it on- \NSwyx：我的意思是, 比如, 你的基础是......
EDL	01:07:59,000	01:08:08,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: And Elon does a lot of information theory as well, too. But the difference maybe is expressed in what your ambitions are, right? Elon's ambitions may be like- \N乔治：而埃隆也做了很多信息理论. 但区别可能表现在你的野心是什么, 对吗? 埃隆的野心可能是...
EDL	01:08:08,000	01:08:10,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Go to Mars. Go to Mars, right? \NSwyx：去火星. 去火星, 对吗? 
EDL	01:08:10,000	01:08:16,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Go to Mars is the ultimate modernist physics ambition, right? It's a physics problem getting to Mars, right? \N乔治：去火星是现代主义物理学的终极野心, 对吗? 去火星是一个物理学问题, 对吗? 
EDL	01:08:16,000	01:08:17,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Well, what are electric cars? \NSwyx：那么, 什么是电动汽车? 
EDL	01:08:17,000	01:08:25,143	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: It's a physics problem, right? Okay, now he's like pushing on the autonomy stuff, and you push a little on information theory. But fundamentally, his dreams are physics-based dreams. \N乔治：这是一个物理学问题, 对吗? 好吧, 现在他就像在推动自主性的东西, 而你在信息论上推了一下. 但从根本上说, 他的梦想是基于物理学的梦想. 
EDL	01:08:25,143	01:08:33,329	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	My dreams are information-based dreams. I want to live forever in virtual reality with my AI girlfriend. Those are the aspirations of someone who accepts information theory as a core science. \N我的梦想是基于信息的梦想. 我想和我的人工智能女友永远生活在虚拟现实中. 这些是接受信息理论作为核心科学的人的愿望. 
EDL	01:08:33,329	01:08:39,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	So I think that's the main difference between me and him. He has physics-based aspirations, and I have information-based aspirations. \N所以我认为这是我和他之间的主要区别. 他有基于物理学的愿望, 而我有基于信息的愿望. 
EDL	01:08:39,000	01:08:50,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Mark Andreessen, he is a- Hi, Mark. He's a listener. He's a big proponent of effective accelerationism. You've been a bit more critical. Why do you say that IAC is not taken seriously by its adherents? \NSwyx: 马克-安德森, 他是一个-- 嗨, 马克. 他是一个倾听者. 他是有效加速主义的一个重要支持者. 你的批评比较多. 为什么你说IAC没有被其信徒认真对待? 
EDL	01:08:50,000	01:08:55,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Oh, well, only the left takes ideology seriously. It's just like a fact, right? \N乔治：哦, 好吧, 只有左派才会认真对待意识形态. 这就像一个事实, 对吗? 
EDL	01:08:55,000	01:08:57,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Is the right more cynical? Is that what it is? \NSwyx：右派更愤世嫉俗吗? 是这样的吗? 
EDL	01:08:57,000	01:08:58,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: I don't know. \N乔治：我不知道. 
EDL	01:08:58,000	01:08:59,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: It's like the left actually manages \NSwyx：这就像左派实际上设法
EDL	01:08:59,000	01:09:02,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: to get energy around the ideologies, right? \N乔治：在意识形态周围获得能量, 对吗? 
EDL	01:09:02,000	01:09:03,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Look, here you have- \NSwyx：听着, 你有...
EDL	01:09:03,000	01:09:08,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: You have two effective altruists named Sam going in front of Congress. Only one of them is in jail. \N乔治：你有两个叫山姆的有效的利他主义者在国会面前. 只有一个人在监狱里. 
EDL	01:09:08,000	01:09:09,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: You know, it's interesting. \NSwyx：你知道, 这很有趣. 
EDL	01:09:09,000	01:09:11,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: They're both calling for regulation in their respective spaces, right? \N乔治：他们都在呼吁对各自的空间进行监管, 对吗? 
EDL	01:09:11,000	01:09:19,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: So SBF is definitely like kind of wolf in sheep's clothing, kind of, right? Like he only adopted IAC or EA to market. \NSwyx：所以SBF绝对是那种披着羊皮的狼, 有点像, 对吗? 就像他只采用了IAC或EA来做市场. 
EDL	01:09:19,000	01:09:24,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Oh, and Sam Altman is a genuinely good guy who is not interested in power-seeking for himself. \N乔治：哦, 山姆-奥特曼是一个真正的好人, 他对为自己谋取权力不感兴趣. 
EDL	01:09:24,000	01:09:27,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: All right. Okay, okay. We don't have to go there. Fair enough, fair enough. \NSwyx：好的. 好吧, 好吧. 我们没有必要去那里. 够公平, 够公平. 
EDL	01:09:27,000	01:09:42,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: But no, IAC is not like, like you are not serious, right? Mark Andreessen, I like Mark Andreessen, but it's like someone who's like 2019, whose like eyes were opened about like the political world being not exact. You mean all the people on the news were lying to me?\N乔治：但是, 不, IAC不是像, 像你不是认真的, 对吗? 马克-安德森, 我喜欢马克-安德森, 但这是像2019年的人, 他的眼睛被打开了, 像政治世界是不准确的. 你的意思是说, 新闻上所有的人都在对我撒谎? 
EDL	01:09:42,000	01:09:43,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Bro, they were lying to you. \NSwyx：兄弟, 他们在骗你. 
EDL	01:09:43,000	01:09:50,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Like, okay, we all figured this out five years ago. Now, what are you going to do about it? I'm going to complain about it on Twitter. Great, and that's what IAC is. \N乔治：就像, 好吧, 我们都在五年前就知道了. 现在, 你打算怎么做? 我要在推特上抱怨一下. 很好, 这就是IAC的情况. 
EDL	01:09:50,000	01:09:55,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: Last and maybe most important, why was Avatar 2 bad?\N阿莱西奥：最后, 也许是最重要的, 《阿凡达2》为什么不好? 
EDL	01:09:55,000	01:09:56,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Oh, I have a whole, you can go on my blog. \NSwyx：哦, 我有一个整体, 你可以上我的博客. 
EDL	01:09:56,000	01:10:04,695	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: I rewrote the script of Avatar 2. I wrote a script that actually might make you feel something for the characters. I killed Jake Sully in the first scene. Like you had to. \N乔治：我重写了《阿凡达2》的剧本. 我写了一个剧本, 实际上可能会让你对角色有一些感觉. 我在第一幕就杀了杰克-萨利. 就像你必须做的那样. 
EDL	01:10:04,695	01:10:16,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Do you really think his second story art topped his first one? No, of course not. You had to kill the guy and make the movie about the brothers, right? And just that alone and realizing that, like you could have kept the Titanic scene.\N你真的认为他的第二个故事艺术超过了他的第一个故事吗? 不, 当然不是. 你不得不杀了那个人, 并把电影拍成关于兄弟俩的, 对吗? 仅仅是这一点, 意识到这一点, 就像你可以保留泰坦尼克号的场景. 
EDL	01:10:16,000	01:10:16,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: It would have been fine. \NSwyx：那就可以了. 
EDL	01:10:16,000	01:10:23,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: I didn't even take it out. I left your Titanic scene, James Cameron, but I wrote you a story. So, you know, you're just, just, just. \N乔治：我甚至没有把它拿出来. 我留下了你的泰坦尼克号场景, 詹姆斯-卡梅隆, 但我给你写了一个故事. 所以, 你知道, 你只是, 只是, 只是. 
EDL	01:10:23,000	01:10:24,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: He needs ships to sink in water. \N斯威克斯：他需要船在水中沉没. 
EDL	01:10:24,000	01:10:30,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Look, it's a great scene, but like the movie was just like, like the Roman, I've never. \N乔治：看, 这是一个伟大的场景, 但像电影只是像, 像罗马, 我从来没有. 
EDL	01:10:30,000	01:10:34,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Great CGI, you know, let down by the writing maybe. It's a beautiful world. \NSwyx：伟大的CGI, 你知道的, 也许是被写作辜负了. 这是个美丽的世界. 
EDL	01:10:34,000	01:10:44,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: And that's why like I care so much, right? Like you don't hear me ranting about Pirates of the Caribbean 2 being a terrible story. Cause come on, what do you expect, man? Like Johnny Depp's like, wow, I had a movie that made me rich. I love this.\N乔治：这就是为什么我这么关心, 对吗? 你不会听到我对《加勒比海盗2》是一个糟糕的故事的咆哮. 因为来吧, 你能指望什么, 伙计? 就像约翰尼-德普说的, 哇, 我有一部让我发财的电影. 我喜欢这个. 
EDL	01:10:44,000	01:10:53,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: But this goes back to like the midpoint. You know, I think you wrote like, feels like ChatGPT wrote the movie and that's my worry a little bit. It's like kind of converging towards that. \N阿莱西奥：但这又回到了中点的时候. 你知道, 我认为你写的, 感觉像是ChatGPT写的电影, 这是我有点担心. 这就像有点向那个方向靠拢. 
EDL	01:10:53,000	01:10:59,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Oh, I. Malik, Malik wrote the movie. Sorry, I didn't want to interrupt you. \NSwyx：哦, 我, 马利克, 马利克写的电影. 对不起, 我不想打断你. 
EDL	01:10:59,000	01:11:04,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: I closed a pull request two days ago. I was like, was this written by ChatGPT? And I just closed it. \N乔治：我两天前关闭了一个拉动请求. 我当时想, 这是由ChatGPT写的吗? 然后我就关闭了它. 
EDL	01:11:04,000	01:11:05,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Like, you know what? \NSwyx：就像, 你知道什么? 
EDL	01:11:05,000	01:11:07,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: I honestly feel bad if you were a human who wrote this. \N乔治：如果你是一个人写的, 我真的感到很难过. 
EDL	01:11:07,000	01:11:09,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Incapable of being more perplexed. \NSwyx：不可能更困惑了. 
EDL	01:11:09,000	01:11:19,120	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: But if you, if I have a classifier running in my head that asks, you know, is this a AI or is this a human? Like, you know, the only way to deal with all this, like, like, like, oh God, it's like the worst possible. \N乔治：但是如果你, 如果我有一个分类器在我脑子里运行, 问, 你知道, 这是一个人工智能还是一个人? 就像, 你知道, 处理这一切的唯一方法, 就像, 就像, 哦, 上帝, 这就像最糟糕的可能. 
EDL	01:11:19,120	01:11:28,788	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Like, you know, people are like, how are you mad about like these chatbots? You're not mad about like Tesla. I don't want to buy a Tesla. I don't have to buy a Tesla. And it won't really impact my life negatively. \N就像, 你知道, 人们喜欢, 你怎么会对像这些聊天机器人感到生气? 你对像特斯拉这样的东西不生气. 我不想买特斯拉. 我不一定要买特斯拉. 而且它不会真的对我的生活产生负面影响. 
EDL	01:11:28,788	01:11:38,186	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	But if I don't want to use a chatbot, it's still going to impact my life negatively. All the amount of like personalized spam that now makes me spend more cycles on my classifier to tell if it's spam or not, \N但如果我不想使用聊天机器人, 它还是会对我的生活产生负面影响. 所有像个性化的垃圾邮件的数量, 现在让我花更多的周期在我的分类器上, 以分辨它是否是垃圾邮件、
EDL	01:11:38,186	01:11:48,261	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	because you can now use AIs and generate this so cheaply. Like, no, I mean, we have to move to a model where everything's just a dollar, right? Like you want to send me an email, it's a dollar. Like you guys wouldn't care. \N因为你现在可以使用人工智能, 并产生如此便宜的东西. 就像, 不, 我的意思是, 我们必须转移到一个模式, 一切都只是一块钱, 对吗? 就像你想给我发一个电子邮件, 它是一美元. 就像你们不会关心. 
EDL	01:11:48,261	01:11:54,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	None of my friends would care. No one would care, except the spammers, right? Like we just got to move to those sort of models. \N我的朋友都不会在乎. 没有人会在乎, 除了那些垃圾邮件发送者, 对吗? 就像我们必须转移到这些模式. 
EDL	01:11:54,000	01:11:55,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Awesome. \NSwyx: 棒极了. 
EDL	01:11:55,000	01:11:58,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: One last message you want everyone to remember. \N阿莱西奥：你希望大家记住的最后一条信息. 
EDL	01:11:58,000	01:12:08,277	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	George: Go try TinyGrad. I hope that we're a serious competitor to what's out there. And then I want to take it all the way. We'll start with just building something for GPUs and then we'll start building chips \N乔治：去试试TinyGrad吧. 我希望我们是一个真正的竞争者. 然后, 我想把它一直做下去. 我们将从建立GPU的东西开始, 然后我们将开始建立芯片
EDL	01:12:08,277	01:12:15,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	and then we'll start building fabs and then we'll start building silicon mines and then we'll have the first self-reproducing robot using. \N然后我们将开始建造工厂, 然后我们将开始建造硅矿, 然后我们将有第一个使用自我复制的机器人. 
EDL	01:12:15,000	01:12:18,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Yeah, okay. All right, George. \NSwyx：是的, 好的. 好的, 乔治. 
EDL	01:12:18,000	01:12:19,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Alessio: Thank you so much for coming on. \N阿莱西奥：非常感谢你来参加. 
EDL	01:12:19,000	01:12:21,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: You did a big inspiration. Thank you. Thanks. \NSwyx：你做了一个很大的启发. 谢谢你. 谢谢. 
EDL	01:12:21,000	01:12:29,000	| Commoditizing the Petaflop — with George Hotz of the tiny corp |	Swyx: Thank you. \NSwyx：谢谢. \N
