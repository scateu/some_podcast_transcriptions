EDL	Record In	Record Out	Clipname	Subtitle
EDL	00:00:00,410	00:00:02,320	| E58 |	[Music]
EDL	00:00:02,320	00:00:04,000	| E58 |	coming to DARPA is like grabbing the
EDL	00:00:04,000	00:00:05,920	| E58 |	nose cone of a rocket and holding on for
EDL	00:00:05,920	00:00:08,240	| E58 |	dear life
EDL	00:00:08,240	00:00:09,679	| E58 |	DARPA is a place where if you don't
EDL	00:00:09,679	00:00:11,250	| E58 |	invent the internet you only get a b
EDL	00:00:11,250	00:00:12,880	| E58 |	[Music]
EDL	00:00:12,880	00:00:14,960	| E58 |	a DARPA program manager quite literally
EDL	00:00:14,960	00:00:17,199	| E58 |	invents tomorrow coming to work every
EDL	00:00:17,199	00:00:19,439	| E58 |	day and being humbled by that DARPA is
EDL	00:00:19,439	00:00:21,520	| E58 |	not one person or one place it's a
EDL	00:00:21,520	00:00:23,039	| E58 |	collection of people that are excited
EDL	00:00:23,039	00:00:26,560	| E58 |	about moving technology forward
EDL	00:00:26,560	00:00:29,840	| E58 |	for more than 60 years DARPA the defense
EDL	00:00:29,840	00:00:32,399	| E58 |	advance research projects agency has
EDL	00:00:32,399	00:00:35,040	| E58 |	held to a singular and enduring mission
EDL	00:00:35,040	00:00:36,960	| E58 |	to make pivotal investments in
EDL	00:00:36,960	00:00:38,800	| E58 |	breakthrough technologies for national
EDL	00:00:38,800	00:00:40,160	| E58 |	security
EDL	00:00:40,160	00:00:42,000	| E58 |	working with innovators inside and
EDL	00:00:42,000	00:00:44,000	| E58 |	outside of government DARPA has
EDL	00:00:44,000	00:00:46,239	| E58 |	repeatedly delivered on that mission
EDL	00:00:46,239	00:00:48,559	| E58 |	transforming revolutionary concepts and
EDL	00:00:48,559	00:00:50,879	| E58 |	even seeming impossibilities into
EDL	00:00:50,879	00:00:53,840	| E58 |	practical capabilities
EDL	00:00:53,840	00:00:54,960	| E58 |	welcome to
EDL	00:00:54,960	00:00:57,840	| E58 |	voices from DARPA a window onto DARPA's
EDL	00:00:57,840	00:01:01,039	| E58 |	programs partners and performers
EDL	00:01:01,039	00:01:03,120	| E58 |	my name is stacey wersbach and i'll be
EDL	00:01:03,120	00:01:05,920	| E58 |	your DARPA host today
EDL	00:01:05,920	00:01:08,720	| E58 |	in 1890 american lawyer and later
EDL	00:01:08,720	00:01:11,280	| E58 |	supreme court justice louis brandeis
EDL	00:01:11,280	00:01:13,200	| E58 |	pioneered the principle of a person's
EDL	00:01:13,200	00:01:15,119	| E58 |	right to privacy
EDL	00:01:15,119	00:01:17,520	| E58 |	in today's big data world privacy has
EDL	00:01:17,520	00:01:20,720	| E58 |	become a bigger issue than ever a 2019
EDL	00:01:20,720	00:01:22,880	| E58 |	pew research center poll highlighted
EDL	00:01:22,880	00:01:25,119	| E58 |	that 70 percent of americans are
EDL	00:01:25,119	00:01:27,040	| E58 |	concerned about the security of their
EDL	00:01:27,040	00:01:29,520	| E58 |	personal data this comes at a time when
EDL	00:01:29,520	00:01:31,840	| E58 |	technology advances continue to connect
EDL	00:01:31,840	00:01:34,159	| E58 |	us in ways that justice brandeis could
EDL	00:01:34,159	00:01:36,000	| E58 |	likely never imagine
EDL	00:01:36,000	00:01:38,960	| E58 |	at DARPA cryptography expert dr josh
EDL	00:01:38,960	00:01:41,360	| E58 |	baron is looking at ways to improve
EDL	00:01:41,360	00:01:43,600	| E58 |	privacy not only for national security
EDL	00:01:43,600	00:01:45,759	| E58 |	purposes but for the greater good of
EDL	00:01:45,759	00:01:48,399	| E58 |	society the work that i do here at DARPA
EDL	00:01:48,399	00:01:50,560	| E58 |	is kind of motivated both by
EDL	00:01:50,560	00:01:52,000	| E58 |	my background in cryptography and
EDL	00:01:52,000	00:01:53,520	| E58 |	thinking through cryptographic and
EDL	00:01:53,520	00:01:56,159	| E58 |	privacy issues i'm very interested in
EDL	00:01:56,159	00:01:59,119	| E58 |	technologies that affirm democratic
EDL	00:01:59,119	00:02:02,079	| E58 |	values and i'm cognizant that some of
EDL	00:02:02,079	00:02:04,079	| E58 |	the tech that we develop
EDL	00:02:04,079	00:02:06,000	| E58 |	if we're doing it right could have the
EDL	00:02:06,000	00:02:07,840	| E58 |	ability to make for example like
EDL	00:02:07,840	00:02:09,360	| E58 |	authoritarian regimes have to work a
EDL	00:02:09,360	00:02:10,560	| E58 |	little bit harder
EDL	00:02:10,560	00:02:12,560	| E58 |	clearly u.s forces in the field might
EDL	00:02:12,560	00:02:13,599	| E58 |	have a desire for anonymous
EDL	00:02:13,599	00:02:15,280	| E58 |	communications but most of the work that
EDL	00:02:15,280	00:02:17,360	| E58 |	i do it doesn't necessarily appear to be
EDL	00:02:17,360	00:02:18,480	| E58 |	so direct
EDL	00:02:18,480	00:02:21,120	| E58 |	what i'm most interested in
EDL	00:02:21,120	00:02:23,120	| E58 |	is the department of defense's in the
EDL	00:02:23,120	00:02:24,560	| E58 |	national security communities
EDL	00:02:24,560	00:02:27,760	| E58 |	relationship with the world and so when
EDL	00:02:27,760	00:02:29,840	| E58 |	i talk about privacy issues the privacy
EDL	00:02:29,840	00:02:32,000	| E58 |	issues that we address certainly impact
EDL	00:02:32,000	00:02:33,920	| E58 |	the dod community but also really does
EDL	00:02:33,920	00:02:35,360	| E58 |	impact the larger american and even
EDL	00:02:35,360	00:02:36,879	| E58 |	global communities and one of the
EDL	00:02:36,879	00:02:38,640	| E58 |	reasons for that is because i think it's
EDL	00:02:38,640	00:02:39,920	| E58 |	important that we view the national
EDL	00:02:39,920	00:02:42,080	| E58 |	security community as citizens of the
EDL	00:02:42,080	00:02:43,680	| E58 |	united states and of the world just like
EDL	00:02:43,680	00:02:45,760	| E58 |	everyone else i run programs in
EDL	00:02:45,760	00:02:47,920	| E58 |	cryptography privacy and anonymity on
EDL	00:02:47,920	00:02:49,920	| E58 |	the cryptographic side i helped finish a
EDL	00:02:49,920	00:02:51,440	| E58 |	program called brandeis which was
EDL	00:02:51,440	00:02:52,480	| E58 |	looking at privacy preserving
EDL	00:02:52,480	00:02:54,239	| E58 |	technologies so it was both cryptography
EDL	00:02:54,239	00:02:56,560	| E58 |	and privacy i ran a program called
EDL	00:02:56,560	00:02:58,239	| E58 |	cooperative secure learning which was an
EDL	00:02:58,239	00:03:00,239	| E58 |	artificial intelligence related program
EDL	00:03:00,239	00:03:02,080	| E58 |	on privacy preserving machine learning
EDL	00:03:02,080	00:03:04,319	| E58 |	also using cryptography and then on the
EDL	00:03:04,319	00:03:06,239	| E58 |	anonymity side also involving
EDL	00:03:06,239	00:03:07,840	| E58 |	cryptography but primarily focused on
EDL	00:03:07,840	00:03:10,239	| E58 |	anonymity i run this program called race
EDL	00:03:10,239	00:03:12,319	| E58 |	or resilient anonymous communication for
EDL	00:03:12,319	00:03:14,080	| E58 |	everyone that's about looking at new
EDL	00:03:14,080	00:03:16,080	| E58 |	ways of possibly doing really resilient
EDL	00:03:16,080	00:03:17,680	| E58 |	secure communications that could be
EDL	00:03:17,680	00:03:19,680	| E58 |	available to everyone and the most
EDL	00:03:19,680	00:03:22,159	| E58 |	recent one i started was mice measuring
EDL	00:03:22,159	00:03:24,239	| E58 |	the information control environment and
EDL	00:03:24,239	00:03:26,319	| E58 |	that is about open source technologies
EDL	00:03:26,319	00:03:28,959	| E58 |	to measure how authoritarian regimes try
EDL	00:03:28,959	00:03:31,040	| E58 |	to control their information environment
EDL	00:03:31,040	00:03:32,959	| E58 |	via often censorship or throttling or
EDL	00:03:32,959	00:03:35,360	| E58 |	blocking of the internet i run a program
EDL	00:03:35,360	00:03:37,760	| E58 |	called civ which is about zero knowledge
EDL	00:03:37,760	00:03:38,879	| E58 |	technology
EDL	00:03:38,879	00:03:41,040	| E58 |	one of the major technologies that DARPA
EDL	00:03:41,040	00:03:42,879	| E58 |	helped develop about 10 years ago is
EDL	00:03:42,879	00:03:44,400	| E58 |	this notion of fully homomorphic
EDL	00:03:44,400	00:03:46,640	| E58 |	encryption which is a way of taking
EDL	00:03:46,640	00:03:48,560	| E58 |	something encrypting it offloading it to
EDL	00:03:48,560	00:03:50,560	| E58 |	the cloud and then computing arbitrarily
EDL	00:03:50,560	00:03:51,920	| E58 |	on that encrypted value and then
EDL	00:03:51,920	00:03:53,439	| E58 |	returning it to you zero knowledge is
EDL	00:03:53,439	00:03:55,840	| E58 |	more subtle a zero knowledge proof is a
EDL	00:03:55,840	00:03:58,319	| E58 |	mathematical technique to verify the
EDL	00:03:58,319	00:04:00,720	| E58 |	correctness of information without
EDL	00:04:00,720	00:04:03,120	| E58 |	revealing the information itself while
EDL	00:04:03,120	00:04:05,439	| E58 |	still fairly nascent its potential for
EDL	00:04:05,439	00:04:08,239	| E58 |	securing private information is huge
EDL	00:04:08,239	00:04:09,439	| E58 |	zero knowledge is one of these really
EDL	00:04:09,439	00:04:11,200	| E58 |	fascinating areas in the sense that it
EDL	00:04:11,200	00:04:13,200	| E58 |	was developed in the late 80s and is
EDL	00:04:13,200	00:04:15,280	| E58 |	only kind of now being really examined
EDL	00:04:15,280	00:04:16,880	| E58 |	broadly by a large swath of the
EDL	00:04:16,880	00:04:18,720	| E58 |	technical community because of its ties
EDL	00:04:18,720	00:04:20,959	| E58 |	to cryptocurrency technologies so in
EDL	00:04:20,959	00:04:23,120	| E58 |	fully homomorphic encryption you have
EDL	00:04:23,120	00:04:24,479	| E58 |	the ability to compute on the
EDL	00:04:24,479	00:04:26,400	| E58 |	information whereas in zero knowledge
EDL	00:04:26,400	00:04:28,479	| E58 |	you're making a statement about
EDL	00:04:28,479	00:04:30,800	| E58 |	something that was already computed now
EDL	00:04:30,800	00:04:33,199	| E58 |	that may sound subtle
EDL	00:04:33,199	00:04:35,199	| E58 |	but believe it or not it is about four
EDL	00:04:35,199	00:04:38,160	| E58 |	to five orders of magnitude faster to do
EDL	00:04:38,160	00:04:39,840	| E58 |	zero knowledge than it is to do fully
EDL	00:04:39,840	00:04:41,360	| E58 |	homomorphic encryption to put in
EDL	00:04:41,360	00:04:42,400	| E58 |	perspective what five orders of
EDL	00:04:42,400	00:04:44,080	| E58 |	magnitude would be that would be like
EDL	00:04:44,080	00:04:46,160	| E58 |	instead of going from the east coast to
EDL	00:04:46,160	00:04:48,479	| E58 |	the west coast in hours it taking
EDL	00:04:48,479	00:04:49,759	| E58 |	milliseconds
EDL	00:04:49,759	00:04:51,840	| E58 |	as an example maybe i want to prove to
EDL	00:04:51,840	00:04:53,600	| E58 |	you that your computer system is
EDL	00:04:53,600	00:04:55,440	| E58 |	vulnerable but because we may not have
EDL	00:04:55,440	00:04:57,520	| E58 |	the closest relationship i don't want to
EDL	00:04:57,520	00:04:58,960	| E58 |	necessarily give you the exact details
EDL	00:04:58,960	00:05:00,720	| E58 |	of the vulnerability and maybe we then
EDL	00:05:00,720	00:05:02,160	| E58 |	engage in a conversation and start to
EDL	00:05:02,160	00:05:03,280	| E58 |	have a more of a say a business
EDL	00:05:03,280	00:05:04,880	| E58 |	relationship or a working relationship
EDL	00:05:04,880	00:05:06,880	| E58 |	so how can i prove to you that this
EDL	00:05:06,880	00:05:08,560	| E58 |	thing exists without just giving away
EDL	00:05:08,560	00:05:10,320	| E58 |	the store and so zero knowledge proof
EDL	00:05:10,320	00:05:12,400	| E58 |	technology allows us to do that the
EDL	00:05:12,400	00:05:14,000	| E58 |	reason it's become so in vogue in the
EDL	00:05:14,000	00:05:16,000	| E58 |	cryptocurrency world is there all sorts
EDL	00:05:16,000	00:05:17,120	| E58 |	of things you want to prove without
EDL	00:05:17,120	00:05:19,199	| E58 |	revealing say how much cryptocurrency
EDL	00:05:19,199	00:05:20,720	| E58 |	you have or other kind of sensitive
EDL	00:05:20,720	00:05:22,320	| E58 |	details associated with currency
EDL	00:05:22,320	00:05:23,520	| E58 |	transactions
EDL	00:05:23,520	00:05:25,919	| E58 |	what we're trying to do at DARPA is to
EDL	00:05:25,919	00:05:27,600	| E58 |	say well look doing currency related
EDL	00:05:27,600	00:05:30,320	| E58 |	stuff is super cool but what dod
EDL	00:05:30,320	00:05:32,560	| E58 |	relevant statements could we actually
EDL	00:05:32,560	00:05:34,639	| E58 |	prove in zero knowledge and so the three
EDL	00:05:34,639	00:05:37,039	| E58 |	broad categories that we are looking at
EDL	00:05:37,039	00:05:39,120	| E58 |	one is statements about software so can
EDL	00:05:39,120	00:05:40,960	| E58 |	we prove that something is insecure in
EDL	00:05:40,960	00:05:42,320	| E58 |	zero knowledge could i prove that
EDL	00:05:42,320	00:05:44,560	| E58 |	different sensitive software widgets can
EDL	00:05:44,560	00:05:46,880	| E58 |	be composed into a broader hole without
EDL	00:05:46,880	00:05:48,479	| E58 |	having to necessarily reveal the exact
EDL	00:05:48,479	00:05:50,080	| E58 |	details of the software widgets we're
EDL	00:05:50,080	00:05:52,880	| E58 |	doing work in zero knowledge related to
EDL	00:05:52,880	00:05:54,960	| E58 |	algorithms so can i show that a machine
EDL	00:05:54,960	00:05:57,440	| E58 |	learning classifier was made using only
EDL	00:05:57,440	00:05:58,880	| E58 |	appropriate data without revealing
EDL	00:05:58,880	00:06:01,520	| E58 |	details of the data or could i reveal
EDL	00:06:01,520	00:06:02,880	| E58 |	that i have this machine learning
EDL	00:06:02,880	00:06:04,240	| E58 |	classifier i don't want to reveal it to
EDL	00:06:04,240	00:06:05,919	| E58 |	you because it's super proprietary but
EDL	00:06:05,919	00:06:07,520	| E58 |	maybe you want to test it maybe you want
EDL	00:06:07,520	00:06:09,039	| E58 |	to give it inputs and show that this
EDL	00:06:09,039	00:06:10,960	| E58 |	classifier isn't biased and so what i
EDL	00:06:10,960	00:06:12,560	| E58 |	give you are these outputs and i prove
EDL	00:06:12,560	00:06:14,479	| E58 |	to you that i used my classifier and
EDL	00:06:14,479	00:06:15,840	| E58 |	then you can see the results and decide
EDL	00:06:15,840	00:06:17,039	| E58 |	for yourself whether it was biased or
EDL	00:06:17,039	00:06:18,240	| E58 |	not but i don't actually have to show
EDL	00:06:18,240	00:06:19,840	| E58 |	you the underlying classifier and the
EDL	00:06:19,840	00:06:21,520	| E58 |	last one which i think is almost the
EDL	00:06:21,520	00:06:24,000	| E58 |	most blue sky is these socio-technical
EDL	00:06:24,000	00:06:26,400	| E58 |	interactions so can i prove that
EDL	00:06:26,400	00:06:28,720	| E58 |	business processes or algorithms are
EDL	00:06:28,720	00:06:30,240	| E58 |	privacy law compliant without
EDL	00:06:30,240	00:06:32,400	| E58 |	necessarily revealing the details of
EDL	00:06:32,400	00:06:34,240	| E58 |	those algorithms and things on that
EDL	00:06:34,240	00:06:36,639	| E58 |	order we are funding a pretty decent
EDL	00:06:36,639	00:06:40,000	| E58 |	amount of research in taking real world
EDL	00:06:40,000	00:06:42,319	| E58 |	concepts and literally translating them
EDL	00:06:42,319	00:06:44,720	| E58 |	into math so that we can give ourselves
EDL	00:06:44,720	00:06:46,560	| E58 |	this formalism that we then give a zero
EDL	00:06:46,560	00:06:48,479	| E58 |	knowledge proof on but of course there
EDL	00:06:48,479	00:06:50,160	| E58 |	are meta issues associated with this and
EDL	00:06:50,160	00:06:51,840	| E58 |	so one of the things we are thinking a
EDL	00:06:51,840	00:06:55,120	| E58 |	bit about is the actual relationship of
EDL	00:06:55,120	00:06:57,440	| E58 |	prover and verifier and the components
EDL	00:06:57,440	00:06:59,759	| E58 |	of that proof not just as a mathematical
EDL	00:06:59,759	00:07:01,680	| E58 |	construct but actually a little bit as a
EDL	00:07:01,680	00:07:03,440	| E58 |	sociological or almost philosophical
EDL	00:07:03,440	00:07:05,759	| E58 |	construct to try to get into how do we
EDL	00:07:05,759	00:07:08,160	| E58 |	formally or rigorously think about this
EDL	00:07:08,160	00:07:10,160	| E58 |	prover verifier relationship in such a
EDL	00:07:10,160	00:07:11,520	| E58 |	way as to actually think about what
EDL	00:07:11,520	00:07:13,039	| E58 |	kinds of zero knowledge proofs would
EDL	00:07:13,039	00:07:14,639	| E58 |	most be useful and that's a study we're
EDL	00:07:14,639	00:07:16,800	| E58 |	actually running on the side of civ as
EDL	00:07:16,800	00:07:18,240	| E58 |	we think about leading our lives
EDL	00:07:18,240	00:07:20,960	| E58 |	increasingly in an online fashion and we
EDL	00:07:20,960	00:07:23,199	| E58 |	come into daily issues associated with
EDL	00:07:23,199	00:07:25,120	| E58 |	privacy in our online lives i do think
EDL	00:07:25,120	00:07:26,479	| E58 |	that zero knowledge could play a really
EDL	00:07:26,479	00:07:28,080	| E58 |	important role in demonstrating that our
EDL	00:07:28,080	00:07:30,479	| E58 |	online activities are within bounds for
EDL	00:07:30,479	00:07:32,080	| E58 |	some definition of what that is while
EDL	00:07:32,080	00:07:33,280	| E58 |	still maintaining the important
EDL	00:07:33,280	00:07:35,520	| E58 |	anonymity aspects that we tend to view
EDL	00:07:35,520	00:07:37,280	| E58 |	is pretty important for our lives
EDL	00:07:37,280	00:07:39,440	| E58 |	in addition to exploring real-world
EDL	00:07:39,440	00:07:41,919	| E58 |	applications of zero-knowledge proofs dr
EDL	00:07:41,919	00:07:44,160	| E58 |	barron recently commissioned a report by
EDL	00:07:44,160	00:07:46,400	| E58 |	the company trail of bids that look
EDL	00:07:46,400	00:07:48,560	| E58 |	closely at the fundamental properties of
EDL	00:07:48,560	00:07:50,560	| E58 |	blockchain technologies
EDL	00:07:50,560	00:07:53,120	| E58 |	blockchains today are increasingly used
EDL	00:07:53,120	00:07:55,120	| E58 |	in a variety of contexts they're
EDL	00:07:55,120	00:07:57,120	| E58 |	presumed to be immutable or
EDL	00:07:57,120	00:07:59,120	| E58 |	unsusceptible to change because of
EDL	00:07:59,120	00:08:00,800	| E58 |	strong cryptography as well as
EDL	00:08:00,800	00:08:03,440	| E58 |	decentralized operations and control
EDL	00:08:03,440	00:08:05,039	| E58 |	but are those security assumptions
EDL	00:08:05,039	00:08:07,919	| E58 |	accurate and why does DARPA care one of
EDL	00:08:07,919	00:08:09,440	| E58 |	the core missions for DARPA is
EDL	00:08:09,440	00:08:11,680	| E58 |	anticipating technological surprise and
EDL	00:08:11,680	00:08:12,560	| E58 |	while
EDL	00:08:12,560	00:08:14,000	| E58 |	i wouldn't say at this point that these
EDL	00:08:14,000	00:08:16,000	| E58 |	kinds of distributed technologies and
EDL	00:08:16,000	00:08:18,160	| E58 |	blockchain technologies are
EDL	00:08:18,160	00:08:19,759	| E58 |	surprising i think there is still
EDL	00:08:19,759	00:08:21,280	| E58 |	something to the idea that these
EDL	00:08:21,280	00:08:23,120	| E58 |	technologies may really get integrated
EDL	00:08:23,120	00:08:24,639	| E58 |	into national security systems for
EDL	00:08:24,639	00:08:26,639	| E58 |	example i here at DARPA hadn't been
EDL	00:08:26,639	00:08:28,560	| E58 |	seeing anyone taking a what i would call
EDL	00:08:28,560	00:08:31,199	| E58 |	a holistic view at blockchain technology
EDL	00:08:31,199	00:08:33,039	| E58 |	cyber security and by that i mean the
EDL	00:08:33,039	00:08:35,039	| E58 |	whole way that we view these distributed
EDL	00:08:35,039	00:08:37,039	| E58 |	technologies is that they're distributed
EDL	00:08:37,039	00:08:38,559	| E58 |	and therefore they're resilient and so
EDL	00:08:38,559	00:08:40,000	| E58 |	we almost like say oh well it's being
EDL	00:08:40,000	00:08:41,440	| E58 |	run on like a thousand computers and
EDL	00:08:41,440	00:08:43,200	| E58 |	therefore clearly it's secure because
EDL	00:08:43,200	00:08:44,480	| E58 |	it's running on so many of them you know
EDL	00:08:44,480	00:08:45,680	| E58 |	what can go wrong
EDL	00:08:45,680	00:08:46,959	| E58 |	while it's true that blockchain
EDL	00:08:46,959	00:08:48,959	| E58 |	technologies run on many many systems at
EDL	00:08:48,959	00:08:51,279	| E58 |	a conceptual level you can think of them
EDL	00:08:51,279	00:08:54,080	| E58 |	as one system and so it's a system that
EDL	00:08:54,080	00:08:56,000	| E58 |	is in a distributed fashion performing a
EDL	00:08:56,000	00:08:57,920	| E58 |	specific functionality and so when you
EDL	00:08:57,920	00:08:59,360	| E58 |	view it that way then the question
EDL	00:08:59,360	00:09:01,360	| E58 |	becomes well okay now that i think of it
EDL	00:09:01,360	00:09:03,360	| E58 |	as one system what are the different
EDL	00:09:03,360	00:09:05,200	| E58 |	properties of this system even though
EDL	00:09:05,200	00:09:06,959	| E58 |	it's in many places that is why i was
EDL	00:09:06,959	00:09:10,240	| E58 |	very interested in this study because it
EDL	00:09:10,240	00:09:12,000	| E58 |	really wanted to take a very holistic
EDL	00:09:12,000	00:09:14,480	| E58 |	view of all of the different issues
EDL	00:09:14,480	00:09:15,839	| E58 |	through which blockchain technology
EDL	00:09:15,839	00:09:17,200	| E58 |	could be vulnerable
EDL	00:09:17,200	00:09:18,880	| E58 |	it turns out what they found was that
EDL	00:09:18,880	00:09:21,680	| E58 |	the way in which we think of
EDL	00:09:21,680	00:09:23,839	| E58 |	resilience or security when it comes to
EDL	00:09:23,839	00:09:25,760	| E58 |	these distributed technologies
EDL	00:09:25,760	00:09:27,760	| E58 |	may deserve a second look
EDL	00:09:27,760	00:09:29,680	| E58 |	i think it's important to recognize that
EDL	00:09:29,680	00:09:31,440	| E58 |	a lot of the relevant issues we looked
EDL	00:09:31,440	00:09:33,680	| E58 |	at in this report would involve an
EDL	00:09:33,680	00:09:34,839	| E58 |	incredibly
EDL	00:09:34,839	00:09:37,040	| E58 |	sophisticated actor or adversary for
EDL	00:09:37,040	00:09:38,560	| E58 |	example to try to really affect these
EDL	00:09:38,560	00:09:40,800	| E58 |	currencies what i'm particularly worried
EDL	00:09:40,800	00:09:41,760	| E58 |	about and especially i think the
EDL	00:09:41,760	00:09:43,040	| E58 |	national security community should be
EDL	00:09:43,040	00:09:44,480	| E58 |	particularly worried about are high
EDL	00:09:44,480	00:09:46,240	| E58 |	sophistication actors just because we
EDL	00:09:46,240	00:09:47,920	| E58 |	haven't seen it in the last 10 years
EDL	00:09:47,920	00:09:48,959	| E58 |	doesn't mean we're not going to see it
EDL	00:09:48,959	00:09:50,959	| E58 |	over the next two or three
EDL	00:09:50,959	00:09:53,279	| E58 |	i think cryptocurrency technologies
EDL	00:09:53,279	00:09:57,680	| E58 |	are a really intriguing way of building
EDL	00:09:57,680	00:10:00,320	| E58 |	cyber security out of distributing your
EDL	00:10:00,320	00:10:02,320	| E58 |	kind of most sensitive components across
EDL	00:10:02,320	00:10:04,560	| E58 |	as many elements as you can i just want
EDL	00:10:04,560	00:10:06,399	| E58 |	us to be careful that when you do that
EDL	00:10:06,399	00:10:08,240	| E58 |	you're still thinking holistically about
EDL	00:10:08,240	00:10:10,000	| E58 |	the cyber security issues and that we
EDL	00:10:10,000	00:10:11,360	| E58 |	don't just say oh well because it's in
EDL	00:10:11,360	00:10:12,959	| E58 |	10 places that's by definition more
EDL	00:10:12,959	00:10:14,000	| E58 |	secure
EDL	00:10:14,000	00:10:16,000	| E58 |	two additional programs in dr barron's
EDL	00:10:16,000	00:10:18,640	| E58 |	portfolio focus on different ends of the
EDL	00:10:18,640	00:10:21,040	| E58 |	privacy spectrum first there's measuring
EDL	00:10:21,040	00:10:22,880	| E58 |	the information control environment or
EDL	00:10:22,880	00:10:26,079	| E58 |	mice an ai exploration effort mice seeks
EDL	00:10:26,079	00:10:28,079	| E58 |	to develop algorithms and open source
EDL	00:10:28,079	00:10:30,160	| E58 |	software that would automate analysis
EDL	00:10:30,160	00:10:32,720	| E58 |	about foreign authoritarian regimes
EDL	00:10:32,720	00:10:34,399	| E58 |	attempts to control and repress their
EDL	00:10:34,399	00:10:36,480	| E58 |	public's communications using digital
EDL	00:10:36,480	00:10:38,720	| E58 |	means so mice's six projects running
EDL	00:10:38,720	00:10:40,240	| E58 |	over 18 months it's like six million
EDL	00:10:40,240	00:10:41,920	| E58 |	dollars which is smaller and kind of
EDL	00:10:41,920	00:10:43,519	| E58 |	shorter than your average DARPA program
EDL	00:10:43,519	00:10:44,720	| E58 |	your average starter program is
EDL	00:10:44,720	00:10:46,800	| E58 |	generally on the order of four years and
EDL	00:10:46,800	00:10:48,720	| E58 |	so i think of them as sprints and the
EDL	00:10:48,720	00:10:51,279	| E58 |	sprint that i specifically wanted to do
EDL	00:10:51,279	00:10:52,959	| E58 |	in this effort
EDL	00:10:52,959	00:10:53,839	| E58 |	was
EDL	00:10:53,839	00:10:56,560	| E58 |	to look at technology available today
EDL	00:10:56,560	00:10:59,120	| E58 |	even in the open source about sensing
EDL	00:10:59,120	00:11:01,360	| E58 |	trying to understand just from its pure
EDL	00:11:01,360	00:11:04,160	| E58 |	data perspective when countries are
EDL	00:11:04,160	00:11:06,240	| E58 |	trying to block the internet or
EDL	00:11:06,240	00:11:07,920	| E58 |	otherwise censor their internet there
EDL	00:11:07,920	00:11:09,360	| E58 |	are just a number of these they're on
EDL	00:11:09,360	00:11:10,800	| E58 |	the public domain and what i really
EDL	00:11:10,800	00:11:12,560	| E58 |	wanted to do was turbocharge them
EDL	00:11:12,560	00:11:14,240	| E58 |	essentially by leveraging artificial
EDL	00:11:14,240	00:11:16,399	| E58 |	intelligence technology to take these
EDL	00:11:16,399	00:11:18,959	| E58 |	broad amounts of data that these sensors
EDL	00:11:18,959	00:11:21,200	| E58 |	are looking at and try to make them more
EDL	00:11:21,200	00:11:23,360	| E58 |	fine-grained and then if you really want
EDL	00:11:23,360	00:11:25,040	| E58 |	to be kind of blue sky about it even
EDL	00:11:25,040	00:11:27,120	| E58 |	predictive so given the data that i see
EDL	00:11:27,120	00:11:28,399	| E58 |	today
EDL	00:11:28,399	00:11:30,320	| E58 |	make a prediction about how someone
EDL	00:11:30,320	00:11:32,720	| E58 |	might be censoring tomorrow
EDL	00:11:32,720	00:11:35,040	| E58 |	on the flip side the brandeis program
EDL	00:11:35,040	00:11:37,200	| E58 |	named after you guessed it louis
EDL	00:11:37,200	00:11:39,120	| E58 |	brandeis looks at how to preserve
EDL	00:11:39,120	00:11:41,760	| E58 |	privacy by making complex computations
EDL	00:11:41,760	00:11:43,839	| E58 |	even on a mobile device what we're doing
EDL	00:11:43,839	00:11:45,920	| E58 |	here in this brandeis effort in this
EDL	00:11:45,920	00:11:47,920	| E58 |	particular brandeis technology was
EDL	00:11:47,920	00:11:50,000	| E58 |	distributing the computation to the
EDL	00:11:50,000	00:11:51,680	| E58 |	mobile devices and essentially moving
EDL	00:11:51,680	00:11:53,680	| E58 |	away from the cloud we're actually just
EDL	00:11:53,680	00:11:55,200	| E58 |	about to release some technology that
EDL	00:11:55,200	00:11:56,560	| E58 |	i'm particularly excited about and
EDL	00:11:56,560	00:11:57,760	| E58 |	there's going to be
EDL	00:11:57,760	00:11:59,839	| E58 |	something coming out in the next weeks
EDL	00:11:59,839	00:12:01,040	| E58 |	to months
EDL	00:12:01,040	00:12:02,800	| E58 |	where the actual computation is
EDL	00:12:02,800	00:12:05,040	| E58 |	occurring purely on mobile phones and
EDL	00:12:05,040	00:12:06,320	| E58 |	just to put that in like historical
EDL	00:12:06,320	00:12:08,320	| E58 |	perspective like 10 years ago we had the
EDL	00:12:08,320	00:12:09,680	| E58 |	DARPA proceed effort which is about
EDL	00:12:09,680	00:12:11,120	| E58 |	fully homomorphic encryption and
EDL	00:12:11,120	00:12:14,079	| E58 |	reducing the asymptotic complexity of
EDL	00:12:14,079	00:12:15,920	| E58 |	that by seven orders of magnitude even
EDL	00:12:15,920	00:12:17,680	| E58 |	though it was still about seven orders
EDL	00:12:17,680	00:12:19,200	| E58 |	of magnitude kind of slower than just
EDL	00:12:19,200	00:12:21,600	| E58 |	running it natively and now here we are
EDL	00:12:21,600	00:12:23,440	| E58 |	where you know like 10 different parties
EDL	00:12:23,440	00:12:24,959	| E58 |	can be computing on encrypted
EDL	00:12:24,959	00:12:26,639	| E58 |	information jointly just on mobile
EDL	00:12:26,639	00:12:28,160	| E58 |	phones
EDL	00:12:28,160	00:12:30,000	| E58 |	every DARPA program manager has a
EDL	00:12:30,000	00:12:31,760	| E58 |	formative moment that ignited their
EDL	00:12:31,760	00:12:33,920	| E58 |	passion for their field of expertise
EDL	00:12:33,920	00:12:36,000	| E58 |	whether it's an unsuspecting mentor or
EDL	00:12:36,000	00:12:38,720	| E58 |	an aha moment as a child no two entry
EDL	00:12:38,720	00:12:41,519	| E58 |	points are alike but all are fascinating
EDL	00:12:41,519	00:12:42,880	| E58 |	i think reading like cyberpunk
EDL	00:12:42,880	00:12:44,800	| E58 |	literature such as neil stephenson was
EDL	00:12:44,800	00:12:46,639	| E58 |	incredibly formative to me but also just
EDL	00:12:46,639	00:12:49,279	| E58 |	like i mean watching the movie hackers
EDL	00:12:49,279	00:12:51,519	| E58 |	and you know just just being completely
EDL	00:12:51,519	00:12:55,279	| E58 |	blown away by using technology to
EDL	00:12:55,279	00:12:57,519	| E58 |	empower yourself and others to do wild
EDL	00:12:57,519	00:12:59,360	| E58 |	and crazy things is also a thing that is
EDL	00:12:59,360	00:13:00,959	| E58 |	important really when you get down to it
EDL	00:13:00,959	00:13:02,399	| E58 |	what i'm interested in
EDL	00:13:02,399	00:13:03,200	| E58 |	is
EDL	00:13:03,200	00:13:04,560	| E58 |	information and who has it and who
EDL	00:13:04,560	00:13:06,320	| E58 |	doesn't and what that implies you know
EDL	00:13:06,320	00:13:07,279	| E58 |	when you talk about privacy and
EDL	00:13:07,279	00:13:08,720	| E58 |	anonymity it's really about the study of
EDL	00:13:08,720	00:13:10,079	| E58 |	information flowing and how that
EDL	00:13:10,079	00:13:11,680	| E58 |	information is controlled
EDL	00:13:11,680	00:13:13,200	| E58 |	how we're going to move forward as a
EDL	00:13:13,200	00:13:16,240	| E58 |	country in a big data world but still
EDL	00:13:16,240	00:13:18,480	| E58 |	being ever more attuned to people's
EDL	00:13:18,480	00:13:20,720	| E58 |	privacy the way i see it there are
EDL	00:13:20,720	00:13:22,240	| E58 |	probably two different paradigms that we
EDL	00:13:22,240	00:13:24,079	| E58 |	can move ahead with and i'm honestly not
EDL	00:13:24,079	00:13:25,920	| E58 |	sure which is the right one or maybe
EDL	00:13:25,920	00:13:29,040	| E58 |	it's both one is where we fundamentally
EDL	00:13:29,040	00:13:30,320	| E58 |	trust the people who have our data to
EDL	00:13:30,320	00:13:32,160	| E58 |	treat our data accordingly and maybe
EDL	00:13:32,160	00:13:34,480	| E58 |	what the technology that we need is to
EDL	00:13:34,480	00:13:36,959	| E58 |	leverage something like ai to literally
EDL	00:13:36,959	00:13:38,959	| E58 |	build digital representatives of
EDL	00:13:38,959	00:13:40,800	| E58 |	ourselves that live within the data
EDL	00:13:40,800	00:13:42,320	| E58 |	ecosystem and like represent our
EDL	00:13:42,320	00:13:43,680	| E58 |	interests but to do that would
EDL	00:13:43,680	00:13:45,440	| E58 |	fundamentally involve the companies
EDL	00:13:45,440	00:13:46,639	| E58 |	themselves like allowing that kind of
EDL	00:13:46,639	00:13:48,560	| E58 |	thing to happen i'll say that's the
EDL	00:13:48,560	00:13:50,720	| E58 |	optimistic view the more pessimistic
EDL	00:13:50,720	00:13:53,519	| E58 |	view is that we really can't trust other
EDL	00:13:53,519	00:13:55,760	| E58 |	people to really do well with our data
EDL	00:13:55,760	00:13:57,680	| E58 |	and so then in that respect maybe what
EDL	00:13:57,680	00:14:00,399	| E58 |	we should be thinking more about is
EDL	00:14:00,399	00:14:02,240	| E58 |	how they come to collector data in the
EDL	00:14:02,240	00:14:04,320	| E58 |	first place and just building ever more
EDL	00:14:04,320	00:14:05,920	| E58 |	careful technology that never lets
EDL	00:14:05,920	00:14:08,000	| E58 |	private data get out and just by the way
EDL	00:14:08,000	00:14:09,600	| E58 |	one of the most important parts about
EDL	00:14:09,600	00:14:10,720	| E58 |	that would be
EDL	00:14:10,720	00:14:13,440	| E58 |	having low user burden discussions
EDL	00:14:13,440	00:14:15,600	| E58 |	between say your phone and yourself
EDL	00:14:15,600	00:14:16,720	| E58 |	about
EDL	00:14:16,720	00:14:18,160	| E58 |	what data it is that you truly don't
EDL	00:14:18,160	00:14:20,480	| E58 |	want to leave we've funded it as part of
EDL	00:14:20,480	00:14:22,800	| E58 |	young faculty awards as part of brandeis
EDL	00:14:22,800	00:14:24,800	| E58 |	but that still needs ever more funding
EDL	00:14:24,800	00:14:26,639	| E58 |	is what's often called human factors
EDL	00:14:26,639	00:14:28,399	| E58 |	research or human computer interaction
EDL	00:14:28,399	00:14:29,760	| E58 |	and that's really about forgetting about
EDL	00:14:29,760	00:14:31,279	| E58 |	how well the privacy technology does or
EDL	00:14:31,279	00:14:33,120	| E58 |	doesn't work how do we have faithful
EDL	00:14:33,120	00:14:34,720	| E58 |	conversations between the technology and
EDL	00:14:34,720	00:14:37,360	| E58 |	people about what exact privacy should
EDL	00:14:37,360	00:14:40,399	| E58 |	be maintained and then the trade-off
EDL	00:14:40,399	00:14:42,320	| E58 |	between well if i restrict this kind of
EDL	00:14:42,320	00:14:43,920	| E58 |	data maybe you're going to get less good
EDL	00:14:43,920	00:14:45,839	| E58 |	services in some respect and how people
EDL	00:14:45,839	00:14:47,199	| E58 |	can actually kind of understand that
EDL	00:14:47,199	00:14:48,560	| E58 |	desire

EDL	00:14:48,560	00:14:53,279	| E58 |	trust, information security and people's privacy will continue to be challenged
EDL	00:14:53,279	00:14:55,760	| E58 |	as technology evolves but Dr Barron and
EDL	00:14:55,760	00:14:58,639	| E58 |	his team are undeterred. DARPA is one of
EDL	00:14:58,639	00:15:00,240	| E58 |	these organizations that you have the
EDL	00:15:00,240	00:15:01,920	| E58 |	potential to make a great deal of
EDL	00:15:01,920	00:15:03,680	| E58 |	difference in terms of the technical
EDL	00:15:03,680	00:15:04,959	| E58 |	research direction that the united
EDL	00:15:04,959	00:15:06,959	| E58 |	states research community and global
EDL	00:15:06,959	00:15:09,279	| E58 |	research community looks at
EDL	00:15:09,279	00:15:10,240	| E58 |	to me
EDL	00:15:10,240	00:15:11,920	| E58 |	the thing that makes DARPA awesome is
EDL	00:15:11,920	00:15:13,760	| E58 |	the same thing that makes it a challenge
EDL	00:15:13,760	00:15:15,920	| E58 |	which is they let you come here and they
EDL	00:15:15,920	00:15:17,839	| E58 |	say go do awesome things
EDL	00:15:17,839	00:15:18,959	| E58 |	so
EDL	00:15:18,959	00:15:20,560	| E58 |	yeah you have to go do awesome things
EDL	00:15:20,560	00:15:22,079	| E58 |	that's quite the challenge
EDL	00:15:22,079	00:15:24,639	| E58 |	however the way you do awesome things is
EDL	00:15:24,639	00:15:26,720	| E58 |	by engaging with the most awesome people
EDL	00:15:26,720	00:15:28,079	| E58 |	i tend to think of it like being a
EDL	00:15:28,079	00:15:30,399	| E58 |	conductor of an orchestra where
EDL	00:15:30,399	00:15:31,839	| E58 |	what we're trying to do is to try to
EDL	00:15:31,839	00:15:34,639	| E58 |	find the best violin player the best
EDL	00:15:34,639	00:15:36,320	| E58 |	pianist the best whatever it is and what
EDL	00:15:36,320	00:15:38,720	| E58 |	have you and then probably the one thing
EDL	00:15:38,720	00:15:40,320	| E58 |	that a program manager does more than
EDL	00:15:40,320	00:15:41,600	| E58 |	anything else is figure out how these
EDL	00:15:41,600	00:15:43,839	| E58 |	different parts play together to create
EDL	00:15:43,839	00:15:46,000	| E58 |	a coherent whole but most importantly
EDL	00:15:46,000	00:15:47,839	| E58 |	it's really about ensuring that the
EDL	00:15:47,839	00:15:50,720	| E58 |	people you engage in are given the space
EDL	00:15:50,720	00:15:52,320	| E58 |	to do the very best work that they can
EDL	00:15:52,320	00:15:54,480	| E58 |	do meeting people having open-ended
EDL	00:15:54,480	00:15:56,639	| E58 |	discussions engaging with them and then
EDL	00:15:56,639	00:15:58,079	| E58 |	once you have a research relationship
EDL	00:15:58,079	00:15:59,600	| E58 |	with them them telling you about the
EDL	00:15:59,600	00:16:02,000	| E58 |	cool new result that they just uncovered
EDL	00:16:02,000	00:16:04,000	| E58 |	and oh by the way that results may or
EDL	00:16:04,000	00:16:06,079	| E58 |	may not have direct relevance to the
EDL	00:16:06,079	00:16:07,120	| E58 |	thing that you actually ask them to
EDL	00:16:07,120	00:16:08,399	| E58 |	research but that's the really cool part
EDL	00:16:08,399	00:16:10,079	| E58 |	about DARPA is that again i would never
EDL	00:16:10,079	00:16:11,759	| E58 |	want to prescribe a research
EDL	00:16:11,759	00:16:13,920	| E58 |	relationship that DARPA has to just a
EDL	00:16:13,920	00:16:15,519	| E58 |	very narrow of the very specific thing
EDL	00:16:15,519	00:16:16,959	| E58 |	we asked you to do because that's not
EDL	00:16:16,959	00:16:18,800	| E58 |	how people's brains work right you set
EDL	00:16:18,800	00:16:19,839	| E58 |	them on a path and then they have this
EDL	00:16:19,839	00:16:21,600	| E58 |	other brilliant idea and they engage
EDL	00:16:21,600	00:16:22,880	| E58 |	with you on it and you're like oh wait
EDL	00:16:22,880	00:16:24,160	| E58 |	no maybe we actually should be thinking
EDL	00:16:24,160	00:16:25,199	| E58 |	about that thing even more than the
EDL	00:16:25,199	00:16:26,160	| E58 |	thing that we initially thought we
EDL	00:16:26,160	00:16:27,680	| E58 |	should be thinking on and then pivoting
EDL	00:16:27,680	00:16:29,199	| E58 |	and doing that thing that's all
EDL	00:16:29,199	00:16:31,120	| E58 |	incredible. And then the other part is
EDL	00:16:31,120	00:16:32,560	| E58 |	the ability to engage with folks in
EDL	00:16:32,560	00:16:33,759	| E58 |	government who are just doing such
EDL	00:16:33,759	00:16:35,759	| E58 |	incredible things part of being at DARPA
EDL	00:16:35,759	00:16:38,399	| E58 |	is there's this kind of unspoken idea
EDL	00:16:38,399	00:16:39,680	| E58 |	that the folks within the department of
EDL	00:16:39,680	00:16:41,279	| E58 |	defense or just again within the broader
EDL	00:16:41,279	00:16:42,560	| E58 |	government are coming to you because
EDL	00:16:42,560	00:16:44,639	| E58 |	they have specific problems and they
EDL	00:16:44,639	00:16:46,079	| E58 |	want you to help with those problems and
EDL	00:16:46,079	00:16:47,440	| E58 |	then as part of that they're really
EDL	00:16:47,440	00:16:48,560	| E58 |	going to get into the weeds with you and
EDL	00:16:48,560	00:16:49,680	| E58 |	tell you kind of what their day to day
EDL	00:16:49,680	00:16:50,800	| E58 |	looks like that's just such an
EDL	00:16:50,800	00:16:52,720	| E58 |	incredible privilege just to see these
EDL	00:16:52,720	00:16:54,720	| E58 |	people doing the nation's work and then
EDL	00:16:54,720	00:16:56,880	| E58 |	figuring out how to support them.

EDL	00:16:56,880	00:16:59,040	| E58 |	Thanks for tuning in to this voices from
EDL	00:16:59,040	00:17:01,600	| E58 |	DARPA podcast episode and special thanks
EDL	00:17:01,600	00:17:03,360	| E58 |	to Tom Shortridge for producing this
EDL	00:17:03,360	00:17:07,520	| E58 |	podcast and Heather Dees for her assistance. For more information on the
EDL	00:17:07,520	00:17:14,679	| E58 |	work in Dr Barron's portfolio or any other DARPA effort visit DARPA.mil.
EDL	00:17:14,679	00:17:15,190	| E58 |	[ SPACE 0.5 secs ]
EDL	00:17:15,190	00:17:31,769	| E58 |	[Music]
EDL	00:17:31,769	00:17:34,160	| E58 |	[ SPACE 2.4 secs ]
